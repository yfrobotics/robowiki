{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"\u673a\u5668\u4eba\u7ef4\u57fa\u767e\u79d1 (RoboWiki) \u9879\u76eeGitHub\u5730\u5740 \u4ecb\u7ecd \u6b22\u8fce\u6765\u5230RoboWiki. RoboWiki\u662f\u7531 \u4e91\u98de\u673a\u5668\u4eba\u5b9e\u9a8c\u5ba4 \u53d1\u8d77\u7684\u673a\u5668\u4eba\u9886\u57df\u516c\u5171\u77e5\u8bc6\u7f16\u8f91\u77e5\u8bc6\u5e93\u3002 \u672c\u7ef4\u57fa\u65e8\u5728\u6db5\u76d6\u673a\u5668\u4eba\u8bbe\u8ba1\u3001\u7f16\u7a0b\u3001\u7406\u8bba\u3001\u7b97\u6cd5\u3001\u6a21\u578b\u3001\u8d44\u6e90\u7b49\u591a\u65b9\u9762\u5185\u5bb9\u3002 \u6211\u4eec\u91c7\u7528\u516c\u5171\u77e5\u8bc6\u7f16\u8f91\u7684\u65b9\u5f0f\u5e76\u63d0\u5021 \u77e5\u8bc6\u81ea\u7531 \u3002 \u6240\u6709\u4eba\u90fd\u9f13\u52b1\u3001\u5e76\u53ef\u4ee5\u53c2\u4e0e\u5230\u7f16\u8f91\u7684\u8fc7\u7a0b\u4e2d\uff0c\u5e76\u5728\u8be5\u8fc7\u7a0b\u4e2d\u4e0d\u65ad\u6539\u8fdb\u5185\u5bb9\u7684\u8d28\u91cf\u3002 \u673a\u5668\u4eba\u6b63\u5728\u4e0d\u65ad\u7684\u8fdb\u5165\u5230\u6211\u4eec\u7684\u751f\u6d3b\u91cc\u3002\u6211\u4eec\u76f8\u4fe1\u901a\u8fc7\u6211\u4eec\u7684\u52aa\u529b\uff0c\u53ef\u4ee5\u505a\u6210\u8986\u76d6\u5168\u9762\u7684\u673a\u5668\u4eba\u77e5\u8bc6\u5e93\uff0c\u4e3a\u673a\u5668\u4eba\u5f00\u53d1\u8005\u3001\u7814\u7a76\u8005\u3001\u7231\u597d\u8005\u63d0\u4f9b\u4fbf\u5229\u3002 \u81f4\u8c22 \u672c\u9879\u76ee\u5728\u8bbe\u8ba1\u8fc7\u7a0b\u4e2d\u53c2\u7167\u4e86\u90e8\u5206 OI-wiki \u7684\u8bbe\u8ba1\u7075\u611f\u548c\u7406\u5ff5\uff0c\u5728\u6b64\u8868\u793a\u611f\u8c22\u3002 \u8d21\u732e\u8005\u540d\u5355 automaticdai - \u6234\u6653\u5929 xinyu-xu-dev - Xinyu Xu \u7248\u6743\u7533\u660e \u672c\u9879\u76ee\u9075\u5faaCC 4.0-BY-NC-SA\uff08\u521b\u4f5c\u5171\u7528-\u7f72\u540d-\u975e\u5546\u4e1a\u6027-\u76f8\u540c\u65b9\u5f0f\u5171\u4eab\uff09\u534f\u8bae\uff0c\u8be6\u89c1 \u6761\u6b3e \u3002","title":"\u673a\u5668\u4eba\u7ef4\u57fa\u767e\u79d1 (RoboWiki)"},{"location":"#robowiki","text":"\u9879\u76eeGitHub\u5730\u5740","title":"\u673a\u5668\u4eba\u7ef4\u57fa\u767e\u79d1 (RoboWiki)"},{"location":"#_1","text":"\u6b22\u8fce\u6765\u5230RoboWiki. RoboWiki\u662f\u7531 \u4e91\u98de\u673a\u5668\u4eba\u5b9e\u9a8c\u5ba4 \u53d1\u8d77\u7684\u673a\u5668\u4eba\u9886\u57df\u516c\u5171\u77e5\u8bc6\u7f16\u8f91\u77e5\u8bc6\u5e93\u3002 \u672c\u7ef4\u57fa\u65e8\u5728\u6db5\u76d6\u673a\u5668\u4eba\u8bbe\u8ba1\u3001\u7f16\u7a0b\u3001\u7406\u8bba\u3001\u7b97\u6cd5\u3001\u6a21\u578b\u3001\u8d44\u6e90\u7b49\u591a\u65b9\u9762\u5185\u5bb9\u3002 \u6211\u4eec\u91c7\u7528\u516c\u5171\u77e5\u8bc6\u7f16\u8f91\u7684\u65b9\u5f0f\u5e76\u63d0\u5021 \u77e5\u8bc6\u81ea\u7531 \u3002 \u6240\u6709\u4eba\u90fd\u9f13\u52b1\u3001\u5e76\u53ef\u4ee5\u53c2\u4e0e\u5230\u7f16\u8f91\u7684\u8fc7\u7a0b\u4e2d\uff0c\u5e76\u5728\u8be5\u8fc7\u7a0b\u4e2d\u4e0d\u65ad\u6539\u8fdb\u5185\u5bb9\u7684\u8d28\u91cf\u3002 \u673a\u5668\u4eba\u6b63\u5728\u4e0d\u65ad\u7684\u8fdb\u5165\u5230\u6211\u4eec\u7684\u751f\u6d3b\u91cc\u3002\u6211\u4eec\u76f8\u4fe1\u901a\u8fc7\u6211\u4eec\u7684\u52aa\u529b\uff0c\u53ef\u4ee5\u505a\u6210\u8986\u76d6\u5168\u9762\u7684\u673a\u5668\u4eba\u77e5\u8bc6\u5e93\uff0c\u4e3a\u673a\u5668\u4eba\u5f00\u53d1\u8005\u3001\u7814\u7a76\u8005\u3001\u7231\u597d\u8005\u63d0\u4f9b\u4fbf\u5229\u3002","title":"\u4ecb\u7ecd"},{"location":"#_2","text":"\u672c\u9879\u76ee\u5728\u8bbe\u8ba1\u8fc7\u7a0b\u4e2d\u53c2\u7167\u4e86\u90e8\u5206 OI-wiki \u7684\u8bbe\u8ba1\u7075\u611f\u548c\u7406\u5ff5\uff0c\u5728\u6b64\u8868\u793a\u611f\u8c22\u3002","title":"\u81f4\u8c22"},{"location":"#_3","text":"automaticdai - \u6234\u6653\u5929 xinyu-xu-dev - Xinyu Xu","title":"\u8d21\u732e\u8005\u540d\u5355"},{"location":"#_4","text":"\u672c\u9879\u76ee\u9075\u5faaCC 4.0-BY-NC-SA\uff08\u521b\u4f5c\u5171\u7528-\u7f72\u540d-\u975e\u5546\u4e1a\u6027-\u76f8\u540c\u65b9\u5f0f\u5171\u4eab\uff09\u534f\u8bae\uff0c\u8be6\u89c1 \u6761\u6b3e \u3002","title":"\u7248\u6743\u7533\u660e"},{"location":"about/","text":"\u5173\u4e8e \u4e91\u98de\u673a\u5668\u4eba\u5b9e\u9a8c\u5ba4 \u4e91\u98de\u673a\u5668\u4eba\u5b9e\u9a8c\u5ba4\u662f\u4e00\u4e2a \u201c\u4e13\u6ce8\u4e8e\u673a\u5668\u4eba\u7cfb\u7edf\u5e94\u7528\uff0c\u81f4\u529b\u4e8e\u667a\u80fd\u7cfb\u7edf\u7814\u7a76\u201d \u7684\u5f00\u653e\u578b\u516c\u5171\u5b9e\u9a8c\u5ba4\u3002 \u4e91\u98de\u5b9e\u9a8c\u5ba4\u7684\u5b97\u65e8\u662f\uff1a \u201c\u8ba9\u673a\u5668\u5145\u6ee1\u667a\u6167\u201d \uff0c\u65e8\u5728\u5229\u7528\u673a\u5668\u4eba\u548c\u5d4c\u5165\u5f0f\u6280\u672f\u6539\u53d8\u4eba\u7c7b\u7684\u751f\u6d3b\u65b9\u5f0f\u3002\u5b9e\u9a8c\u5ba4\u5341\u5e74\u4e13\u6ce8\u4e8e\u673a\u5668\u4eba\u76f8\u5173\u9886\u57df\uff0c\u5305\u62ec\u673a\u5668\u4eba\u8bbe\u8ba1\u3001\u673a\u5668\u4eba\u5b89\u5168\u3001\u673a\u5668\u4eba\u6559\u80b2\u3001\u673a\u5668\u4eba\u7cfb\u7edf\u4e0e\u4eff\u771f\u3001\u5d4c\u5165\u5f0f\u5b9e\u65f6\u7cfb\u7edf\u3001\u673a\u5668\u4eba\u7f16\u7a0b\u8bed\u8a00\u7b49\u3002 \u5b9e\u9a8c\u5ba4\u4eba\u5458\u53c2\u4e0e\u7684\u7814\u7a76\u9886\u57df\u5305\u62ec\uff1a\u673a\u5668\u4eba\u5efa\u6a21\u4e0e\u4f18\u5316\u3001\u5b9e\u65f6\u7cfb\u7edf\u8c03\u5ea6\u4e0e\u901a\u4fe1\u3001\u81ea\u4e3b\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u5206\u6790\u3001SLAM\u3001\u89c6\u89c9\u4e09\u7ef4\u5efa\u6a21\u3001\u5f3a\u5316\u4e0e\u8fc1\u79fb\u5b66\u4e60\u3001\u81ea\u52a8\u9a7e\u9a76\u8bbe\u8ba1\u4e0e\u4eff\u771f\u9a8c\u8bc1\u7b49\u3002 \u5b9e\u9a8c\u5ba4\u7684\u4e3b\u8981\u76ee\u6807\u4e0e\u670d\u52a1\u6709\uff1a \u5efa\u8bbe\u673a\u5668\u4eba\u751f\u6001\u793e\u533a \u63d0\u4f9b\u673a\u5668\u4eba\u7684\u7814\u7a76\u52a8\u5411 \u63d0\u4f9b\u673a\u5668\u4eba\u6280\u672f\u6587\u7ae0\u4e0e\u6df1\u5ea6\u5185\u5bb9 \u63d0\u4f9b\u673a\u5668\u4eba\u7684\u516c\u5171\u77e5\u8bc6\u7ef4\u57fa\u5e93 \u4e91\u98de\u673a\u5668\u4eba\u5b9e\u9a8c\u5ba4\u662f\u5f00\u653e\u793e\u533a\u5b9e\u9a8c\u5ba4\u3002\u6b22\u8fce\u4e0e\u6211\u4eec\u6709\u5171\u540c\u7406\u5ff5\u548c\u613f\u666f\u7684\u6709\u5fd7\u4e4b\u58eb\u53c2\u4e0e\u6211\u4eec\u7684\u5de5\u4f5c\uff0c\u4e00\u8d77\u6784\u5efa\u6743\u5a01\u3001\u9886\u5148\u7684\u673a\u5668\u4eba\u751f\u6001\u793e\u533a\u3002 \u673a\u5668\u4eba\u6b63\u5728\u8d8a\u6765\u8d8a\u63a5\u8fd1\u6211\u4eec\u7684\u751f\u6d3b\uff1a\u81ea\u52a8\u9a7e\u9a76\u3001\u5bb6\u7528\u670d\u52a1\u3001\u7269\u6d41\u8fd0\u8f93\u3001\u533b\u7597\u770b\u62a4\u3001AI\u52a9\u624b\u3001\u5bfc\u822a\u5bfc\u89c8\u3002\u6211\u4eec\u5e0c\u671b\u901a\u8fc7\u6211\u4eec\u7684\u52aa\u529b\u8ba9\u673a\u5668\u4eba\u6280\u672f\u5728\u5927\u4f17\u4e2d\u5f97\u5230\u8ba4\u77e5\u548c\u666e\u53ca\uff0c\u5e76\u901a\u8fc7\u5168\u7403\u673a\u5668\u4eba\u5f00\u53d1\u3001\u7814\u7a76\u4eba\u5458\u7684\u529b\u91cf\u548c\u5065\u5eb7\u7684\u5f00\u6e90\u751f\u6001\u94fe\u5b9e\u73b0\u66f4\u667a\u80fd\u3001\u66f4\u666e\u4e16\u4ee5\u53ca\u66f4\u5b89\u5168\u7684\u673a\u5668\u4eba\u7cfb\u7edf\u3002 \u6211\u4eec\u76f8\u4fe1\u672a\u6765\u662f\u673a\u5668\u4eba\u548c\u4eba\u5171\u751f\u7684\u4e16\u754c\u3002","title":"\u5173\u4e8e \u4e91\u98de\u673a\u5668\u4eba\u5b9e\u9a8c\u5ba4"},{"location":"about/#_1","text":"\u4e91\u98de\u673a\u5668\u4eba\u5b9e\u9a8c\u5ba4\u662f\u4e00\u4e2a \u201c\u4e13\u6ce8\u4e8e\u673a\u5668\u4eba\u7cfb\u7edf\u5e94\u7528\uff0c\u81f4\u529b\u4e8e\u667a\u80fd\u7cfb\u7edf\u7814\u7a76\u201d \u7684\u5f00\u653e\u578b\u516c\u5171\u5b9e\u9a8c\u5ba4\u3002 \u4e91\u98de\u5b9e\u9a8c\u5ba4\u7684\u5b97\u65e8\u662f\uff1a \u201c\u8ba9\u673a\u5668\u5145\u6ee1\u667a\u6167\u201d \uff0c\u65e8\u5728\u5229\u7528\u673a\u5668\u4eba\u548c\u5d4c\u5165\u5f0f\u6280\u672f\u6539\u53d8\u4eba\u7c7b\u7684\u751f\u6d3b\u65b9\u5f0f\u3002\u5b9e\u9a8c\u5ba4\u5341\u5e74\u4e13\u6ce8\u4e8e\u673a\u5668\u4eba\u76f8\u5173\u9886\u57df\uff0c\u5305\u62ec\u673a\u5668\u4eba\u8bbe\u8ba1\u3001\u673a\u5668\u4eba\u5b89\u5168\u3001\u673a\u5668\u4eba\u6559\u80b2\u3001\u673a\u5668\u4eba\u7cfb\u7edf\u4e0e\u4eff\u771f\u3001\u5d4c\u5165\u5f0f\u5b9e\u65f6\u7cfb\u7edf\u3001\u673a\u5668\u4eba\u7f16\u7a0b\u8bed\u8a00\u7b49\u3002 \u5b9e\u9a8c\u5ba4\u4eba\u5458\u53c2\u4e0e\u7684\u7814\u7a76\u9886\u57df\u5305\u62ec\uff1a\u673a\u5668\u4eba\u5efa\u6a21\u4e0e\u4f18\u5316\u3001\u5b9e\u65f6\u7cfb\u7edf\u8c03\u5ea6\u4e0e\u901a\u4fe1\u3001\u81ea\u4e3b\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u5206\u6790\u3001SLAM\u3001\u89c6\u89c9\u4e09\u7ef4\u5efa\u6a21\u3001\u5f3a\u5316\u4e0e\u8fc1\u79fb\u5b66\u4e60\u3001\u81ea\u52a8\u9a7e\u9a76\u8bbe\u8ba1\u4e0e\u4eff\u771f\u9a8c\u8bc1\u7b49\u3002 \u5b9e\u9a8c\u5ba4\u7684\u4e3b\u8981\u76ee\u6807\u4e0e\u670d\u52a1\u6709\uff1a \u5efa\u8bbe\u673a\u5668\u4eba\u751f\u6001\u793e\u533a \u63d0\u4f9b\u673a\u5668\u4eba\u7684\u7814\u7a76\u52a8\u5411 \u63d0\u4f9b\u673a\u5668\u4eba\u6280\u672f\u6587\u7ae0\u4e0e\u6df1\u5ea6\u5185\u5bb9 \u63d0\u4f9b\u673a\u5668\u4eba\u7684\u516c\u5171\u77e5\u8bc6\u7ef4\u57fa\u5e93 \u4e91\u98de\u673a\u5668\u4eba\u5b9e\u9a8c\u5ba4\u662f\u5f00\u653e\u793e\u533a\u5b9e\u9a8c\u5ba4\u3002\u6b22\u8fce\u4e0e\u6211\u4eec\u6709\u5171\u540c\u7406\u5ff5\u548c\u613f\u666f\u7684\u6709\u5fd7\u4e4b\u58eb\u53c2\u4e0e\u6211\u4eec\u7684\u5de5\u4f5c\uff0c\u4e00\u8d77\u6784\u5efa\u6743\u5a01\u3001\u9886\u5148\u7684\u673a\u5668\u4eba\u751f\u6001\u793e\u533a\u3002 \u673a\u5668\u4eba\u6b63\u5728\u8d8a\u6765\u8d8a\u63a5\u8fd1\u6211\u4eec\u7684\u751f\u6d3b\uff1a\u81ea\u52a8\u9a7e\u9a76\u3001\u5bb6\u7528\u670d\u52a1\u3001\u7269\u6d41\u8fd0\u8f93\u3001\u533b\u7597\u770b\u62a4\u3001AI\u52a9\u624b\u3001\u5bfc\u822a\u5bfc\u89c8\u3002\u6211\u4eec\u5e0c\u671b\u901a\u8fc7\u6211\u4eec\u7684\u52aa\u529b\u8ba9\u673a\u5668\u4eba\u6280\u672f\u5728\u5927\u4f17\u4e2d\u5f97\u5230\u8ba4\u77e5\u548c\u666e\u53ca\uff0c\u5e76\u901a\u8fc7\u5168\u7403\u673a\u5668\u4eba\u5f00\u53d1\u3001\u7814\u7a76\u4eba\u5458\u7684\u529b\u91cf\u548c\u5065\u5eb7\u7684\u5f00\u6e90\u751f\u6001\u94fe\u5b9e\u73b0\u66f4\u667a\u80fd\u3001\u66f4\u666e\u4e16\u4ee5\u53ca\u66f4\u5b89\u5168\u7684\u673a\u5668\u4eba\u7cfb\u7edf\u3002 \u6211\u4eec\u76f8\u4fe1\u672a\u6765\u662f\u673a\u5668\u4eba\u548c\u4eba\u5171\u751f\u7684\u4e16\u754c\u3002","title":"\u5173\u4e8e \u4e91\u98de\u673a\u5668\u4eba\u5b9e\u9a8c\u5ba4"},{"location":"hardware/","text":"\u673a\u5668\u4eba\u786c\u4ef6\u5e73\u53f0 \u673a\u5668\u4eba\u5f00\u53d1\u4e2d\u5e38\u7528\u7684\u786c\u4ef6\u5e73\u53f0\u6709\uff1a Arduino (AVR) \u6811\u8393\u6d3e (ARM Cortex-A) Nvidia Jetson\u7cfb\u5217 (ARM Cortex-A + GPU) \u57fa\u4e8eSTM32\u7684\u673a\u5668\u4eba\u63a7\u5236\u5668 \u57fa\u4e8e\u5de5\u63a7\u673a (Intel Atom / Intel x86 / Intel x64)","title":"\u673a\u5668\u4eba\u786c\u4ef6\u5e73\u53f0"},{"location":"hardware/#_1","text":"\u673a\u5668\u4eba\u5f00\u53d1\u4e2d\u5e38\u7528\u7684\u786c\u4ef6\u5e73\u53f0\u6709\uff1a Arduino (AVR) \u6811\u8393\u6d3e (ARM Cortex-A) Nvidia Jetson\u7cfb\u5217 (ARM Cortex-A + GPU) \u57fa\u4e8eSTM32\u7684\u673a\u5668\u4eba\u63a7\u5236\u5668 \u57fa\u4e8e\u5de5\u63a7\u673a (Intel Atom / Intel x86 / Intel x64)","title":"\u673a\u5668\u4eba\u786c\u4ef6\u5e73\u53f0"},{"location":"how-to-contribute/","text":"\u5982\u4f55\u8d21\u732e\u8fd9\u4e2a\u7ef4\u57fa\uff1f \u8d21\u732e\u65b9\u6cd5 \u9879\u76eeGitHub\u5730\u5740 \u901a\u8fc7\u63d0\u4ea4\u4ee3\u7801\uff1agit clone -> change -> push & pull request \u901a\u8fc7\u521b\u5efaissue\uff1a Create a new issue \u73af\u5883\u914d\u7f6e\u4e0e\u8fd0\u884c sudo python3 -m pip install -r \"requirements.txt\" mkdocs --version mkdocs serve \u6253\u5f00\u6d4f\u89c8\u5668\uff0c\u8bbf\u95ee\uff1a localhost:8000 \u4e00\u4e9b\u7ec6\u8282 \u521b\u5efa\u65b0\u6761\u76ee \u5982\u679c\u4f60\u7684\u4fee\u6539\u6d89\u53ca\u65b0\u589e\u6761\u76ee\uff0c\u4f60\u9700\u8981\u540c\u65f6\u5728 mkdocs.yml \u4e2d\u4fee\u6539\u5bfc\u822a\u76ee\u5f55\u3002 \u56fe\u7247\u7684\u4fdd\u5b58 \u56fe\u7247\u4fdd\u5b58\u5728\u5bf9\u5e94\u5b50\u76ee\u5f55\u4e0b\u7684 assets \u76ee\u5f55\u4e2d\uff0c\u4f7f\u7528Github\u4f5c\u4e3a\u56fe\u5e8a\u3002","title":"\u5982\u4f55\u8d21\u732e\u8fd9\u4e2a\u7ef4\u57fa\uff1f"},{"location":"how-to-contribute/#_1","text":"","title":"\u5982\u4f55\u8d21\u732e\u8fd9\u4e2a\u7ef4\u57fa\uff1f"},{"location":"how-to-contribute/#_2","text":"\u9879\u76eeGitHub\u5730\u5740 \u901a\u8fc7\u63d0\u4ea4\u4ee3\u7801\uff1agit clone -> change -> push & pull request \u901a\u8fc7\u521b\u5efaissue\uff1a Create a new issue","title":"\u8d21\u732e\u65b9\u6cd5"},{"location":"how-to-contribute/#_3","text":"sudo python3 -m pip install -r \"requirements.txt\" mkdocs --version mkdocs serve \u6253\u5f00\u6d4f\u89c8\u5668\uff0c\u8bbf\u95ee\uff1a localhost:8000","title":"\u73af\u5883\u914d\u7f6e\u4e0e\u8fd0\u884c"},{"location":"how-to-contribute/#_4","text":"","title":"\u4e00\u4e9b\u7ec6\u8282"},{"location":"how-to-contribute/#_5","text":"\u5982\u679c\u4f60\u7684\u4fee\u6539\u6d89\u53ca\u65b0\u589e\u6761\u76ee\uff0c\u4f60\u9700\u8981\u540c\u65f6\u5728 mkdocs.yml \u4e2d\u4fee\u6539\u5bfc\u822a\u76ee\u5f55\u3002","title":"\u521b\u5efa\u65b0\u6761\u76ee"},{"location":"how-to-contribute/#_6","text":"\u56fe\u7247\u4fdd\u5b58\u5728\u5bf9\u5e94\u5b50\u76ee\u5f55\u4e0b\u7684 assets \u76ee\u5f55\u4e2d\uff0c\u4f7f\u7528Github\u4f5c\u4e3a\u56fe\u5e8a\u3002","title":"\u56fe\u7247\u7684\u4fdd\u5b58"},{"location":"how-to-start/","text":"\u5982\u4f55\u5165\u95e8\u673a\u5668\u4eba\uff1f \u8fd9\u662f\u521d\u5b66\u8005\u95ee\u7684\u6700\u591a\u7684\u95ee\u9898\uff0c\u4e5f\u662f\u8fd9\u4e2a\u7ef4\u57fa\u7684\u76ee\u7684 --- \u5e2e\u52a9\u521d\u5b66\u8005\u5165\u95e8\u673a\u5668\u4eba\u8bbe\u8ba1\u4e0e\u5f00\u53d1\u3002 (\u672c\u6761\u76ee\u9700\u8981\u5b8c\u5584\uff0c \u7acb\u523b\u53c2\u4e0e\u77e5\u8bc6\u516c\u5171\u7f16\u8f91 ) \u672c\u6761\u76ee\u8d21\u732e\u8005: automaticdai","title":"\u5982\u4f55\u5165\u95e8\u673a\u5668\u4eba\uff1f"},{"location":"how-to-start/#_1","text":"\u8fd9\u662f\u521d\u5b66\u8005\u95ee\u7684\u6700\u591a\u7684\u95ee\u9898\uff0c\u4e5f\u662f\u8fd9\u4e2a\u7ef4\u57fa\u7684\u76ee\u7684 --- \u5e2e\u52a9\u521d\u5b66\u8005\u5165\u95e8\u673a\u5668\u4eba\u8bbe\u8ba1\u4e0e\u5f00\u53d1\u3002 (\u672c\u6761\u76ee\u9700\u8981\u5b8c\u5584\uff0c \u7acb\u523b\u53c2\u4e0e\u77e5\u8bc6\u516c\u5171\u7f16\u8f91 ) \u672c\u6761\u76ee\u8d21\u732e\u8005: automaticdai","title":"\u5982\u4f55\u5165\u95e8\u673a\u5668\u4eba\uff1f"},{"location":"algorithm/","text":"\u673a\u5668\u4eba\u7b97\u6cd5 \u672c\u6761\u76ee\u5305\u542b\u673a\u5668\u4eba\u63a7\u5236\u4e0e\u611f\u77e5\u7b97\u6cd5 (\u89c6\u89c9\u4e0e\u673a\u5668\u5b66\u4e60\u76f8\u5173\u7684\u5185\u5bb9\u4e0d\u5305\u542b\u5728\u672c\u6761\u76ee\u4e2d)\uff0c\u5305\u62ec\uff1a \u8def\u5f84\u89c4\u5212 \u8f68\u8ff9\u89c4\u5212 \u8fd0\u52a8\u63a7\u5236 SLAM \u4f20\u611f\u5668\u6ee4\u6ce2\u7b97\u6cd5 \u4f20\u611f\u5668\u878d\u5408\u7b97\u6cd5 \u673a\u68b0\u81c2\u6b63\u89e3\u4e0e\u53cd\u89e3\u7b49\u3002 (\u672c\u6761\u76ee\u9700\u8981\u5b8c\u5584\uff0c \u7acb\u523b\u53c2\u4e0e\u77e5\u8bc6\u516c\u5171\u7f16\u8f91 ) \u672c\u6761\u76ee\u8d21\u732e\u8005: automaticdai","title":"\u673a\u5668\u4eba\u7b97\u6cd5"},{"location":"algorithm/#_1","text":"\u672c\u6761\u76ee\u5305\u542b\u673a\u5668\u4eba\u63a7\u5236\u4e0e\u611f\u77e5\u7b97\u6cd5 (\u89c6\u89c9\u4e0e\u673a\u5668\u5b66\u4e60\u76f8\u5173\u7684\u5185\u5bb9\u4e0d\u5305\u542b\u5728\u672c\u6761\u76ee\u4e2d)\uff0c\u5305\u62ec\uff1a \u8def\u5f84\u89c4\u5212 \u8f68\u8ff9\u89c4\u5212 \u8fd0\u52a8\u63a7\u5236 SLAM \u4f20\u611f\u5668\u6ee4\u6ce2\u7b97\u6cd5 \u4f20\u611f\u5668\u878d\u5408\u7b97\u6cd5 \u673a\u68b0\u81c2\u6b63\u89e3\u4e0e\u53cd\u89e3\u7b49\u3002 (\u672c\u6761\u76ee\u9700\u8981\u5b8c\u5584\uff0c \u7acb\u523b\u53c2\u4e0e\u77e5\u8bc6\u516c\u5171\u7f16\u8f91 ) \u672c\u6761\u76ee\u8d21\u732e\u8005: automaticdai","title":"\u673a\u5668\u4eba\u7b97\u6cd5"},{"location":"arduino/","text":"Arduino Arduino\u662f\u5168\u4e16\u754c\u4f7f\u7528\u6700\u5e7f\u6cdb\u7684\u5d4c\u5165\u5f0f\u8ba1\u7b97\u673a\uff0c\u88ab\u7528\u4e8e\u5927\u91cf\u7535\u5b50hacking\u3001\u4e92\u52a8\u5f0f\u827a\u672f\u4ee5\u53caDIY\u4f5c\u54c1\u4e2d\u3002 (\u672c\u6761\u76ee\u9700\u8981\u5b8c\u5584\uff0c \u7acb\u523b\u53c2\u4e0e\u77e5\u8bc6\u516c\u5171\u7f16\u8f91 ) \u672c\u6761\u76ee\u8d21\u732e\u8005: automaticdai","title":"Arduino"},{"location":"arduino/#arduino","text":"Arduino\u662f\u5168\u4e16\u754c\u4f7f\u7528\u6700\u5e7f\u6cdb\u7684\u5d4c\u5165\u5f0f\u8ba1\u7b97\u673a\uff0c\u88ab\u7528\u4e8e\u5927\u91cf\u7535\u5b50hacking\u3001\u4e92\u52a8\u5f0f\u827a\u672f\u4ee5\u53caDIY\u4f5c\u54c1\u4e2d\u3002 (\u672c\u6761\u76ee\u9700\u8981\u5b8c\u5584\uff0c \u7acb\u523b\u53c2\u4e0e\u77e5\u8bc6\u516c\u5171\u7f16\u8f91 ) \u672c\u6761\u76ee\u8d21\u732e\u8005: automaticdai","title":"Arduino"},{"location":"control/","text":"\u63a7\u5236\u7cfb\u7edf\u6307\u5357 \u672c\u9875\u9762\u76ee\u524d\u53ea\u6709\u82f1\u6587\u7248\uff0c\u7531\u6211(automaticdai)\u65e9\u671f\u6574\u7406\u800c\u6210\u3002\u6211\u4f1a\u9010\u6b65\u66f4\u6362\u4e3a\u4e2d\u6587\u8d44\u6599\uff0c\u540c\u65f6\u6b22\u8fce \u8d21\u732e\u8be5\u6761\u76ee \u3002 Control theory is an interdisciplinary branch of engineering and mathematics that deals with the behavior of dynamical systems with inputs, and how their behavior is modified by feedback [1]. The objective of control theory is to design a controller so that the system has some desired characteristics. Typical objectives are [2]: Stabilization Regulation Tracking Disturbance rejection Feedback Control Approach Establish control objectives Qualitative Quantitative: step response time Require understanding of expected commands, disturbances and bandwitdh Require understanding of physical dynamics and appropriate control method Select sensors and actuators What aspect to be sensed and controlled? Sensor noise, cost, reliability, size ... Obtain system model First principle or system identification Evaluation model -> reduce size and complexity Accuracy? Error model? Design controller SISO or MIMO? Classical or state-space? Choose parameters (rule-of-thumb or optimization) Analyze closed-loop performance Does closed loop meet objectives? Analysis, simulation, experimentation and iterate. Declaration This document includes basic descriptions and implementations of a Control System. The materials covered are: system modelling, controller design, classical control theory, modern control theory and C/Matlab/Simulink implementations. This wiki site is maintained by myself at an irregularly base. Contents might be inconsistent when I am working on them. Please use it with caution as I assume no other user than myself would be using this website. Reference Control Theory - Wikipedia, link Jonathan How, and Emilio Frazzoli. 16.30 Feedback Control Systems. Fall 2010. Massachusetts Institute of Technology: MIT OpenCourseWare, https://ocw.mit.edu. License: Creative Commons BY-NC-SA. \u672c\u6761\u76ee\u8d21\u732e\u8005: automaticdai","title":"\u63a7\u5236\u7cfb\u7edf\u6307\u5357"},{"location":"control/#_1","text":"\u672c\u9875\u9762\u76ee\u524d\u53ea\u6709\u82f1\u6587\u7248\uff0c\u7531\u6211(automaticdai)\u65e9\u671f\u6574\u7406\u800c\u6210\u3002\u6211\u4f1a\u9010\u6b65\u66f4\u6362\u4e3a\u4e2d\u6587\u8d44\u6599\uff0c\u540c\u65f6\u6b22\u8fce \u8d21\u732e\u8be5\u6761\u76ee \u3002 Control theory is an interdisciplinary branch of engineering and mathematics that deals with the behavior of dynamical systems with inputs, and how their behavior is modified by feedback [1]. The objective of control theory is to design a controller so that the system has some desired characteristics. Typical objectives are [2]: Stabilization Regulation Tracking Disturbance rejection","title":"\u63a7\u5236\u7cfb\u7edf\u6307\u5357"},{"location":"control/#feedback-control-approach","text":"Establish control objectives Qualitative Quantitative: step response time Require understanding of expected commands, disturbances and bandwitdh Require understanding of physical dynamics and appropriate control method Select sensors and actuators What aspect to be sensed and controlled? Sensor noise, cost, reliability, size ... Obtain system model First principle or system identification Evaluation model -> reduce size and complexity Accuracy? Error model? Design controller SISO or MIMO? Classical or state-space? Choose parameters (rule-of-thumb or optimization) Analyze closed-loop performance Does closed loop meet objectives? Analysis, simulation, experimentation and iterate.","title":"Feedback Control Approach"},{"location":"control/#declaration","text":"This document includes basic descriptions and implementations of a Control System. The materials covered are: system modelling, controller design, classical control theory, modern control theory and C/Matlab/Simulink implementations. This wiki site is maintained by myself at an irregularly base. Contents might be inconsistent when I am working on them. Please use it with caution as I assume no other user than myself would be using this website.","title":"Declaration"},{"location":"control/#reference","text":"Control Theory - Wikipedia, link Jonathan How, and Emilio Frazzoli. 16.30 Feedback Control Systems. Fall 2010. Massachusetts Institute of Technology: MIT OpenCourseWare, https://ocw.mit.edu. License: Creative Commons BY-NC-SA. \u672c\u6761\u76ee\u8d21\u732e\u8005: automaticdai","title":"Reference"},{"location":"control/analysis/","text":"Analysis Frequency Domain Analysis Gain margin Phase margin Time Domain Analysis Rising Time Peak Time Steady-state Time","title":"2. Analysis"},{"location":"control/analysis/#analysis","text":"","title":"Analysis"},{"location":"control/analysis/#frequency-domain-analysis","text":"Gain margin Phase margin","title":"Frequency Domain Analysis"},{"location":"control/analysis/#time-domain-analysis","text":"Rising Time Peak Time Steady-state Time","title":"Time Domain Analysis"},{"location":"control/mpc/","text":"MPC Generals MPC: regulatory controls using an explicit dynamic model of the response of process variables to changes in manipulated variables. obj = min(\\sum (y - y_{trajectory})^2) obj = min(\\sum (y - y_{trajectory})^2) basic version uses linear model. Can also be empirical model. advantages over PID: long time constants, substaintial time delays, inverse response, etc; multiple variables has constraints over process variables General characteristcs: targets (set points) selected by real-time optimization software based on current operating and economic conditions minimize square of deviations between predicted future outputs and specific reference trajectory to new targets handles MIMO control problems can include equality and inequality constraints on controlled and manipulated variables solves a nonlinear programming problem at each sampling instant disturbance is estimated by comparing the actual controlled variable with the model prediction usually implements the first move out of M M calculated moves MPC target trajectories Types: Funnel Trajectory Pure dead-band Referecen Trajectory Near-term vs. long-term objectives Response Target Response Speed Quadratic objective \\sum_{i=0}^p x_i^TQx_i + \\sum_{i=0}^{m-1} u_i^TRu_i \\sum_{i=0}^p x_i^TQx_i + \\sum_{i=0}^{m-1} u_i^TRu_i <span><span class=\"MathJax_Preview\">\\sum_{i=0}^p x_i^TQx_i + \\sum_{i=0}^{m-1} u_i^TRu_i</span><script type=\"math/tex\">\\sum_{i=0}^p x_i^TQx_i + \\sum_{i=0}^{m-1} u_i^TRu_i Details Impulse and step response models and the prediction equation Use of state estimation Optimization Infinite-horizon MPC and stability Use of nonlinear models","title":"4. MPC"},{"location":"control/mpc/#mpc","text":"","title":"MPC"},{"location":"control/mpc/#generals","text":"MPC: regulatory controls using an explicit dynamic model of the response of process variables to changes in manipulated variables. obj = min(\\sum (y - y_{trajectory})^2) obj = min(\\sum (y - y_{trajectory})^2) basic version uses linear model. Can also be empirical model. advantages over PID: long time constants, substaintial time delays, inverse response, etc; multiple variables has constraints over process variables General characteristcs: targets (set points) selected by real-time optimization software based on current operating and economic conditions minimize square of deviations between predicted future outputs and specific reference trajectory to new targets handles MIMO control problems can include equality and inequality constraints on controlled and manipulated variables solves a nonlinear programming problem at each sampling instant disturbance is estimated by comparing the actual controlled variable with the model prediction usually implements the first move out of M M calculated moves MPC target trajectories Types: Funnel Trajectory Pure dead-band Referecen Trajectory Near-term vs. long-term objectives Response Target Response Speed Quadratic objective \\sum_{i=0}^p x_i^TQx_i + \\sum_{i=0}^{m-1} u_i^TRu_i \\sum_{i=0}^p x_i^TQx_i + \\sum_{i=0}^{m-1} u_i^TRu_i <span><span class=\"MathJax_Preview\">\\sum_{i=0}^p x_i^TQx_i + \\sum_{i=0}^{m-1} u_i^TRu_i</span><script type=\"math/tex\">\\sum_{i=0}^p x_i^TQx_i + \\sum_{i=0}^{m-1} u_i^TRu_i","title":"Generals"},{"location":"control/mpc/#details","text":"Impulse and step response models and the prediction equation Use of state estimation Optimization Infinite-horizon MPC and stability Use of nonlinear models","title":"Details"},{"location":"control/modelling/modelling/","text":"Modelling Overview A system can be described as one of the followings: Differential equation Difference Equation Transfer Function State Space Differential Equation \\begin{aligned} \\ddot{x} + \\dot{x} &= ax + b \\\\\\\\ y &= x \\end{aligned} \\begin{aligned} \\ddot{x} + \\dot{x} &= ax + b \\\\\\\\ y &= x \\end{aligned} Difference Equation x_{t} = ax_{t-1} + b x_{t} = ax_{t-1} + b Transfer Function Polynomial $$ Y(s) = \\frac{a_m s^m + ... + a_0}{b_n s^n + ... + b_0} $$ Poles and Zeros $$ Y(s) = K \\frac{(s-z_m)...(s-z_0)}{(s - p_n) ... (s-p_0)} $$ State Space \\begin{align} \\dot{x}(t) &= Ax(t) + Bu(t) \\\\\\\\ y(t) &= Cx(t) + Du(t) \\end{align} \\begin{align} \\dot{x}(t) &= Ax(t) + Bu(t) \\\\\\\\ y(t) &= Cx(t) + Du(t) \\end{align} x as the state vector, A as the system matrix (square, N x N for N states), B as the input matrix (N rows x 1 column for a single-input, single output (SISO) system, C as the output matrix (one row x N columns for a SISO system), D as the feedforward matrix (1 x 1 for a SISO system). (*) The poles of the transfer function are the eigenvalues of the system matrix A Matlab Code sys = ss(a,b,c,d) sys = ss(a,b,c,d,Ts) sys_ss = ss(sys) Matlab functions Transfer Function s = tf('s') feedback(G(s), H(s)) G = zpk(sys) G = zpk([1],[1],[1]) Poles and Zeros Find poles of a SISO or MIMO system: pole(sys) pzplot(sys) State Space System Analysis linearSystemAnalyzer(G,T1,T2) step(sys) Reference [1] http://ctms.engin.umich.edu/CTMS/index.php?example=InvertedPendulum&section=ControlDigital","title":"Modelling Overview"},{"location":"control/modelling/modelling/#modelling-overview","text":"A system can be described as one of the followings: Differential equation Difference Equation Transfer Function State Space","title":"Modelling Overview"},{"location":"control/modelling/modelling/#differential-equation","text":"\\begin{aligned} \\ddot{x} + \\dot{x} &= ax + b \\\\\\\\ y &= x \\end{aligned} \\begin{aligned} \\ddot{x} + \\dot{x} &= ax + b \\\\\\\\ y &= x \\end{aligned}","title":"Differential Equation"},{"location":"control/modelling/modelling/#difference-equation","text":"x_{t} = ax_{t-1} + b x_{t} = ax_{t-1} + b","title":"Difference Equation"},{"location":"control/modelling/modelling/#transfer-function","text":"Polynomial $$ Y(s) = \\frac{a_m s^m + ... + a_0}{b_n s^n + ... + b_0} $$ Poles and Zeros $$ Y(s) = K \\frac{(s-z_m)...(s-z_0)}{(s - p_n) ... (s-p_0)} $$","title":"Transfer Function"},{"location":"control/modelling/modelling/#state-space","text":"\\begin{align} \\dot{x}(t) &= Ax(t) + Bu(t) \\\\\\\\ y(t) &= Cx(t) + Du(t) \\end{align} \\begin{align} \\dot{x}(t) &= Ax(t) + Bu(t) \\\\\\\\ y(t) &= Cx(t) + Du(t) \\end{align} x as the state vector, A as the system matrix (square, N x N for N states), B as the input matrix (N rows x 1 column for a single-input, single output (SISO) system, C as the output matrix (one row x N columns for a SISO system), D as the feedforward matrix (1 x 1 for a SISO system). (*) The poles of the transfer function are the eigenvalues of the system matrix A","title":"State Space"},{"location":"control/modelling/modelling/#matlab-code","text":"sys = ss(a,b,c,d) sys = ss(a,b,c,d,Ts) sys_ss = ss(sys)","title":"Matlab Code"},{"location":"control/modelling/modelling/#matlab-functions","text":"","title":"Matlab functions"},{"location":"control/modelling/modelling/#transfer-function_1","text":"s = tf('s') feedback(G(s), H(s)) G = zpk(sys) G = zpk([1],[1],[1])","title":"Transfer Function"},{"location":"control/modelling/modelling/#poles-and-zeros","text":"Find poles of a SISO or MIMO system: pole(sys) pzplot(sys)","title":"Poles and Zeros"},{"location":"control/modelling/modelling/#state-space_1","text":"","title":"State Space"},{"location":"control/modelling/modelling/#system-analysis","text":"linearSystemAnalyzer(G,T1,T2) step(sys)","title":"System Analysis"},{"location":"control/modelling/modelling/#reference","text":"[1] http://ctms.engin.umich.edu/CTMS/index.php?example=InvertedPendulum&section=ControlDigital","title":"Reference"},{"location":"control/modelling/state_space/","text":"State Space State space model is in time domain and can describe both SISO and MIMO systems. Some advantages: Numerically simple, easy for computers. Transfer function only deals with input/output behavior, while state-space can assess internal features of the system. MIMO and system coupling Controller Design: Full-state feedback (pole placement) Observer / estimator design: estimating the system state from available measurements. Dynamic output feedback: combines these two with provable guarantees on stability and performance. Overall, state-space design process is more systematic than classical control design. Controllability Observability Calculate Gain For a SISO system, the transfer function can take the forms: H(s) = [C(sI-A)^{-1}B + D] H(s) = [C(sI-A)^{-1}B + D] and H(z) = [C(zI-A)^{-1}B + D] H(z) = [C(zI-A)^{-1}B + D] . The new input can be calculated as: $$ u(t) = r(t) - KX = r(t) - \\begin{pmatrix}k_1 & k_2 & k_3\\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{pmatrix} $$ This resulted in a new state equation for the closed-loop system: $$ \\frac{dx}{dt} = [A - BK]x - Br(t) $$ Matlab code for LQR A = sys_d . a ; B = sys_d . b ; C = sys_d . c ; D = sys_d . d ; Q = C '* C % state-cost matrix R = 1 ; % control-cost [ K ] = dlqr ( A , B , Q , R ) % control gain matrix Ac = [( A - B * K )]; Bc = [ B ]; Cc = [ C ]; Dc = [ D ]; states = { 'x' 'x_dot' 'phi' 'phi_dot' }; inputs = { 'r' }; outputs = { 'x' ; 'phi' }; sys_cl = ss ( Ac , Bc , Cc , Dc , Ts , 'statename' , states , 'inputname' , inputs , 'outputname' , outputs ); t = 0 : 0.01 : 5 ; r = 0.2 * ones ( size ( t )); [ y , t , x ]= lsim ( sys_cl , r , t ); [ AX , H1 , H2 ] = plotyy ( t , y (:, 1 ), t , y (:, 2 ), 'plot' ); set ( get ( AX ( 1 ), 'Ylabel' ), 'String' , 'cart position (m)' ) set ( get ( AX ( 2 ), 'Ylabel' ), 'String' , 'pendulum angle (radians)' ) title ( 'Step Response with Digital LQR Control' )","title":"State Space"},{"location":"control/modelling/state_space/#state-space","text":"State space model is in time domain and can describe both SISO and MIMO systems. Some advantages: Numerically simple, easy for computers. Transfer function only deals with input/output behavior, while state-space can assess internal features of the system. MIMO and system coupling Controller Design: Full-state feedback (pole placement) Observer / estimator design: estimating the system state from available measurements. Dynamic output feedback: combines these two with provable guarantees on stability and performance. Overall, state-space design process is more systematic than classical control design.","title":"State Space"},{"location":"control/modelling/state_space/#controllability","text":"","title":"Controllability"},{"location":"control/modelling/state_space/#observability","text":"","title":"Observability"},{"location":"control/modelling/state_space/#calculate-gain","text":"For a SISO system, the transfer function can take the forms: H(s) = [C(sI-A)^{-1}B + D] H(s) = [C(sI-A)^{-1}B + D] and H(z) = [C(zI-A)^{-1}B + D] H(z) = [C(zI-A)^{-1}B + D] . The new input can be calculated as: $$ u(t) = r(t) - KX = r(t) - \\begin{pmatrix}k_1 & k_2 & k_3\\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{pmatrix} $$ This resulted in a new state equation for the closed-loop system: $$ \\frac{dx}{dt} = [A - BK]x - Br(t) $$","title":"Calculate Gain"},{"location":"control/modelling/state_space/#matlab-code-for-lqr","text":"A = sys_d . a ; B = sys_d . b ; C = sys_d . c ; D = sys_d . d ; Q = C '* C % state-cost matrix R = 1 ; % control-cost [ K ] = dlqr ( A , B , Q , R ) % control gain matrix Ac = [( A - B * K )]; Bc = [ B ]; Cc = [ C ]; Dc = [ D ]; states = { 'x' 'x_dot' 'phi' 'phi_dot' }; inputs = { 'r' }; outputs = { 'x' ; 'phi' }; sys_cl = ss ( Ac , Bc , Cc , Dc , Ts , 'statename' , states , 'inputname' , inputs , 'outputname' , outputs ); t = 0 : 0.01 : 5 ; r = 0.2 * ones ( size ( t )); [ y , t , x ]= lsim ( sys_cl , r , t ); [ AX , H1 , H2 ] = plotyy ( t , y (:, 1 ), t , y (:, 2 ), 'plot' ); set ( get ( AX ( 1 ), 'Ylabel' ), 'String' , 'cart position (m)' ) set ( get ( AX ( 2 ), 'Ylabel' ), 'String' , 'pendulum angle (radians)' ) title ( 'Step Response with Digital LQR Control' )","title":"Matlab code for LQR"},{"location":"control/pid/pid/","text":"PID Controller Formula u(t) = K_p e(t) + K_i \\int^t_0 e(\\tau) d\\tau + K_d \\frac{de(t)}{dt} u(t) = K_p e(t) + K_i \\int^t_0 e(\\tau) d\\tau + K_d \\frac{de(t)}{dt} The Laplace transform is: $$ L(s) = U(s)/E(s) = K_p + \\frac{K_i}{s} + K_d s $$ Discretization A control system is designed in continuous time, however a computer that running the control algorithm needs a digital implementation. Discretization is to convert a system from continuous to discrete time. Typical methods are: Forward difference: often for integration part. Backward difference: For the derivative part, it is often choose to have a backward difference to have a stable derivative (the result discrete parameters are often position, so no ringing effect). Tustin approximation. Implementation C code: float k_p = 0 ; float k_i = 0 ; float k_d = 0 ; float e_i = 0 ; /* integrated error */ float e_p = 0 ; /* previous error */ void pid_init ( float kp_ , float ki_ , float kd_ ) { k_p = kp_ ; k_i = ki_ ; k_d = kd_ ; e_i = 0 ; e_p = 0 ; } void pid_controller () { float y = adc_input (); float e = r - y ; e_i += e * dt ; float u = k_p * e + k_i * e_i + k_d * ( e - e_p ) / dt ; dac_output ( u ); e_p = e ; sleep ( dt ); }","title":"PID Controller"},{"location":"control/pid/pid/#pid-controller","text":"","title":"PID Controller"},{"location":"control/pid/pid/#formula","text":"u(t) = K_p e(t) + K_i \\int^t_0 e(\\tau) d\\tau + K_d \\frac{de(t)}{dt} u(t) = K_p e(t) + K_i \\int^t_0 e(\\tau) d\\tau + K_d \\frac{de(t)}{dt} The Laplace transform is: $$ L(s) = U(s)/E(s) = K_p + \\frac{K_i}{s} + K_d s $$","title":"Formula"},{"location":"control/pid/pid/#discretization","text":"A control system is designed in continuous time, however a computer that running the control algorithm needs a digital implementation. Discretization is to convert a system from continuous to discrete time. Typical methods are: Forward difference: often for integration part. Backward difference: For the derivative part, it is often choose to have a backward difference to have a stable derivative (the result discrete parameters are often position, so no ringing effect). Tustin approximation.","title":"Discretization"},{"location":"control/pid/pid/#implementation","text":"C code: float k_p = 0 ; float k_i = 0 ; float k_d = 0 ; float e_i = 0 ; /* integrated error */ float e_p = 0 ; /* previous error */ void pid_init ( float kp_ , float ki_ , float kd_ ) { k_p = kp_ ; k_i = ki_ ; k_d = kd_ ; e_i = 0 ; e_p = 0 ; } void pid_controller () { float y = adc_input (); float e = r - y ; e_i += e * dt ; float u = k_p * e + k_i * e_i + k_d * ( e - e_p ) / dt ; dac_output ( u ); e_p = e ; sleep ( dt ); }","title":"Implementation"},{"location":"control/pid/pid_improved/","text":"PID Improvement Techniques According to [1], a few improvements can be made to improve the so called Beginner's PID. The author of [1] wrote the PID library for Arduino. Here is a list of his advices: Sample Time - The PID algorithm functions best if it is evaluated at a regular interval. If the algorithm is aware of this interval, we can also simplify some of the internal math. Derivative Kick - Not the biggest deal, but easy to get rid of, so we\u2019re going to do just that. On-The-Fly Tuning Changes - A good PID algorithm is one where tuning parameters can be changed without jolting the internal workings. Reset Windup Mitigation - We\u2019ll go into what Reset Windup is, and implement a solution with side benefits On/Off (Auto/Manual) - In most applications, there is a desire to sometimes turn off the PID controller and adjust the output by hand, without the controller interfering Initialization - When the controller first turns on, we want a \u201cbumpless transfer.\u201d That is, we don\u2019t want the output to suddenly jerk to some new value Controller Direction - This last one isn\u2019t a change in the name of robustness per se. it\u2019s designed to ensure that the user enters tuning parameters with the correct sign In this section, I will follow his advices and rewrite my version of code to illustrate the main ideas. Fixed Sampling Time The first thing to make sure is the controller is called at a regular time interval. We can create a periodic control task, making use of ADC sampling interrupts, or we can use OS utilities to test if the specified sampling time has elapsed. With a fixed sampling time, we do not need to calculate the math related to dt dt every time, and we can incorporate dt dt into coefficients K_i K_i and K_d K_d : /* ... */ void pid_init ( float kp_ , float ki_ , float kd_ , float dt ){ k_p = kp_ ; k_i = ki_ * dt ; k_d = kd_ / dt ; /* ... */ } void pid_controller () { /* ... */ e_i += e ; float u = k_p * e + k_i * e_i + k_d * ( e - e_p ); /* ... */ } Derivative Kick Since error = set-point - input, any change in the set-point would cause an instantaneous change in error, especially for derivative as this change leads to a close-to-infinity large number. When this number is fed into the PID equation, the result will lead to an undesirable spike in the output. As \\dot{e} = \\dot{r} - \\dot{y} \\dot{e} = \\dot{r} - \\dot{y} , we can ignore the setpoint as constant, so \\frac{de}{dt} = -\\frac{dy}{dt} \\frac{de}{dt} = -\\frac{dy}{dt} . This leads to a \"Derivative on Measurement\" method. /* ... */ float y_p = 0 ; void pid_controller () { /* ... */ e_i += e ; float u = k_p * e + k_i * e_i + k_d * ( y - y_p ); /* ... */ y_p = y ; } Tuning Changes Changing PID parameters while the system is running may cause undesirable behaviors. The major change comes from the \"I\" term. The solution is simply multiply k_i every time instead of multiply it on the overall sum. This leads to a smooth solution without additional computation. /* ... */ float ITerm = 0 ; void pid_controller () { /* ... */ ITerm += k_i * e ; float u = k_p * e + ITerm + k_d * ( y - y_p ); /* ... */ } Reset Windup The problem of windup comes from the fact that there is limitations on the output that a PID controller can send. For example, for Arduino, the PWM output can only accept values from 0-255. If the output value reaches this range, the controller should stop increasing its output and stop accumulating integral error. If the controller is not aware its output is not the actual output, the output will saturate and will introduce lag when the setpoint drop back again. The C code after this step: /* ... */ float u_limit_upp = xxx ; float u_limit_low = xxx ; void pid_controller () { /* ... */ if ( pid_output_saturated ( u )) { pid_output_reset ( u ); /* roll back the I term */ ITerm -= k_i * e ; } /* ... */ } int pid_output_saturated ( float u ) { if ( u > u_limit_upp || u < u_limit_low ) { return 1 ; } else { return 0 ; } } int pid_output_reset ( float u ) { if ( u > u_limit_upp ) { u = u_limit_upp ; } else if ( u < u_limit_low ) { u = u_limit_low ; } } Switch On/off (In very rare situations), we may want to switch on/off a PID controller and manually feed control input to the process. This action may confuse the controller as it totally lose control of the output. The solution is simple, adding a on/off control variable to enable/disable the controller and stop changing its internal state variables. /* ... */ int pid_switch_on = 1 ; void pid_controller () { if ( pid_switch_on == 0 ) { return ; } /* ... */ } void pid_switch ( int new_state ) { pid_switch_on = new_state ; } Initialization after Switch A side effect of using on/off control is that when the controller switches from off to on, an undesirable bump would appear. This is illustrated in the following diagram: To make the output smooth after switch back on the controller, we can reset the controller internal variables: \"P\": the proportional term does not rely on any past information, so it doesn't need any initilization, so P = 0. \"D\": set last_input = previous_input, so D = 0. \"I\": set ITerm = previous_output, so P + I + D = previous_output. The result controller has a smooth response after switch the controller back on: Reverse Control For some systems, the increasing in input will result decreasing in output. For example, an inceasing speed of a cooling fan will cause the temerature to go down. To handle these systems, we introduce a direction variable to address the difference between direct/reserve control. The only difference of reverse control is the sign of the PID parameters need to be negative instead of postive in the direct case. #define DIRECT_CONTROL (0) #define REVERSE_CONTROL (1) int direction = DIRECT_CONTROL ; void pid_init () { /* ... */ if ( direction == REVERSE_CONTROL ) { k_p = 0 - k_p ; k_i = 0 - k_i ; k_d = 0 - k_d ; } /* ... */ } void pid_setdir ( int d_ ) { direction = d_ ; } Other Improvements Input Filtering To avoid problems of high frequency measurement noise in the derivative part, a low-pass filter is added. U_D(s) = \\frac{K T_D s}{1 + s T_D / N}(\\gamma Y_{sp}(s) - Y(s)) U_D(s) = \\frac{K T_D s}{1 + s T_D / N}(\\gamma Y_{sp}(s) - Y(s)) \\gamma \\gamma is for set-point weighting, which can be interpreted as feedforward from the set point. Timing Compensation The I and D parts are dependent on the actual interval between two control actions. If the interval is inconsistent, we need to compensate them. Feedforward Reset Tiebacks I I term Saturation D D term Filtering Error Dead-zone Output Limitation Dead band Anti Windup Event-based PID [2] Event Detector (event-trigged) -> PID Controller (time-trigged) Event trig condition should have small complexity to compare with time-trigged controller: |e(t_k) - e(t_{s}) > e_{lim}| |e(t_k) - e(t_{s}) > e_{lim}| OR h_{act} > h_{max} h_{act} > h_{max} which implies the detector operates at the nominal sampling frequency but the PID calculation only performs when an event is detected. This algorithm, however, requires more calculations due to the fact that each time the PID coefficients need to be recalculated. It is important to filter the measurement noise properly and to set the error limit sufficiently large to avoid trigging control due to noise. References Improving the Beginner\u2019s PID, web page link \u00c5rz\u00e9n, K-E. (1999), A Simple Event-Based PID Controller, Paper presented at 14th IFAC World Congress (1999), Beijing, China.","title":"PID Improvement Techniques"},{"location":"control/pid/pid_improved/#pid-improvement-techniques","text":"According to [1], a few improvements can be made to improve the so called Beginner's PID. The author of [1] wrote the PID library for Arduino. Here is a list of his advices: Sample Time - The PID algorithm functions best if it is evaluated at a regular interval. If the algorithm is aware of this interval, we can also simplify some of the internal math. Derivative Kick - Not the biggest deal, but easy to get rid of, so we\u2019re going to do just that. On-The-Fly Tuning Changes - A good PID algorithm is one where tuning parameters can be changed without jolting the internal workings. Reset Windup Mitigation - We\u2019ll go into what Reset Windup is, and implement a solution with side benefits On/Off (Auto/Manual) - In most applications, there is a desire to sometimes turn off the PID controller and adjust the output by hand, without the controller interfering Initialization - When the controller first turns on, we want a \u201cbumpless transfer.\u201d That is, we don\u2019t want the output to suddenly jerk to some new value Controller Direction - This last one isn\u2019t a change in the name of robustness per se. it\u2019s designed to ensure that the user enters tuning parameters with the correct sign In this section, I will follow his advices and rewrite my version of code to illustrate the main ideas.","title":"PID Improvement Techniques"},{"location":"control/pid/pid_improved/#fixed-sampling-time","text":"The first thing to make sure is the controller is called at a regular time interval. We can create a periodic control task, making use of ADC sampling interrupts, or we can use OS utilities to test if the specified sampling time has elapsed. With a fixed sampling time, we do not need to calculate the math related to dt dt every time, and we can incorporate dt dt into coefficients K_i K_i and K_d K_d : /* ... */ void pid_init ( float kp_ , float ki_ , float kd_ , float dt ){ k_p = kp_ ; k_i = ki_ * dt ; k_d = kd_ / dt ; /* ... */ } void pid_controller () { /* ... */ e_i += e ; float u = k_p * e + k_i * e_i + k_d * ( e - e_p ); /* ... */ }","title":"Fixed Sampling Time"},{"location":"control/pid/pid_improved/#derivative-kick","text":"Since error = set-point - input, any change in the set-point would cause an instantaneous change in error, especially for derivative as this change leads to a close-to-infinity large number. When this number is fed into the PID equation, the result will lead to an undesirable spike in the output. As \\dot{e} = \\dot{r} - \\dot{y} \\dot{e} = \\dot{r} - \\dot{y} , we can ignore the setpoint as constant, so \\frac{de}{dt} = -\\frac{dy}{dt} \\frac{de}{dt} = -\\frac{dy}{dt} . This leads to a \"Derivative on Measurement\" method. /* ... */ float y_p = 0 ; void pid_controller () { /* ... */ e_i += e ; float u = k_p * e + k_i * e_i + k_d * ( y - y_p ); /* ... */ y_p = y ; }","title":"Derivative Kick"},{"location":"control/pid/pid_improved/#tuning-changes","text":"Changing PID parameters while the system is running may cause undesirable behaviors. The major change comes from the \"I\" term. The solution is simply multiply k_i every time instead of multiply it on the overall sum. This leads to a smooth solution without additional computation. /* ... */ float ITerm = 0 ; void pid_controller () { /* ... */ ITerm += k_i * e ; float u = k_p * e + ITerm + k_d * ( y - y_p ); /* ... */ }","title":"Tuning Changes"},{"location":"control/pid/pid_improved/#reset-windup","text":"The problem of windup comes from the fact that there is limitations on the output that a PID controller can send. For example, for Arduino, the PWM output can only accept values from 0-255. If the output value reaches this range, the controller should stop increasing its output and stop accumulating integral error. If the controller is not aware its output is not the actual output, the output will saturate and will introduce lag when the setpoint drop back again. The C code after this step: /* ... */ float u_limit_upp = xxx ; float u_limit_low = xxx ; void pid_controller () { /* ... */ if ( pid_output_saturated ( u )) { pid_output_reset ( u ); /* roll back the I term */ ITerm -= k_i * e ; } /* ... */ } int pid_output_saturated ( float u ) { if ( u > u_limit_upp || u < u_limit_low ) { return 1 ; } else { return 0 ; } } int pid_output_reset ( float u ) { if ( u > u_limit_upp ) { u = u_limit_upp ; } else if ( u < u_limit_low ) { u = u_limit_low ; } }","title":"Reset Windup"},{"location":"control/pid/pid_improved/#switch-onoff","text":"(In very rare situations), we may want to switch on/off a PID controller and manually feed control input to the process. This action may confuse the controller as it totally lose control of the output. The solution is simple, adding a on/off control variable to enable/disable the controller and stop changing its internal state variables. /* ... */ int pid_switch_on = 1 ; void pid_controller () { if ( pid_switch_on == 0 ) { return ; } /* ... */ } void pid_switch ( int new_state ) { pid_switch_on = new_state ; }","title":"Switch On/off"},{"location":"control/pid/pid_improved/#initialization-after-switch","text":"A side effect of using on/off control is that when the controller switches from off to on, an undesirable bump would appear. This is illustrated in the following diagram: To make the output smooth after switch back on the controller, we can reset the controller internal variables: \"P\": the proportional term does not rely on any past information, so it doesn't need any initilization, so P = 0. \"D\": set last_input = previous_input, so D = 0. \"I\": set ITerm = previous_output, so P + I + D = previous_output. The result controller has a smooth response after switch the controller back on:","title":"Initialization after Switch"},{"location":"control/pid/pid_improved/#reverse-control","text":"For some systems, the increasing in input will result decreasing in output. For example, an inceasing speed of a cooling fan will cause the temerature to go down. To handle these systems, we introduce a direction variable to address the difference between direct/reserve control. The only difference of reverse control is the sign of the PID parameters need to be negative instead of postive in the direct case. #define DIRECT_CONTROL (0) #define REVERSE_CONTROL (1) int direction = DIRECT_CONTROL ; void pid_init () { /* ... */ if ( direction == REVERSE_CONTROL ) { k_p = 0 - k_p ; k_i = 0 - k_i ; k_d = 0 - k_d ; } /* ... */ } void pid_setdir ( int d_ ) { direction = d_ ; }","title":"Reverse Control"},{"location":"control/pid/pid_improved/#other-improvements","text":"","title":"Other Improvements"},{"location":"control/pid/pid_improved/#input-filtering","text":"To avoid problems of high frequency measurement noise in the derivative part, a low-pass filter is added. U_D(s) = \\frac{K T_D s}{1 + s T_D / N}(\\gamma Y_{sp}(s) - Y(s)) U_D(s) = \\frac{K T_D s}{1 + s T_D / N}(\\gamma Y_{sp}(s) - Y(s)) \\gamma \\gamma is for set-point weighting, which can be interpreted as feedforward from the set point.","title":"Input Filtering"},{"location":"control/pid/pid_improved/#timing-compensation","text":"The I and D parts are dependent on the actual interval between two control actions. If the interval is inconsistent, we need to compensate them.","title":"Timing Compensation"},{"location":"control/pid/pid_improved/#feedforward","text":"","title":"Feedforward"},{"location":"control/pid/pid_improved/#reset-tiebacks","text":"","title":"Reset Tiebacks"},{"location":"control/pid/pid_improved/#ii-term-saturation","text":"","title":"II term Saturation"},{"location":"control/pid/pid_improved/#dd-term-filtering","text":"","title":"DD term Filtering"},{"location":"control/pid/pid_improved/#error-dead-zone","text":"","title":"Error Dead-zone"},{"location":"control/pid/pid_improved/#output-limitation","text":"","title":"Output Limitation"},{"location":"control/pid/pid_improved/#dead-band","text":"","title":"Dead band"},{"location":"control/pid/pid_improved/#anti-windup","text":"","title":"Anti Windup"},{"location":"control/pid/pid_improved/#event-based-pid-2","text":"Event Detector (event-trigged) -> PID Controller (time-trigged) Event trig condition should have small complexity to compare with time-trigged controller: |e(t_k) - e(t_{s}) > e_{lim}| |e(t_k) - e(t_{s}) > e_{lim}| OR h_{act} > h_{max} h_{act} > h_{max} which implies the detector operates at the nominal sampling frequency but the PID calculation only performs when an event is detected. This algorithm, however, requires more calculations due to the fact that each time the PID coefficients need to be recalculated. It is important to filter the measurement noise properly and to set the error limit sufficiently large to avoid trigging control due to noise.","title":"Event-based PID [2]"},{"location":"control/pid/pid_improved/#references","text":"Improving the Beginner\u2019s PID, web page link \u00c5rz\u00e9n, K-E. (1999), A Simple Event-Based PID Controller, Paper presented at 14th IFAC World Congress (1999), Beijing, China.","title":"References"},{"location":"control/pid/pid_tuning/","text":"PID Parameters Tuning Ziegler-Nichols Tuning Reaction Curve Tuning","title":"PID Parameters Tuning"},{"location":"control/pid/pid_tuning/#pid-parameters-tuning","text":"Ziegler-Nichols Tuning Reaction Curve Tuning","title":"PID Parameters Tuning"},{"location":"cv/","text":"\u673a\u5668\u89c6\u89c9\u6982\u8ff0 (\u672c\u6761\u76ee\u9700\u8981\u5b8c\u5584\uff0c \u7acb\u523b\u53c2\u4e0e\u77e5\u8bc6\u516c\u5171\u7f16\u8f91 ) \u672c\u6761\u76ee\u8d21\u732e\u8005: automaticdai","title":"\u673a\u5668\u89c6\u89c9\u6982\u8ff0"},{"location":"cv/#_1","text":"(\u672c\u6761\u76ee\u9700\u8981\u5b8c\u5584\uff0c \u7acb\u523b\u53c2\u4e0e\u77e5\u8bc6\u516c\u5171\u7f16\u8f91 ) \u672c\u6761\u76ee\u8d21\u732e\u8005: automaticdai","title":"\u673a\u5668\u89c6\u89c9\u6982\u8ff0"},{"location":"cv/faster-rcnn/","text":"Faster R-CNN Faster R-CNN\u5c06Fast R-CNN\u4e2d\u7684Selective Search\u6362\u6210\u4e86Region Proposal Network\uff0c\u8fd9\u6837\u4f4d\u7f6e\u7f51\u7edc\u5c31\u548c\u5206\u7c7b\u7f51\u7edc\u7ed3\u5408\u8d77\u6765\uff0c \u4e8e\u662fCNN\u63d0\u53d6\u7684\u7279\u5f81feature maps\u88ab\u4e24\u8005\u5171\u7528 \uff0c\u4e0d\u4ec5\u6781\u5927\u52a0\u5feb\u4e86\u901f\u5ea6\uff0c\u8fd8\u63d0\u5347\u4e86\u7cbe\u5ea6\uff08\u4e24\u8005\u4f1a\u4e92\u76f8\u4fc3\u8fdb\uff09\u3002 Faster R-CNN\u7684\u8bad\u7ec3\u8fc7\u7a0b\uff1a \u63d0\u53d6\u56fe\u7247features \u521b\u5efa\u76ee\u6807anchors RPN\u7f51\u7edc\u8f93\u51fa\u8fd9\u4e9banchors\u7684locations\u548cobjectness\u5206\u6570 \u53d6locations\u548cobjectness\u5206\u6570\u6700\u597d\u7684\u524dN\u4e2aanchors\uff0c\u53c8\u79f0\u4e3aproposal layer \u5c06\u8fd9N\u4e2aanchors\u8f93\u5165\u7f51\u7edc\uff0c\u53d6\u5f97\u66f4\u7cbe\u786e\u7684locations\u5f97\u5206\u548cclassification\u5f97\u5206 \u8ba1\u7b97\u6b65\u9aa43\u4e2d\u7684 rpn_cls_loss \u548c rpn_reg_loss \u7cbe\u7b97\u6b65\u9aa45\u4e2d\u7684 roi_cls_loss \u548c roi_reg_loss 1. Input \u6211\u4eec\u7528PyTorch\u5b98\u65b9\u5b9e\u73b0\u7684Faster R-CNN\u7f51\u7edc\u6765\u5b66\u4e60\uff0c\u8bba\u6587\u4e2d\u4f7f\u7528\u63d0\u53d6features\u7684backbone\u7f51\u7edc\u662fVGG\uff0cPyTorch\u4f18\u5316\u4f7f\u7528\u4e86ResNet-50\u5e76\u7ed3\u5408\u4e86FPN\uff0c\u6211\u4eec\u5148\u770b\u4e0b\u7b2c\u4e00\u5c42 transform \uff1a # get the pretrained model from torchvision.models # Note: pretrained=True will get the pretrained weights for the model. # model.eval() to use the model for inference model = torchvision . models . detection . fasterrcnn_resnet50_fpn ( pretrained = False ) model . eval () list ( model . _modules . items ())[ 0 ] \u53ef\u4ee5\u770b\u51fa\u5148\u5bf9\u6570\u636e\u505a\u4e86\u5f52\u4e00\u5316 Normalize \uff0c\u7136\u540e\u8c03\u6574\u56fe\u7247\u5927\u5c0f\uff08\u7b49\u6bd4\u7f29\u653e\uff09\uff0c\u5728\u4fdd\u8bc1\u6700\u957f\u8fb9\u4e0d\u8d85\u8fc7 1333 \u60c5\u51b5\u4e0b\uff0c\u6700\u77ed\u8fb9\u7f29\u653e\u5230 800 \uff1a def resize ( image , min_size = 800 , max_size = 1333 ): im_shape = torch . tensor ( image . shape [ - 2 :]) min_s = float ( torch . min ( im_shape )) max_s = float ( torch . max ( im_shape )) scale_factor = min_size / min_s if max_s * scale_factor & gt ; max_size : scale_factor = max_size / max_s return ( torch . nn . functional . interpolate ( image [ None ], scale_factor = scale_factor , mode = 'bilinear' , recompute_scale_factor = True , align_corners = False )[ 0 ]) image = torch . rand ( 3 , 200 , 300 ) # get some dummy image resize ( image ) . shape \u4fdd\u8bc1\u8f93\u5165\u56fe\u7247\u6700\u957f\u8fb9\u4e0d\u8d85\u8fc7 1333 \uff0c\u907f\u514d\u5185\u5b58\u7206\u70b8\uff1a image = torch . rand ( 3 , 3000 , 1300 ) # get some dummy image print ( resize ( image ) . shape ) del image , model 2. Feature Extraction Faster R-CNN\u7f51\u7edc\u4e3b\u8981\u6709\u4e09\u4e2a\u90e8\u5206\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u5206\u522b\u4e3a feature extraction \u3001 region proposal \u548c predication \uff1a 2.1 FPN \u6ce8\u610f\u4e0a\u56fe\u8bba\u6587\u4e2d\u7684 feature extraction \u4f7f\u7528\u7684backbone\u662fVGG\uff0cPyTorch\u5b98\u65b9\u7248\u672c\u4f7f\u7528\u4e86\u5e26FPN\u7684ResNet-50\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff0cResNet-50\u56db\u4e2a\u9636\u6bb5\u7684features\u90fd\u88ab\u4f7f\u7528\u4e86\u3002\u4f4e\u5c42\u7684\u7279\u5f81\u8bed\u4e49\u4fe1\u606f\u6bd4\u8f83\u5c11\uff0c\u4f46\u662f\u76ee\u6807\u4f4d\u7f6e\u51c6\u786e\uff1b\u9ad8\u5c42\u7684\u7279\u5f81\u8bed\u4e49\u4fe1\u606f\u6bd4\u8f83\u4e30\u5bcc\uff0c\u4f46\u662f\u76ee\u6807\u4f4d\u7f6e\u6bd4\u8f83\u7c97\u7565\u3002\u5c06\u4f4e\u5c42\u7684\u7279\u5f81\u548c\u9ad8\u5c42\u7684\u7279\u5f81\u878d\u5408\u8d77\u6765\uff0c\u6709\u5229\u4e8e\u7f51\u7edc\u6027\u80fd\u3002\u53e6\u5916\u76ee\u6807\u6846\u4f1a\u968f\u7740features\u51cf\u5c0f\u800c\u51cf\u5c0f\uff0c\u8fd9\u6837\u5728\u88ab\u7f29\u5c0f\u4e8632\u500d\u7684\u6700\u540e\u4e00\u5c42features\u4e0a\uff0c\u5c0f\u76ee\u6807\u5c31\u4f1a\u53d8\u5f97\u975e\u5e38\u5c0f\uff0c\u96be\u4ee5\u88ab\u68c0\u6d4b\u51fa\u6765\uff0c \u4e8e\u662f\u878d\u5408\u540e\u4e0d\u540c\u5c3a\u5ea6\u7684\u7279\u5f81\u8d1f\u8d23\u68c0\u6d4b\u4e0d\u540c\u5927\u5c0f\u7684\u7269\u4f53 \u3002 \u5982\u56fe\u6240\u793a\uff0c\u9ad8\u5c42\u7684\u7279\u5f81\u4f1a\u88ab\u653e\u59272\u500d\u540e\uff0c\u52a0\u4e0a\u7ecf\u8fc71x1\u5377\u79ef\u7684\u5e95\u5c42\u7279\u5f81\uff0c\u4e0b\u9762\u662f\u7ed3\u5408\u4e86FPN\u7684ResNet-50\u7684\u8f93\u51fa\uff1a from torchvision.models.detection.backbone_utils import resnet_fpn_backbone backbone = resnet_fpn_backbone ( 'resnet50' , pretrained = False ) x = torch . rand ( 1 , 3 , 800 , 800 ) # get some dummy image output = backbone ( x ) for k , v in output . items (): print ( 'features' , k , v . shape ) del x , output , backbone features 0/1/2/3 \u5206\u522b\u5bf9\u5e94\u56fe\u4e2d\u7684 P2/3/4/5 \uff0c\u63a5\u4e0b\u6765\u5c31\u9700\u8981\u5728\u8fd9\u4e9bfeatures\u4e0a\u9884\u6d4b\u539f\u56fe\u4e2d\u7684\u7269\u4f53\u3002 3 Region Proposal Network \u5982\u4e0a\u56fe\u6240\u793a\uff0c\u5047\u8bbebackbone\u7684 stride=4 \u6216\u8005\u8bf4\u539f\u56feImage\u88abdown sample\u4e864\u500d\uff0c\u7531\u4e8e\u591a\u6b21\u5377\u79ef\u64cd\u4f5c\uff0c feature_map \u4e2d\u4e00\u4e2acell\u7684\u611f\u53d7\u91ce\u8981\u8fdc\u5927\u4e8e\u5de6\u8fb9\u7684\u4e00\u4e2agrid\uff0c\u751a\u81f3\u80fd\u8fbe\u5230\u6574\u5e45\u56fe\u7684\u533a\u57df\u3002\u4e0a\u6587\u4e2d\u5e26FPN\u7684ResNet-50\u63d0\u4f9b\u4e864\u79cd\u5c3a\u5bf8\u7684feature maps\uff0c\u6211\u4eec\u53ef\u4ee5\u7528\u8fd9\u4e9bfeature maps\u4e2d\u7684cells\u6765\u9884\u6d4b\u539f\u56fe\u4e2d\u7684\u7269\u4f53\u3002 3.1 Anchors \u56e0\u4e3a\u7269\u4f53\u7684\u5f62\u72b6\u548c\u5927\u5c0f\u5404\u79cd\u5404\u6837\uff0c\u6240\u4ee5\u4e00\u4e2acell\u9700\u8981\u80fd\u591f\u9884\u6d4b\u5f62\u72b6\u548c\u5927\u5c0f\u4e0d\u540c\u7684\u7269\u4f53\uff08\u7269\u4f53\u4e2d\u5fc3\u9760\u8fd1cell\u4e2d\u5fc3\uff09\u3002\u5982\u679c\u76f4\u63a5\u8ba9\u7f51\u7edc\u5b66\u4e60\u5404\u79cd\u4e0d\u786e\u5b9a\u7684\u76ee\u6807\u6846\u4f1a\u5f88\u96be\uff0c\u6240\u4ee5\u6211\u4eec\u5bf9\u8fd9\u4e9bcells\u9884\u5148\u8bbe\u7f6e\u4e86\u4e00\u4e9banchors\uff0c\u8ba9cells\u57fa\u4e8e\u8fd9\u4e9banchors\u9884\u6d4b\u5927\u5c0f\u548c\u4f4d\u7f6e\u7684\u504f\u79fb\u91cf\u3002 \u8bbeanchors\u7684\u5927\u5c0f\u4e3a s s \uff0c\u5bbd\u9ad8\u6bd4\u4e3a r>0 r&gt;0 \uff0c\u90a3\u4e48anchors\u7684\u5bbd\u548c\u9ad8\u5206\u522b\u4e3a s/\\sqrt{r} s/\\sqrt{r} \u548c s\\sqrt{r} s\\sqrt{r} \u3002\u5982\u679c r r \u67093\u79cd\uff0c s s \u67092\u79cd\uff0c\u90a3\u4e48\u7ec4\u5408\u8d77\u6765\u80fd\u5f97\u52306\u79cd\u6846\uff1a ratio = [ 0.5 , 1 , 2 ] scale = [ 16. , 32. ] # [width, height] anchors = [[ s * np . sqrt ( 1 / r ), s * np . sqrt ( r )] for s in scale for r in ratio ] np . around ( anchors , 2 ) \u5047\u8bbe\u56fe\u50cf\u5927\u5c0f\u4e3a 64\\times 64 64\\times 64 \uff0c\u6211\u4eec\u770b\u4e0b\u4e0a\u97626\u79cdanchors\u753b\u5728\u4e2d\u5fc3\u7684\u6837\u5b50\uff1a from matplotlib.patches import Rectangle def plot_init_grid ( ax , w = 416 , h = 416 , grid = 13 ): ax . set_xticks ( np . arange ( 0 , w + 1 , w / grid )) ax . set_yticks ( np . arange ( 0 , h + 1 , h / grid )) ax . xaxis . tick_top () ax . set_aspect ( 'equal' ) plt . xlim ([ 0 , w ]) plt . ylim ([ 0 , h ]) ax . invert_yaxis () def plot_anchors ( cx , cy , anchors ): for w , h in anchors : xy = ( cx - w / 2. , cy - h / 2. ) rect = Rectangle ( xy , w , h , linewidth = 2 , fill = False , linestyle = '-.' , edgecolor = np . random . rand ( 3 ,)) ax . add_patch ( rect ) # \u56fe\u7247\u5c3a\u5bf8 img_w = 64 img_h = 64 cx = img_w / 2 cy = img_h / 2 plt . figure ( figsize = ( 6 , 6 )) ax = plt . gca () plot_init_grid ( ax , img_w , img_h , grid = 1 ) plt . plot ( cx , cy , '.r' , markersize = 24 ) plot_anchors ( cx , cy , anchors ) plt . show () \u6211\u4eec\u53ef\u4ee5\u8111\u8865\u4e00\u4e0bfeature maps\u7684\u6bcf\u4e2acell\u90fd\u6709\u9884\u5148\u8bbe\u5b9a\u7684anchors\uff0c\u4e8e\u662fRegion Proposal Network\uff08RPN\uff09\u5c31\u8981\u5bf9\u8fd9\u4e9banchors\u8fdb\u884c\u5904\u7406\u3002 \u8bad\u7ec3\u65f6\uff0c\u51e1\u662f\u8d8a\u8fc7\u56fe\u7247\u8fb9\u754c\uff08cross the boundary of the image\uff09\u7684anchors\u90fd\u88ab\u5ffd\u7565 \u6d4b\u8bd5\u65f6\uff0c\u8d8a\u8fc7\u8fb9\u754c\u7684anchors\u88ab\u622a\u65ad\u5728\u8fb9\u754c\u5904 3.2 RPN \u5982\u4e0b\u56fe\u6240\u793a\uff0c\u5047\u8bbe\u6bcf\u4e2acell\u6709 k k \u4e2aanchors\uff0c\u4e8e\u662fRPN\u8981\u5224\u65ad\u8fd9 k k \u4e2aanchors\u5426\u4e3a\u7269\u4f53\uff08\u5206\u7c7b\uff0cclassification layer\uff09\uff0c\u8fd8\u8981\u5224\u65ad\u51c6\u786e\u7684\u4f4d\u7f6e\u548c\u5f62\u72b6\uff08\u56de\u5f52\uff0cregression layer\uff09\uff0c\u5728\u8fd9\u4e4b\u524d\u5148\u505a\u4e00\u6b213x3\u5377\u79ef\u5f97\u5230channel\u6570\u4e3a256-d\u7684featuer maps\u3002 RPN\u7f51\u7edc\u4ee3\u7801\u5982\u4e0b\uff1a import torch.nn.functional as F class RPNHead ( nn . Module ): \"\"\" Adds a simple RPN Head with classification and regression heads Arguments: in_channels (int): number of channels of the input feature num_anchors (int): number of anchors to be predicted \"\"\" def __init__ ( self , in_channels , num_anchors ): super ( RPNHead , self ) . __init__ () self . conv = nn . Conv2d ( in_channels , in_channels , kernel_size = 3 , stride = 1 , padding = 1 ) self . cls_logits = nn . Conv2d ( in_channels , num_anchors , kernel_size = 1 , stride = 1 ) self . bbox_pred = nn . Conv2d ( in_channels , num_anchors * 4 , kernel_size = 1 , stride = 1 ) for layer in self . children (): torch . nn . init . normal_ ( layer . weight , std = 0.01 ) torch . nn . init . constant_ ( layer . bias , 0 ) def forward ( self , x ): # type: (List[Tensor]) -&gt; Tuple[List[Tensor], List[Tensor]] logits = [] bbox_reg = [] for feature in x : t = F . relu ( self . conv ( feature )) logits . append ( self . cls_logits ( t )) bbox_reg . append ( self . bbox_pred ( t )) return logits , bbox_reg \u7531\u4e8eFPN\u7684backbone\u4f1a\u8f93\u51fa\u591a\u7ec4feature maps\uff08\u5206\u522b\u4e3a stride=4/8/16/32 \uff09\uff0c\u6240\u4ee5 RPNHead \u7684 forward() \u9ed8\u8ba4\u8f93\u5165 x \u4e3aiteratble\u7c7b\u578b\u7684\uff0c\u4f8b\u5982 [fm_1/4, fm_1/8, fm_1/16, fm_1/32] \u3002\u6574\u4e2a\u8fc7\u7a0b\u5982\u4e0b\u56fe\u6240\u793a\uff08\u8bbe k=3 k=3 \uff09\uff1a \u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u8fd9\u91cc\u9ec4\u8272 scores \u7684 channels=3 \uff0c\u800c\u975e 2k=10 2k=10 \uff0c\u8fd9\u662f\u56e0\u4e3a\u662f\u5224\u65ad\u6846\u662f\u5426\u4e3a\u7269\u4f53\u7684\u5206\u7c7b\u51fd\u6570\u7528\u4e86\u903b\u8f91\u56de\u5f52\uff0c\u76f4\u63a5\u8f93\u51fa\u7684\u662flogit\u800c\u975e\u6982\u7387\uff0closs\u51fd\u6570\u7528\u4e86 binary_cross_entropy_with_logits \uff0c\u5e94\u8be5\u662f\u4e3a\u4e86\u4f18\u5316cross entropy\u548csigmoid\u7684\u8054\u5408\u6c42\u5bfc\uff08\u7c7b\u4f3csoftmax\u548ccorss entropy\u8054\u5408\u6c42\u5bfc\uff09\u3002\u5047\u8bbe w,h=32,c=10 w,h=32,c=10 \uff0c\u90a3\u4e48\u5bf9\u5e94\u7684\u4ee3\u7801\u4e3a\uff1a x = torch . rand ( 1 , 10 , 32 , 32 ) scores , coordinates = RPNHead ( 10 , 3 )([ x ]) print ( \"scores:\" , scores [ 0 ] . shape ) print ( \"coordinates:\" , coordinates [ 0 ] . shape ) del x , scores , coordinates 3.3 Bounding Box Regression \u73b0\u5728RPN\u9884\u6d4b\u7684\u7269\u4f53bounding box\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff0c x_a, y_a, w_a, h_a x_a, y_a, w_a, h_a \u662f\u67d0\u4e00\u4e2aanchor\uff0c x, y, w, h x, y, w, h \u662fRPN\u57fa\u4e8e\u8fd9\u4e2aanchor\u9884\u6d4b\u7684bbox\uff0c x^*, y^*, w^*, h^* x^*, y^*, w^*, h^* \u662f\u5bf9\u5e94\u76ee\u6807\u7684ground truth\u3002 \u90a3\u4e48\u5c06\u4e2d\u5fc3\u5750\u6807\u504f\u79fb\u91cf\u548c\u5bbd\u9ad8\u6bd4\u5206\u522b\u5f52\u4e00\u5316\u540e\u53ef\u4ee5\u5f97\u5230 t_x, t_y, t_w, t_h t_x, t_y, t_w, t_h \uff0c\u4e5f\u5c31\u662fRPN\u7f51\u7edc\u9700\u8981\u5b66\u4e60\u8f93\u51fa\u7684bbox\u4fe1\u606f\uff0c\u800c t_*, t_*, t_*, t_* t_*, t_*, t_*, t_* \u662fground truth\uff0c\u4e24\u8005\u7ed3\u5408\u53ef\u4ee5\u8ba1\u7b97\u51fabounding box regreesion\u5206\u652f\u7684loss\u3002 t_{\\mathrm{x}}=\\left(x-x_{\\mathrm{a}}\\right) / w_{\\mathrm{a}}, \\quad t_{\\mathrm{y}}=\\left(y-y_{\\mathrm{a}}\\right) / h_{\\mathrm{a}} t_{\\mathrm{x}}=\\left(x-x_{\\mathrm{a}}\\right) / w_{\\mathrm{a}}, \\quad t_{\\mathrm{y}}=\\left(y-y_{\\mathrm{a}}\\right) / h_{\\mathrm{a}} t_{\\mathrm{w}}=\\log \\left(w / w_{\\mathrm{a}}\\right), \\quad t_{\\mathrm{h}}=\\log \\left(h / h_{\\mathrm{a}}\\right) t_{\\mathrm{w}}=\\log \\left(w / w_{\\mathrm{a}}\\right), \\quad t_{\\mathrm{h}}=\\log \\left(h / h_{\\mathrm{a}}\\right) t_{\\mathrm{x}}^{\\*}=\\left(x^{*}-x_{\\mathrm{a}}\\right) / w_{\\mathrm{a}}, \\quad t_{\\mathrm{y}}^{\\*}=\\left(y^{\\*}-y_{\\mathrm{a}}\\right) / h_{\\mathrm{a}} t_{\\mathrm{x}}^{\\*}=\\left(x^{*}-x_{\\mathrm{a}}\\right) / w_{\\mathrm{a}}, \\quad t_{\\mathrm{y}}^{\\*}=\\left(y^{\\*}-y_{\\mathrm{a}}\\right) / h_{\\mathrm{a}} t_{\\mathrm{w}}^{\\*}=\\log \\left(w^{\\*} / w_{\\mathrm{a}}\\right), \\quad t_{\\mathrm{h}}^{\\*}=\\log \\left(h^{\\*} / h_{\\mathrm{a}}\\right) t_{\\mathrm{w}}^{\\*}=\\log \\left(w^{\\*} / w_{\\mathrm{a}}\\right), \\quad t_{\\mathrm{h}}^{\\*}=\\log \\left(h^{\\*} / h_{\\mathrm{a}}\\right) \u5206\u522b\u9664\u4ee5 w_a, h_a w_a, h_a \u8fdb\u884c\u5f52\u4e00\u5316\u5229\u4e8e\u7f51\u7edc\u5b66\u4e60\uff0c\u4f46\u662f\u4e3a\u4ec0\u4e48\u5bbd\u9ad8\u6bd4\u503c\u90fd\u52a0\u4e86\u4e00\u4e2alog\u51fd\u6570\u5462\uff1f \u56e0\u4e3a\u5bbd\u9ad8\u6bd4\u5fc5\u987b\u5927\u4e8e\u7b49\u4e8e0\uff0c\u6240\u4ee5\u53d8\u6210\u4e86\u4e00\u4e2a\u5e26\u7ea6\u675f\u7684\u4f18\u5316\u95ee\u9898\uff0c\u800c w/w_a=e^{t_w} w/w_a=e^{t_w} \u6052\u5927\u4e8e0\uff0c\u8fd9\u6837\u7f51\u7edc\u8f93\u51fa\u7684 t_w, t_h t_w, t_h \u5c31\u6ca1\u6709\u9650\u5236\u4e86\uff01\uff01\uff01 3.4 Training RPN anchors\u6839\u636e\u6709\u65e0\u7269\u4f53\u5206\u4e3a\u6b63\u6837\u672c\u548c\u8d1f\u6837\u672c\uff1a\u5982\u679c\u4e00\u4e2aanchor\u548c\u67d0\u4e00\u4e2agt\u6846\u7684IoU\u5927\u4e8e0.7\u5c31\u88ab\u8ba4\u4e3a\u662f\u6b63\u6837\u672c\uff0c\u5982\u679c\u7279\u6b8a\u60c5\u51b5\u4e0b\u67d0\u4e2agt\u6846\u6ca1\u6709\u4efb\u4f55\u4e00\u4e2aanchor\u4e0e\u4e4b\u5bf9\u5e94\uff0c\u5c31\u9009IoU\u6700\u9ad8\u7684\u90a3\u4e2aanchor\uff1b\u51e1\u662fIoU\u5c0f\u4e8e0.3\u7684\u90fd\u88ab\u8ba4\u4e3a\u662f\u8d1f\u6837\u672c\u3002 \u5c3d\u7ba1\u53ef\u4ee5\u6240\u6709\u7684\u6b63\u8d1f\u6837\u672c\u90fd\u53ef\u4ee5\u53c2\u4e0e\u8bad\u7ec3\uff0c\u4f46\u662f\u56e0\u4e3a\u56fe\u7247\u4e2d\u76ee\u6807\u4e2a\u6570\u6709\u9650\uff0c\u6240\u4ee5\u4f1a\u5bfc\u81f4\u5927\u591a\u6570anchors\u90fd\u662f\u8d1f\u6837\u672c\uff08\u80cc\u666f\uff09\u3002\u4f8b\u5982 k=9 k=9 \uff0cfeature maps\u7684 w=h=50 w=h=50 \u65f6\uff0canchors\u603b\u6570\u4e3a 9\\times 50 \\times50=22500 9\\times 50 \\times50=22500 \u4e2a\uff0c\u8fd9\u6837\u6b63\u8d1f\u6837\u672c\u5f88\u4e0d\u5e73\u8861\uff0c\u4e8e\u662f\u4f5c\u8005\u5728\u4e00\u5f20\u56fe\u4e2d\u968f\u673a\u5404\u9009\u53d6128\u4e2a\u6b63\u8d1f\u6837\u672c\u7ec4\u6210256\u4e2aanchors\u7684mini batch\u3002 RPN\u7f51\u7edc\u7684Loss\u51fd\u6570\u5982\u4e0b\uff0c N_{reg} N_{reg} \u53ea\u5305\u62ec p^*=1 p^*=1 \u7684\u6b63\u6837\u672c\uff1a L(\\{p_i\\},\\{t_{i}\\})=\\frac{1}{N_{cls}} \\sum_{i} L_{cls}\\left(p_i, p_{i}^{\\*}\\right)+\\lambda \\frac{1}{N_{reg}} \\sum_{i} p_{i}^{\\*} L_{reg}\\left(t_{i}, t_{i}^{\\*}\\right) L(\\{p_i\\},\\{t_{i}\\})=\\frac{1}{N_{cls}} \\sum_{i} L_{cls}\\left(p_i, p_{i}^{\\*}\\right)+\\lambda \\frac{1}{N_{reg}} \\sum_{i} p_{i}^{\\*} L_{reg}\\left(t_{i}, t_{i}^{\\*}\\right) 3.5 NMS \u56e0\u4e3aRPN\u8f93\u51fa\u7684\u76ee\u6807\u6846\u4f1a\u6709\u5f88\u591a\u91cd\u53e0\u7684\uff08\u5982\u4e0b\u56fe\u6240\u793a\uff09\uff0c\u6240\u4ee5\u6211\u4eec\u9700\u8981\u4f7f\u7528NMS\u8fdb\u884c\u8fc7\u6ee4\u3002 from matplotlib.patches import Rectangle def plt_boxes ( bboxes , ax ): \"\"\" matplotlib Rectangle --- (xy, w, h) \"\"\" for box in bboxes : x1 , y1 , x2 , y2 , _ = box w = x2 - x1 h = y2 - y1 ax . add_patch ( Rectangle (( x1 , y1 ), w , h , linewidth = 2 , fill = False , edgecolor = np . random . rand ( 3 ,))) plt . xlim ([ 0 , max ( bboxes [:, 2 ]) + 20 ]) plt . ylim ([ 0 , max ( bboxes [:, 3 ]) + 20 ]) ax . xaxis . tick_top () ax . invert_yaxis () # [x1, y1, x2, y2, score] dets = np . array ([[ 218 , 322 , 385 , 491 , 0.98 ], [ 247 , 312 , 419 , 461 , 0.83 ], [ 237 , 344 , 407 , 510 , 0.92 ], [ 757 , 218 , 937 , 394 , 0.96 ], [ 768 , 198 , 962 , 364 , 0.85 ], [ 740 , 240 , 906 , 414 , 0.83 ], [ 1101 , 84 , 1302 , 303 , 0.82 ], [ 1110 , 67 , 1331 , 260 , 0.97 ], [ 1123 , 42 , 1362 , 220 , 0.85 ]]) ax = plt . gca () plt_boxes ( dets , ax ) plt . show () \u9996\u5148\u6309\u7167\u5206\u7c7b\u5f97\u5206\u9ad8\u4f4e\u5c06\u6846\u6392\u5e8f\uff0c\u7136\u540e\u904d\u5386\uff08\u5df2\u5220\u9664\u7684\u4e0d\u518d\u904d\u5386\uff09\uff0c\u5220\u9664\u548c\u5f53\u524d\u6846 \\text{IoU}>\\text{threshold} \\text{IoU}&gt;\\text{threshold} \uff08\u8bba\u6587\u4e2d\u4e3a0.7\uff09\u7684\u6846\u3002 IoU\u7684\u516c\u5f0f\u548c\u793a\u610f\u56fe\u5982\u4e0b\uff1a J(\\mathcal{A}, \\mathcal{B})=\\frac{|\\mathcal{A} \\cap \\mathcal{B}|}{|\\mathcal{A} \\cup \\mathcal{B}|} J(\\mathcal{A}, \\mathcal{B})=\\frac{|\\mathcal{A} \\cap \\mathcal{B}|}{|\\mathcal{A} \\cup \\mathcal{B}|} def nms ( dets , thres ): \"\"\" @dets, detecion results, shape: [batch, 5], form: [[x1, y1, x2, y2, score]] @thres, threshold \"\"\" x1 = dets [:, 0 ] y1 = dets [:, 1 ] x2 = dets [:, 2 ] y2 = dets [:, 3 ] scores = dets [:, 4 ] area = ( x2 - x1 + 1 ) * ( y2 - y1 + 1 ) order = scores . argsort ()[:: - 1 ] kept_idx = [] while order . size & gt ; 0 : i = order [ 0 ] kept_idx . append ( i ) xx1 = np . maximum ( x1 [ i ], x1 [ order [ 1 :]]) yy1 = np . maximum ( y1 [ i ], y1 [ order [ 1 :]]) xx2 = np . minimum ( x2 [ i ], x2 [ order [ 1 :]]) yy2 = np . minimum ( y2 [ i ], y2 [ order [ 1 :]]) w = np . maximum ( 0.0 , xx2 - xx1 + 1 ) h = np . maximum ( 0.0 , yy2 - yy1 + 1 ) inter = w * h IoU = inter / ( area [ i ] + area [ order [ 1 :]] - inter ) inds = np . where ( IoU 0.7 \u7684\u4e3a\u6b63\u6837\u672c \uff0c threshold are chosen . \"\"\" img = Image.open(img_path) transform = T.Compose([T.ToTensor()]) img = transform(img) pred = model([img]) pred_class = [COCO_INSTANCE_CATEGORY_NAMES[i] for i in list(pred[0]['labels'].numpy())] pred_boxes = [[(i[0], i[1]), (i[2], i[3])] for i in list(pred[0]['boxes'].detach().numpy())] pred_score = list(pred[0]['scores'].detach().numpy()) pred_t = [pred_score.index(x) for x in pred_score if x&gt;threshold][-1] pred_boxes = pred_boxes[:pred_t+1] pred_class = pred_class[:pred_t+1] return pred_boxes, pred_class def object_detection_api(img_path, threshold=0.5, rect_th=3, text_size=3, text_th=3): \"\"\" object_detection_api parameters : - img_path - path of the input image - threshold - threshold value for prediction score - rect_th - thickness of bounding box - text_size - size of the class label text - text_th - thichness of the text method : - prediction is obtained from get_prediction method - for each prediction , bounding box is drawn and text is written with opencv - the final image is displayed \"\"\" boxes, pred_cls = get_prediction(img_path, threshold) img = cv2.imread(img_path) img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) for i in range(len(boxes)): cv2.rectangle(img, boxes[i][0], boxes[i][1],color=(0, 255, 0), thickness=rect_th) cv2.putText(img,pred_cls[i], boxes[i][0], cv2.FONT_HERSHEY_SIMPLEX, text_size, (0,255,0),thickness=text_th) plt.figure(figsize=(20,30)) plt.imshow(img) plt.xticks([]) plt.yticks([]) plt.show() object_detection_api ( \"../_files/people.jpg\" , threshold = 0.8 ) object_detection_api ( '../_files/traffic-143391_960_720.jpg' , threshold = 0.8 , text_size = 1 ) 4. \u63a8\u8350\u9605\u8bfb Faster R-CNN Object Detection with PyTorch \u634b\u4e00\u634bpytorch\u5b98\u65b9FasterRCNN\u4ee3\u7801 \u4e00\u6587\u8bfb\u61c2Faster RCNN Guide to build Faster RCNN in PyTorch \u53c2\u8003\u8d44\u6599\uff1a Yang Dawei, Faster R-CNN\u539f\u7406\u4e0e\u4f7f\u7528 (Pytorch) , \u4e91\u98de\u673a\u5668\u4eba\u5b9e\u9a8c\u5ba4 \u672c\u6761\u76ee\u8d21\u732e\u8005 \uff1a LinkHS","title":"Faster R-CNN"},{"location":"cv/faster-rcnn/#faster-r-cnn","text":"Faster R-CNN\u5c06Fast R-CNN\u4e2d\u7684Selective Search\u6362\u6210\u4e86Region Proposal Network\uff0c\u8fd9\u6837\u4f4d\u7f6e\u7f51\u7edc\u5c31\u548c\u5206\u7c7b\u7f51\u7edc\u7ed3\u5408\u8d77\u6765\uff0c \u4e8e\u662fCNN\u63d0\u53d6\u7684\u7279\u5f81feature maps\u88ab\u4e24\u8005\u5171\u7528 \uff0c\u4e0d\u4ec5\u6781\u5927\u52a0\u5feb\u4e86\u901f\u5ea6\uff0c\u8fd8\u63d0\u5347\u4e86\u7cbe\u5ea6\uff08\u4e24\u8005\u4f1a\u4e92\u76f8\u4fc3\u8fdb\uff09\u3002 Faster R-CNN\u7684\u8bad\u7ec3\u8fc7\u7a0b\uff1a \u63d0\u53d6\u56fe\u7247features \u521b\u5efa\u76ee\u6807anchors RPN\u7f51\u7edc\u8f93\u51fa\u8fd9\u4e9banchors\u7684locations\u548cobjectness\u5206\u6570 \u53d6locations\u548cobjectness\u5206\u6570\u6700\u597d\u7684\u524dN\u4e2aanchors\uff0c\u53c8\u79f0\u4e3aproposal layer \u5c06\u8fd9N\u4e2aanchors\u8f93\u5165\u7f51\u7edc\uff0c\u53d6\u5f97\u66f4\u7cbe\u786e\u7684locations\u5f97\u5206\u548cclassification\u5f97\u5206 \u8ba1\u7b97\u6b65\u9aa43\u4e2d\u7684 rpn_cls_loss \u548c rpn_reg_loss \u7cbe\u7b97\u6b65\u9aa45\u4e2d\u7684 roi_cls_loss \u548c roi_reg_loss","title":"Faster R-CNN"},{"location":"cv/faster-rcnn/#1-input","text":"\u6211\u4eec\u7528PyTorch\u5b98\u65b9\u5b9e\u73b0\u7684Faster R-CNN\u7f51\u7edc\u6765\u5b66\u4e60\uff0c\u8bba\u6587\u4e2d\u4f7f\u7528\u63d0\u53d6features\u7684backbone\u7f51\u7edc\u662fVGG\uff0cPyTorch\u4f18\u5316\u4f7f\u7528\u4e86ResNet-50\u5e76\u7ed3\u5408\u4e86FPN\uff0c\u6211\u4eec\u5148\u770b\u4e0b\u7b2c\u4e00\u5c42 transform \uff1a # get the pretrained model from torchvision.models # Note: pretrained=True will get the pretrained weights for the model. # model.eval() to use the model for inference model = torchvision . models . detection . fasterrcnn_resnet50_fpn ( pretrained = False ) model . eval () list ( model . _modules . items ())[ 0 ] \u53ef\u4ee5\u770b\u51fa\u5148\u5bf9\u6570\u636e\u505a\u4e86\u5f52\u4e00\u5316 Normalize \uff0c\u7136\u540e\u8c03\u6574\u56fe\u7247\u5927\u5c0f\uff08\u7b49\u6bd4\u7f29\u653e\uff09\uff0c\u5728\u4fdd\u8bc1\u6700\u957f\u8fb9\u4e0d\u8d85\u8fc7 1333 \u60c5\u51b5\u4e0b\uff0c\u6700\u77ed\u8fb9\u7f29\u653e\u5230 800 \uff1a def resize ( image , min_size = 800 , max_size = 1333 ): im_shape = torch . tensor ( image . shape [ - 2 :]) min_s = float ( torch . min ( im_shape )) max_s = float ( torch . max ( im_shape )) scale_factor = min_size / min_s if max_s * scale_factor & gt ; max_size : scale_factor = max_size / max_s return ( torch . nn . functional . interpolate ( image [ None ], scale_factor = scale_factor , mode = 'bilinear' , recompute_scale_factor = True , align_corners = False )[ 0 ]) image = torch . rand ( 3 , 200 , 300 ) # get some dummy image resize ( image ) . shape \u4fdd\u8bc1\u8f93\u5165\u56fe\u7247\u6700\u957f\u8fb9\u4e0d\u8d85\u8fc7 1333 \uff0c\u907f\u514d\u5185\u5b58\u7206\u70b8\uff1a image = torch . rand ( 3 , 3000 , 1300 ) # get some dummy image print ( resize ( image ) . shape ) del image , model","title":"1. Input"},{"location":"cv/faster-rcnn/#2-feature-extraction","text":"Faster R-CNN\u7f51\u7edc\u4e3b\u8981\u6709\u4e09\u4e2a\u90e8\u5206\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u5206\u522b\u4e3a feature extraction \u3001 region proposal \u548c predication \uff1a","title":"2. Feature Extraction"},{"location":"cv/faster-rcnn/#21-fpn","text":"\u6ce8\u610f\u4e0a\u56fe\u8bba\u6587\u4e2d\u7684 feature extraction \u4f7f\u7528\u7684backbone\u662fVGG\uff0cPyTorch\u5b98\u65b9\u7248\u672c\u4f7f\u7528\u4e86\u5e26FPN\u7684ResNet-50\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff0cResNet-50\u56db\u4e2a\u9636\u6bb5\u7684features\u90fd\u88ab\u4f7f\u7528\u4e86\u3002\u4f4e\u5c42\u7684\u7279\u5f81\u8bed\u4e49\u4fe1\u606f\u6bd4\u8f83\u5c11\uff0c\u4f46\u662f\u76ee\u6807\u4f4d\u7f6e\u51c6\u786e\uff1b\u9ad8\u5c42\u7684\u7279\u5f81\u8bed\u4e49\u4fe1\u606f\u6bd4\u8f83\u4e30\u5bcc\uff0c\u4f46\u662f\u76ee\u6807\u4f4d\u7f6e\u6bd4\u8f83\u7c97\u7565\u3002\u5c06\u4f4e\u5c42\u7684\u7279\u5f81\u548c\u9ad8\u5c42\u7684\u7279\u5f81\u878d\u5408\u8d77\u6765\uff0c\u6709\u5229\u4e8e\u7f51\u7edc\u6027\u80fd\u3002\u53e6\u5916\u76ee\u6807\u6846\u4f1a\u968f\u7740features\u51cf\u5c0f\u800c\u51cf\u5c0f\uff0c\u8fd9\u6837\u5728\u88ab\u7f29\u5c0f\u4e8632\u500d\u7684\u6700\u540e\u4e00\u5c42features\u4e0a\uff0c\u5c0f\u76ee\u6807\u5c31\u4f1a\u53d8\u5f97\u975e\u5e38\u5c0f\uff0c\u96be\u4ee5\u88ab\u68c0\u6d4b\u51fa\u6765\uff0c \u4e8e\u662f\u878d\u5408\u540e\u4e0d\u540c\u5c3a\u5ea6\u7684\u7279\u5f81\u8d1f\u8d23\u68c0\u6d4b\u4e0d\u540c\u5927\u5c0f\u7684\u7269\u4f53 \u3002 \u5982\u56fe\u6240\u793a\uff0c\u9ad8\u5c42\u7684\u7279\u5f81\u4f1a\u88ab\u653e\u59272\u500d\u540e\uff0c\u52a0\u4e0a\u7ecf\u8fc71x1\u5377\u79ef\u7684\u5e95\u5c42\u7279\u5f81\uff0c\u4e0b\u9762\u662f\u7ed3\u5408\u4e86FPN\u7684ResNet-50\u7684\u8f93\u51fa\uff1a from torchvision.models.detection.backbone_utils import resnet_fpn_backbone backbone = resnet_fpn_backbone ( 'resnet50' , pretrained = False ) x = torch . rand ( 1 , 3 , 800 , 800 ) # get some dummy image output = backbone ( x ) for k , v in output . items (): print ( 'features' , k , v . shape ) del x , output , backbone features 0/1/2/3 \u5206\u522b\u5bf9\u5e94\u56fe\u4e2d\u7684 P2/3/4/5 \uff0c\u63a5\u4e0b\u6765\u5c31\u9700\u8981\u5728\u8fd9\u4e9bfeatures\u4e0a\u9884\u6d4b\u539f\u56fe\u4e2d\u7684\u7269\u4f53\u3002","title":"2.1 FPN"},{"location":"cv/faster-rcnn/#3-region-proposal-network","text":"\u5982\u4e0a\u56fe\u6240\u793a\uff0c\u5047\u8bbebackbone\u7684 stride=4 \u6216\u8005\u8bf4\u539f\u56feImage\u88abdown sample\u4e864\u500d\uff0c\u7531\u4e8e\u591a\u6b21\u5377\u79ef\u64cd\u4f5c\uff0c feature_map \u4e2d\u4e00\u4e2acell\u7684\u611f\u53d7\u91ce\u8981\u8fdc\u5927\u4e8e\u5de6\u8fb9\u7684\u4e00\u4e2agrid\uff0c\u751a\u81f3\u80fd\u8fbe\u5230\u6574\u5e45\u56fe\u7684\u533a\u57df\u3002\u4e0a\u6587\u4e2d\u5e26FPN\u7684ResNet-50\u63d0\u4f9b\u4e864\u79cd\u5c3a\u5bf8\u7684feature maps\uff0c\u6211\u4eec\u53ef\u4ee5\u7528\u8fd9\u4e9bfeature maps\u4e2d\u7684cells\u6765\u9884\u6d4b\u539f\u56fe\u4e2d\u7684\u7269\u4f53\u3002","title":"3 Region Proposal Network"},{"location":"cv/faster-rcnn/#31-anchors","text":"\u56e0\u4e3a\u7269\u4f53\u7684\u5f62\u72b6\u548c\u5927\u5c0f\u5404\u79cd\u5404\u6837\uff0c\u6240\u4ee5\u4e00\u4e2acell\u9700\u8981\u80fd\u591f\u9884\u6d4b\u5f62\u72b6\u548c\u5927\u5c0f\u4e0d\u540c\u7684\u7269\u4f53\uff08\u7269\u4f53\u4e2d\u5fc3\u9760\u8fd1cell\u4e2d\u5fc3\uff09\u3002\u5982\u679c\u76f4\u63a5\u8ba9\u7f51\u7edc\u5b66\u4e60\u5404\u79cd\u4e0d\u786e\u5b9a\u7684\u76ee\u6807\u6846\u4f1a\u5f88\u96be\uff0c\u6240\u4ee5\u6211\u4eec\u5bf9\u8fd9\u4e9bcells\u9884\u5148\u8bbe\u7f6e\u4e86\u4e00\u4e9banchors\uff0c\u8ba9cells\u57fa\u4e8e\u8fd9\u4e9banchors\u9884\u6d4b\u5927\u5c0f\u548c\u4f4d\u7f6e\u7684\u504f\u79fb\u91cf\u3002 \u8bbeanchors\u7684\u5927\u5c0f\u4e3a s s \uff0c\u5bbd\u9ad8\u6bd4\u4e3a r>0 r&gt;0 \uff0c\u90a3\u4e48anchors\u7684\u5bbd\u548c\u9ad8\u5206\u522b\u4e3a s/\\sqrt{r} s/\\sqrt{r} \u548c s\\sqrt{r} s\\sqrt{r} \u3002\u5982\u679c r r \u67093\u79cd\uff0c s s \u67092\u79cd\uff0c\u90a3\u4e48\u7ec4\u5408\u8d77\u6765\u80fd\u5f97\u52306\u79cd\u6846\uff1a ratio = [ 0.5 , 1 , 2 ] scale = [ 16. , 32. ] # [width, height] anchors = [[ s * np . sqrt ( 1 / r ), s * np . sqrt ( r )] for s in scale for r in ratio ] np . around ( anchors , 2 ) \u5047\u8bbe\u56fe\u50cf\u5927\u5c0f\u4e3a 64\\times 64 64\\times 64 \uff0c\u6211\u4eec\u770b\u4e0b\u4e0a\u97626\u79cdanchors\u753b\u5728\u4e2d\u5fc3\u7684\u6837\u5b50\uff1a from matplotlib.patches import Rectangle def plot_init_grid ( ax , w = 416 , h = 416 , grid = 13 ): ax . set_xticks ( np . arange ( 0 , w + 1 , w / grid )) ax . set_yticks ( np . arange ( 0 , h + 1 , h / grid )) ax . xaxis . tick_top () ax . set_aspect ( 'equal' ) plt . xlim ([ 0 , w ]) plt . ylim ([ 0 , h ]) ax . invert_yaxis () def plot_anchors ( cx , cy , anchors ): for w , h in anchors : xy = ( cx - w / 2. , cy - h / 2. ) rect = Rectangle ( xy , w , h , linewidth = 2 , fill = False , linestyle = '-.' , edgecolor = np . random . rand ( 3 ,)) ax . add_patch ( rect ) # \u56fe\u7247\u5c3a\u5bf8 img_w = 64 img_h = 64 cx = img_w / 2 cy = img_h / 2 plt . figure ( figsize = ( 6 , 6 )) ax = plt . gca () plot_init_grid ( ax , img_w , img_h , grid = 1 ) plt . plot ( cx , cy , '.r' , markersize = 24 ) plot_anchors ( cx , cy , anchors ) plt . show () \u6211\u4eec\u53ef\u4ee5\u8111\u8865\u4e00\u4e0bfeature maps\u7684\u6bcf\u4e2acell\u90fd\u6709\u9884\u5148\u8bbe\u5b9a\u7684anchors\uff0c\u4e8e\u662fRegion Proposal Network\uff08RPN\uff09\u5c31\u8981\u5bf9\u8fd9\u4e9banchors\u8fdb\u884c\u5904\u7406\u3002 \u8bad\u7ec3\u65f6\uff0c\u51e1\u662f\u8d8a\u8fc7\u56fe\u7247\u8fb9\u754c\uff08cross the boundary of the image\uff09\u7684anchors\u90fd\u88ab\u5ffd\u7565 \u6d4b\u8bd5\u65f6\uff0c\u8d8a\u8fc7\u8fb9\u754c\u7684anchors\u88ab\u622a\u65ad\u5728\u8fb9\u754c\u5904","title":"3.1 Anchors"},{"location":"cv/faster-rcnn/#32-rpn","text":"\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u5047\u8bbe\u6bcf\u4e2acell\u6709 k k \u4e2aanchors\uff0c\u4e8e\u662fRPN\u8981\u5224\u65ad\u8fd9 k k \u4e2aanchors\u5426\u4e3a\u7269\u4f53\uff08\u5206\u7c7b\uff0cclassification layer\uff09\uff0c\u8fd8\u8981\u5224\u65ad\u51c6\u786e\u7684\u4f4d\u7f6e\u548c\u5f62\u72b6\uff08\u56de\u5f52\uff0cregression layer\uff09\uff0c\u5728\u8fd9\u4e4b\u524d\u5148\u505a\u4e00\u6b213x3\u5377\u79ef\u5f97\u5230channel\u6570\u4e3a256-d\u7684featuer maps\u3002 RPN\u7f51\u7edc\u4ee3\u7801\u5982\u4e0b\uff1a import torch.nn.functional as F class RPNHead ( nn . Module ): \"\"\" Adds a simple RPN Head with classification and regression heads Arguments: in_channels (int): number of channels of the input feature num_anchors (int): number of anchors to be predicted \"\"\" def __init__ ( self , in_channels , num_anchors ): super ( RPNHead , self ) . __init__ () self . conv = nn . Conv2d ( in_channels , in_channels , kernel_size = 3 , stride = 1 , padding = 1 ) self . cls_logits = nn . Conv2d ( in_channels , num_anchors , kernel_size = 1 , stride = 1 ) self . bbox_pred = nn . Conv2d ( in_channels , num_anchors * 4 , kernel_size = 1 , stride = 1 ) for layer in self . children (): torch . nn . init . normal_ ( layer . weight , std = 0.01 ) torch . nn . init . constant_ ( layer . bias , 0 ) def forward ( self , x ): # type: (List[Tensor]) -&gt; Tuple[List[Tensor], List[Tensor]] logits = [] bbox_reg = [] for feature in x : t = F . relu ( self . conv ( feature )) logits . append ( self . cls_logits ( t )) bbox_reg . append ( self . bbox_pred ( t )) return logits , bbox_reg \u7531\u4e8eFPN\u7684backbone\u4f1a\u8f93\u51fa\u591a\u7ec4feature maps\uff08\u5206\u522b\u4e3a stride=4/8/16/32 \uff09\uff0c\u6240\u4ee5 RPNHead \u7684 forward() \u9ed8\u8ba4\u8f93\u5165 x \u4e3aiteratble\u7c7b\u578b\u7684\uff0c\u4f8b\u5982 [fm_1/4, fm_1/8, fm_1/16, fm_1/32] \u3002\u6574\u4e2a\u8fc7\u7a0b\u5982\u4e0b\u56fe\u6240\u793a\uff08\u8bbe k=3 k=3 \uff09\uff1a \u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u8fd9\u91cc\u9ec4\u8272 scores \u7684 channels=3 \uff0c\u800c\u975e 2k=10 2k=10 \uff0c\u8fd9\u662f\u56e0\u4e3a\u662f\u5224\u65ad\u6846\u662f\u5426\u4e3a\u7269\u4f53\u7684\u5206\u7c7b\u51fd\u6570\u7528\u4e86\u903b\u8f91\u56de\u5f52\uff0c\u76f4\u63a5\u8f93\u51fa\u7684\u662flogit\u800c\u975e\u6982\u7387\uff0closs\u51fd\u6570\u7528\u4e86 binary_cross_entropy_with_logits \uff0c\u5e94\u8be5\u662f\u4e3a\u4e86\u4f18\u5316cross entropy\u548csigmoid\u7684\u8054\u5408\u6c42\u5bfc\uff08\u7c7b\u4f3csoftmax\u548ccorss entropy\u8054\u5408\u6c42\u5bfc\uff09\u3002\u5047\u8bbe w,h=32,c=10 w,h=32,c=10 \uff0c\u90a3\u4e48\u5bf9\u5e94\u7684\u4ee3\u7801\u4e3a\uff1a x = torch . rand ( 1 , 10 , 32 , 32 ) scores , coordinates = RPNHead ( 10 , 3 )([ x ]) print ( \"scores:\" , scores [ 0 ] . shape ) print ( \"coordinates:\" , coordinates [ 0 ] . shape ) del x , scores , coordinates","title":"3.2 RPN"},{"location":"cv/faster-rcnn/#33-bounding-box-regression","text":"\u73b0\u5728RPN\u9884\u6d4b\u7684\u7269\u4f53bounding box\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff0c x_a, y_a, w_a, h_a x_a, y_a, w_a, h_a \u662f\u67d0\u4e00\u4e2aanchor\uff0c x, y, w, h x, y, w, h \u662fRPN\u57fa\u4e8e\u8fd9\u4e2aanchor\u9884\u6d4b\u7684bbox\uff0c x^*, y^*, w^*, h^* x^*, y^*, w^*, h^* \u662f\u5bf9\u5e94\u76ee\u6807\u7684ground truth\u3002 \u90a3\u4e48\u5c06\u4e2d\u5fc3\u5750\u6807\u504f\u79fb\u91cf\u548c\u5bbd\u9ad8\u6bd4\u5206\u522b\u5f52\u4e00\u5316\u540e\u53ef\u4ee5\u5f97\u5230 t_x, t_y, t_w, t_h t_x, t_y, t_w, t_h \uff0c\u4e5f\u5c31\u662fRPN\u7f51\u7edc\u9700\u8981\u5b66\u4e60\u8f93\u51fa\u7684bbox\u4fe1\u606f\uff0c\u800c t_*, t_*, t_*, t_* t_*, t_*, t_*, t_* \u662fground truth\uff0c\u4e24\u8005\u7ed3\u5408\u53ef\u4ee5\u8ba1\u7b97\u51fabounding box regreesion\u5206\u652f\u7684loss\u3002 t_{\\mathrm{x}}=\\left(x-x_{\\mathrm{a}}\\right) / w_{\\mathrm{a}}, \\quad t_{\\mathrm{y}}=\\left(y-y_{\\mathrm{a}}\\right) / h_{\\mathrm{a}} t_{\\mathrm{x}}=\\left(x-x_{\\mathrm{a}}\\right) / w_{\\mathrm{a}}, \\quad t_{\\mathrm{y}}=\\left(y-y_{\\mathrm{a}}\\right) / h_{\\mathrm{a}} t_{\\mathrm{w}}=\\log \\left(w / w_{\\mathrm{a}}\\right), \\quad t_{\\mathrm{h}}=\\log \\left(h / h_{\\mathrm{a}}\\right) t_{\\mathrm{w}}=\\log \\left(w / w_{\\mathrm{a}}\\right), \\quad t_{\\mathrm{h}}=\\log \\left(h / h_{\\mathrm{a}}\\right) t_{\\mathrm{x}}^{\\*}=\\left(x^{*}-x_{\\mathrm{a}}\\right) / w_{\\mathrm{a}}, \\quad t_{\\mathrm{y}}^{\\*}=\\left(y^{\\*}-y_{\\mathrm{a}}\\right) / h_{\\mathrm{a}} t_{\\mathrm{x}}^{\\*}=\\left(x^{*}-x_{\\mathrm{a}}\\right) / w_{\\mathrm{a}}, \\quad t_{\\mathrm{y}}^{\\*}=\\left(y^{\\*}-y_{\\mathrm{a}}\\right) / h_{\\mathrm{a}} t_{\\mathrm{w}}^{\\*}=\\log \\left(w^{\\*} / w_{\\mathrm{a}}\\right), \\quad t_{\\mathrm{h}}^{\\*}=\\log \\left(h^{\\*} / h_{\\mathrm{a}}\\right) t_{\\mathrm{w}}^{\\*}=\\log \\left(w^{\\*} / w_{\\mathrm{a}}\\right), \\quad t_{\\mathrm{h}}^{\\*}=\\log \\left(h^{\\*} / h_{\\mathrm{a}}\\right) \u5206\u522b\u9664\u4ee5 w_a, h_a w_a, h_a \u8fdb\u884c\u5f52\u4e00\u5316\u5229\u4e8e\u7f51\u7edc\u5b66\u4e60\uff0c\u4f46\u662f\u4e3a\u4ec0\u4e48\u5bbd\u9ad8\u6bd4\u503c\u90fd\u52a0\u4e86\u4e00\u4e2alog\u51fd\u6570\u5462\uff1f \u56e0\u4e3a\u5bbd\u9ad8\u6bd4\u5fc5\u987b\u5927\u4e8e\u7b49\u4e8e0\uff0c\u6240\u4ee5\u53d8\u6210\u4e86\u4e00\u4e2a\u5e26\u7ea6\u675f\u7684\u4f18\u5316\u95ee\u9898\uff0c\u800c w/w_a=e^{t_w} w/w_a=e^{t_w} \u6052\u5927\u4e8e0\uff0c\u8fd9\u6837\u7f51\u7edc\u8f93\u51fa\u7684 t_w, t_h t_w, t_h \u5c31\u6ca1\u6709\u9650\u5236\u4e86\uff01\uff01\uff01","title":"3.3 Bounding Box Regression"},{"location":"cv/faster-rcnn/#34-training-rpn","text":"anchors\u6839\u636e\u6709\u65e0\u7269\u4f53\u5206\u4e3a\u6b63\u6837\u672c\u548c\u8d1f\u6837\u672c\uff1a\u5982\u679c\u4e00\u4e2aanchor\u548c\u67d0\u4e00\u4e2agt\u6846\u7684IoU\u5927\u4e8e0.7\u5c31\u88ab\u8ba4\u4e3a\u662f\u6b63\u6837\u672c\uff0c\u5982\u679c\u7279\u6b8a\u60c5\u51b5\u4e0b\u67d0\u4e2agt\u6846\u6ca1\u6709\u4efb\u4f55\u4e00\u4e2aanchor\u4e0e\u4e4b\u5bf9\u5e94\uff0c\u5c31\u9009IoU\u6700\u9ad8\u7684\u90a3\u4e2aanchor\uff1b\u51e1\u662fIoU\u5c0f\u4e8e0.3\u7684\u90fd\u88ab\u8ba4\u4e3a\u662f\u8d1f\u6837\u672c\u3002 \u5c3d\u7ba1\u53ef\u4ee5\u6240\u6709\u7684\u6b63\u8d1f\u6837\u672c\u90fd\u53ef\u4ee5\u53c2\u4e0e\u8bad\u7ec3\uff0c\u4f46\u662f\u56e0\u4e3a\u56fe\u7247\u4e2d\u76ee\u6807\u4e2a\u6570\u6709\u9650\uff0c\u6240\u4ee5\u4f1a\u5bfc\u81f4\u5927\u591a\u6570anchors\u90fd\u662f\u8d1f\u6837\u672c\uff08\u80cc\u666f\uff09\u3002\u4f8b\u5982 k=9 k=9 \uff0cfeature maps\u7684 w=h=50 w=h=50 \u65f6\uff0canchors\u603b\u6570\u4e3a 9\\times 50 \\times50=22500 9\\times 50 \\times50=22500 \u4e2a\uff0c\u8fd9\u6837\u6b63\u8d1f\u6837\u672c\u5f88\u4e0d\u5e73\u8861\uff0c\u4e8e\u662f\u4f5c\u8005\u5728\u4e00\u5f20\u56fe\u4e2d\u968f\u673a\u5404\u9009\u53d6128\u4e2a\u6b63\u8d1f\u6837\u672c\u7ec4\u6210256\u4e2aanchors\u7684mini batch\u3002 RPN\u7f51\u7edc\u7684Loss\u51fd\u6570\u5982\u4e0b\uff0c N_{reg} N_{reg} \u53ea\u5305\u62ec p^*=1 p^*=1 \u7684\u6b63\u6837\u672c\uff1a L(\\{p_i\\},\\{t_{i}\\})=\\frac{1}{N_{cls}} \\sum_{i} L_{cls}\\left(p_i, p_{i}^{\\*}\\right)+\\lambda \\frac{1}{N_{reg}} \\sum_{i} p_{i}^{\\*} L_{reg}\\left(t_{i}, t_{i}^{\\*}\\right) L(\\{p_i\\},\\{t_{i}\\})=\\frac{1}{N_{cls}} \\sum_{i} L_{cls}\\left(p_i, p_{i}^{\\*}\\right)+\\lambda \\frac{1}{N_{reg}} \\sum_{i} p_{i}^{\\*} L_{reg}\\left(t_{i}, t_{i}^{\\*}\\right)","title":"3.4 Training RPN"},{"location":"cv/faster-rcnn/#35-nms","text":"\u56e0\u4e3aRPN\u8f93\u51fa\u7684\u76ee\u6807\u6846\u4f1a\u6709\u5f88\u591a\u91cd\u53e0\u7684\uff08\u5982\u4e0b\u56fe\u6240\u793a\uff09\uff0c\u6240\u4ee5\u6211\u4eec\u9700\u8981\u4f7f\u7528NMS\u8fdb\u884c\u8fc7\u6ee4\u3002 from matplotlib.patches import Rectangle def plt_boxes ( bboxes , ax ): \"\"\" matplotlib Rectangle --- (xy, w, h) \"\"\" for box in bboxes : x1 , y1 , x2 , y2 , _ = box w = x2 - x1 h = y2 - y1 ax . add_patch ( Rectangle (( x1 , y1 ), w , h , linewidth = 2 , fill = False , edgecolor = np . random . rand ( 3 ,))) plt . xlim ([ 0 , max ( bboxes [:, 2 ]) + 20 ]) plt . ylim ([ 0 , max ( bboxes [:, 3 ]) + 20 ]) ax . xaxis . tick_top () ax . invert_yaxis () # [x1, y1, x2, y2, score] dets = np . array ([[ 218 , 322 , 385 , 491 , 0.98 ], [ 247 , 312 , 419 , 461 , 0.83 ], [ 237 , 344 , 407 , 510 , 0.92 ], [ 757 , 218 , 937 , 394 , 0.96 ], [ 768 , 198 , 962 , 364 , 0.85 ], [ 740 , 240 , 906 , 414 , 0.83 ], [ 1101 , 84 , 1302 , 303 , 0.82 ], [ 1110 , 67 , 1331 , 260 , 0.97 ], [ 1123 , 42 , 1362 , 220 , 0.85 ]]) ax = plt . gca () plt_boxes ( dets , ax ) plt . show () \u9996\u5148\u6309\u7167\u5206\u7c7b\u5f97\u5206\u9ad8\u4f4e\u5c06\u6846\u6392\u5e8f\uff0c\u7136\u540e\u904d\u5386\uff08\u5df2\u5220\u9664\u7684\u4e0d\u518d\u904d\u5386\uff09\uff0c\u5220\u9664\u548c\u5f53\u524d\u6846 \\text{IoU}>\\text{threshold} \\text{IoU}&gt;\\text{threshold} \uff08\u8bba\u6587\u4e2d\u4e3a0.7\uff09\u7684\u6846\u3002 IoU\u7684\u516c\u5f0f\u548c\u793a\u610f\u56fe\u5982\u4e0b\uff1a J(\\mathcal{A}, \\mathcal{B})=\\frac{|\\mathcal{A} \\cap \\mathcal{B}|}{|\\mathcal{A} \\cup \\mathcal{B}|} J(\\mathcal{A}, \\mathcal{B})=\\frac{|\\mathcal{A} \\cap \\mathcal{B}|}{|\\mathcal{A} \\cup \\mathcal{B}|} def nms ( dets , thres ): \"\"\" @dets, detecion results, shape: [batch, 5], form: [[x1, y1, x2, y2, score]] @thres, threshold \"\"\" x1 = dets [:, 0 ] y1 = dets [:, 1 ] x2 = dets [:, 2 ] y2 = dets [:, 3 ] scores = dets [:, 4 ] area = ( x2 - x1 + 1 ) * ( y2 - y1 + 1 ) order = scores . argsort ()[:: - 1 ] kept_idx = [] while order . size & gt ; 0 : i = order [ 0 ] kept_idx . append ( i ) xx1 = np . maximum ( x1 [ i ], x1 [ order [ 1 :]]) yy1 = np . maximum ( y1 [ i ], y1 [ order [ 1 :]]) xx2 = np . minimum ( x2 [ i ], x2 [ order [ 1 :]]) yy2 = np . minimum ( y2 [ i ], y2 [ order [ 1 :]]) w = np . maximum ( 0.0 , xx2 - xx1 + 1 ) h = np . maximum ( 0.0 , yy2 - yy1 + 1 ) inter = w * h IoU = inter / ( area [ i ] + area [ order [ 1 :]] - inter ) inds = np . where ( IoU 0.7 \u7684\u4e3a\u6b63\u6837\u672c \uff0c threshold are chosen . \"\"\" img = Image.open(img_path) transform = T.Compose([T.ToTensor()]) img = transform(img) pred = model([img]) pred_class = [COCO_INSTANCE_CATEGORY_NAMES[i] for i in list(pred[0]['labels'].numpy())] pred_boxes = [[(i[0], i[1]), (i[2], i[3])] for i in list(pred[0]['boxes'].detach().numpy())] pred_score = list(pred[0]['scores'].detach().numpy()) pred_t = [pred_score.index(x) for x in pred_score if x&gt;threshold][-1] pred_boxes = pred_boxes[:pred_t+1] pred_class = pred_class[:pred_t+1] return pred_boxes, pred_class def object_detection_api(img_path, threshold=0.5, rect_th=3, text_size=3, text_th=3): \"\"\" object_detection_api parameters : - img_path - path of the input image - threshold - threshold value for prediction score - rect_th - thickness of bounding box - text_size - size of the class label text - text_th - thichness of the text method : - prediction is obtained from get_prediction method - for each prediction , bounding box is drawn and text is written with opencv - the final image is displayed \"\"\" boxes, pred_cls = get_prediction(img_path, threshold) img = cv2.imread(img_path) img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) for i in range(len(boxes)): cv2.rectangle(img, boxes[i][0], boxes[i][1],color=(0, 255, 0), thickness=rect_th) cv2.putText(img,pred_cls[i], boxes[i][0], cv2.FONT_HERSHEY_SIMPLEX, text_size, (0,255,0),thickness=text_th) plt.figure(figsize=(20,30)) plt.imshow(img) plt.xticks([]) plt.yticks([]) plt.show() object_detection_api ( \"../_files/people.jpg\" , threshold = 0.8 ) object_detection_api ( '../_files/traffic-143391_960_720.jpg' , threshold = 0.8 , text_size = 1 )","title":"3.5 NMS"},{"location":"cv/faster-rcnn/#4","text":"Faster R-CNN Object Detection with PyTorch \u634b\u4e00\u634bpytorch\u5b98\u65b9FasterRCNN\u4ee3\u7801 \u4e00\u6587\u8bfb\u61c2Faster RCNN Guide to build Faster RCNN in PyTorch \u53c2\u8003\u8d44\u6599\uff1a Yang Dawei, Faster R-CNN\u539f\u7406\u4e0e\u4f7f\u7528 (Pytorch) , \u4e91\u98de\u673a\u5668\u4eba\u5b9e\u9a8c\u5ba4 \u672c\u6761\u76ee\u8d21\u732e\u8005 \uff1a LinkHS","title":"4. \u63a8\u8350\u9605\u8bfb"},{"location":"jetson/","text":"Nvidia Jetson Jetson\u662f\u82f1\u4f1f\u8fbe\u63a8\u51fa\u7684\u9762\u5411\u5d4c\u5165\u5f0f\u8ba1\u7b97\u7684\u786c\u4ef6\u5e73\u53f0\uff0c\u5305\u62ec\uff1a Jetson Nano Jetson TX1 Jetson TX2 Jetson Xaiver Jetson Xavier Nx Jetson\u5404\u4e2a\u578b\u53f7\u7684\u5bf9\u6bd4\u5982\u4e0b\uff1a Hardware feature \\ Jetson module Jetson Nano Jetson TX1 Jetson TX2/TX2i Jetson Xavier Jetson Xavier Nx CPU (ARM) 4-core ARM A57 @ 1.43 GHz 4-core ARM Cortex A57 @ 1.73 GHz 4-core ARM Cortex-A57 @ 2 GHz, 2-core Denver2 @ 2 GHz 8-core ARM Carmel v.8.2 @ 2.26 GHz 6-core NVIDIA Carmel ARM\u00aev8.2 64-bit CPU GPU 128-core Maxwell @ 921 MHz 256-core Maxwell @ 998 MHz 256-core Pascal @ 1.3 GHz 512-core Volta @ 1.37 GHz 384-core NVIDIA Volta\u2122 GPU Memory 4 GB LPDDR4, 25.6 GB/s 4 GB LPDDR4, 25.6 GB/s 8 GB 128-bit LPDDR4, 58.3 GB/s 16 GB 256-bit LPDDR4, 137 GB/s 8 GB 128-bit LPDDR4x @ 1600 MHz51.2GB/s Storage MicroSD 16 GB eMMC 5.1 32 GB eMMC 5.1 32 GB eMMC 5.1 16 GB eMMC 5.1 Tensor cores -- -- -- 64 48 Video encoding (1x) 4Kp30, (2x) 1080p60, (4x) 1080p30 (1x) 4Kp30, (2x) 1080p60, (4x) 1080p30 (1x) 4Kp60, (3x) 4Kp30, (4x) 1080p60, (8x) 1080p30 (4x) 4Kp60, (8x) 4Kp30, (32x) 1080p30 2x464MP/sec (HEVC)2x 4K @ 30 (HEVC)6x 1080p @ 60 (HEVC)14x 1080p @ 30 (HEVC) Video decoding (1x) 4Kp60, (2x) 4Kp30, (4x) 1080p60, (8x) 1080p30 (1x) 4Kp60, (2x) 4Kp30, (4x) 1080p60, (8x) 1080p30 (2x) 4Kp60, (4x) 4Kp30, (7x) 1080p60 (2x) 8Kp30, (6x) 4Kp60, (12x) 4Kp30 2x690MP/sec (HEVC)2x 4K @ 60 (HEVC)4x 4K @ 30 (HEVC)12x 1080p @ 60 (HEVC)32x 1080p @ 30 (HEVC)16x 1080p @ 30 (H.264) USB (4x) USB 3.0 + Micro-USB 2.0 (1x) USB 3.0 + (1x) USB 2.0 (1x) USB 3.0 + (1x) USB 2.0 (3x) USB 3.1 + (4x) USB 2.0 PCI-Express lanes 4 lanes PCIe Gen 2 5 lanes PCIe Gen 2 5 lanes PCIe Gen 2 16 lanes PCIe Gen 4 1 x1 + 1x4(PCIe Gen3, Root Port & Endpoint) Power 5W / 10W 10W 7.5W / 15W 10W / 15W / 30W 10W / 15W \u53c2\u8003\u8d44\u6599\uff1a Benchmark comparison for Jetson Nano, TX1, TX2 and AGX Xavier, https://www.fastcompression.com/blog/jetson-benchmark-comparison.htm Jetson Xavier NX, https://developer.nvidia.com/embedded/jetson-xavier-nx \u672c\u6761\u76ee\u8d21\u732e\u8005 \uff1a automaticdai (\u672c\u6761\u76ee\u9700\u8981\u5b8c\u5584\uff0c \u7acb\u523b\u53c2\u4e0e\u77e5\u8bc6\u516c\u5171\u7f16\u8f91 )","title":"Nvidia Jetson"},{"location":"jetson/#nvidia-jetson","text":"Jetson\u662f\u82f1\u4f1f\u8fbe\u63a8\u51fa\u7684\u9762\u5411\u5d4c\u5165\u5f0f\u8ba1\u7b97\u7684\u786c\u4ef6\u5e73\u53f0\uff0c\u5305\u62ec\uff1a Jetson Nano Jetson TX1 Jetson TX2 Jetson Xaiver Jetson Xavier Nx Jetson\u5404\u4e2a\u578b\u53f7\u7684\u5bf9\u6bd4\u5982\u4e0b\uff1a Hardware feature \\ Jetson module Jetson Nano Jetson TX1 Jetson TX2/TX2i Jetson Xavier Jetson Xavier Nx CPU (ARM) 4-core ARM A57 @ 1.43 GHz 4-core ARM Cortex A57 @ 1.73 GHz 4-core ARM Cortex-A57 @ 2 GHz, 2-core Denver2 @ 2 GHz 8-core ARM Carmel v.8.2 @ 2.26 GHz 6-core NVIDIA Carmel ARM\u00aev8.2 64-bit CPU GPU 128-core Maxwell @ 921 MHz 256-core Maxwell @ 998 MHz 256-core Pascal @ 1.3 GHz 512-core Volta @ 1.37 GHz 384-core NVIDIA Volta\u2122 GPU Memory 4 GB LPDDR4, 25.6 GB/s 4 GB LPDDR4, 25.6 GB/s 8 GB 128-bit LPDDR4, 58.3 GB/s 16 GB 256-bit LPDDR4, 137 GB/s 8 GB 128-bit LPDDR4x @ 1600 MHz51.2GB/s Storage MicroSD 16 GB eMMC 5.1 32 GB eMMC 5.1 32 GB eMMC 5.1 16 GB eMMC 5.1 Tensor cores -- -- -- 64 48 Video encoding (1x) 4Kp30, (2x) 1080p60, (4x) 1080p30 (1x) 4Kp30, (2x) 1080p60, (4x) 1080p30 (1x) 4Kp60, (3x) 4Kp30, (4x) 1080p60, (8x) 1080p30 (4x) 4Kp60, (8x) 4Kp30, (32x) 1080p30 2x464MP/sec (HEVC)2x 4K @ 30 (HEVC)6x 1080p @ 60 (HEVC)14x 1080p @ 30 (HEVC) Video decoding (1x) 4Kp60, (2x) 4Kp30, (4x) 1080p60, (8x) 1080p30 (1x) 4Kp60, (2x) 4Kp30, (4x) 1080p60, (8x) 1080p30 (2x) 4Kp60, (4x) 4Kp30, (7x) 1080p60 (2x) 8Kp30, (6x) 4Kp60, (12x) 4Kp30 2x690MP/sec (HEVC)2x 4K @ 60 (HEVC)4x 4K @ 30 (HEVC)12x 1080p @ 60 (HEVC)32x 1080p @ 30 (HEVC)16x 1080p @ 30 (H.264) USB (4x) USB 3.0 + Micro-USB 2.0 (1x) USB 3.0 + (1x) USB 2.0 (1x) USB 3.0 + (1x) USB 2.0 (3x) USB 3.1 + (4x) USB 2.0 PCI-Express lanes 4 lanes PCIe Gen 2 5 lanes PCIe Gen 2 5 lanes PCIe Gen 2 16 lanes PCIe Gen 4 1 x1 + 1x4(PCIe Gen3, Root Port & Endpoint) Power 5W / 10W 10W 7.5W / 15W 10W / 15W / 30W 10W / 15W \u53c2\u8003\u8d44\u6599\uff1a Benchmark comparison for Jetson Nano, TX1, TX2 and AGX Xavier, https://www.fastcompression.com/blog/jetson-benchmark-comparison.htm Jetson Xavier NX, https://developer.nvidia.com/embedded/jetson-xavier-nx \u672c\u6761\u76ee\u8d21\u732e\u8005 \uff1a automaticdai (\u672c\u6761\u76ee\u9700\u8981\u5b8c\u5584\uff0c \u7acb\u523b\u53c2\u4e0e\u77e5\u8bc6\u516c\u5171\u7f16\u8f91 )","title":"Nvidia Jetson"},{"location":"raspberrypi/","text":"Raspberry Pi \u6811\u8393\u6d3e\u662f\u82f1\u56fd\u6811\u8393\u6d3e\u57fa\u91d1\u8bbe\u8ba1\u548c\u63a8\u5e7f\u7684\u5d4c\u5165\u5f0fLinux\u5f00\u53d1\u677f\u3002 (\u672c\u6761\u76ee\u9700\u8981\u5b8c\u5584\uff0c \u7acb\u523b\u53c2\u4e0e\u77e5\u8bc6\u516c\u5171\u7f16\u8f91 ) \u672c\u6761\u76ee\u8d21\u732e\u8005: automaticdai","title":"Raspberry Pi"},{"location":"raspberrypi/#raspberry-pi","text":"\u6811\u8393\u6d3e\u662f\u82f1\u56fd\u6811\u8393\u6d3e\u57fa\u91d1\u8bbe\u8ba1\u548c\u63a8\u5e7f\u7684\u5d4c\u5165\u5f0fLinux\u5f00\u53d1\u677f\u3002 (\u672c\u6761\u76ee\u9700\u8981\u5b8c\u5584\uff0c \u7acb\u523b\u53c2\u4e0e\u77e5\u8bc6\u516c\u5171\u7f16\u8f91 ) \u672c\u6761\u76ee\u8d21\u732e\u8005: automaticdai","title":"Raspberry Pi"},{"location":"resources/","text":"\u673a\u5668\u4eba\u8d44\u6e90 \u672c\u9875\u9762\u5305\u62ec\u673a\u5668\u4eba\u9879\u76ee\u8d44\u6e90\u3002 \u673a\u5668\u4eba\u5de5\u5177/\u8f6f\u4ef6 \u64cd\u4f5c\u7cfb\u7edf ROS (Robot Operating System) Gazebo Simulator \u673a\u5668\u5b66\u4e60 TensorFlow PyTorch \u786c\u4ef6\u5e73\u53f0 Arduino Raspberry Pi Nvidia Jetson \u673a\u5668\u4eba\u5b9e\u9a8c\u5ba4 \uff08\u5f85\u5b8c\u5584\uff09 \u673a\u5668\u4eba\u7ade\u8d5b DJI RoboMaster Eurobot FIRST LEGO League Robocup Pi Wars \u672c\u6761\u76ee\u8d21\u732e\u8005 \uff1a automaticdai xinyu-xu-dev","title":"\u673a\u5668\u4eba\u8d44\u6e90"},{"location":"resources/#_1","text":"\u672c\u9875\u9762\u5305\u62ec\u673a\u5668\u4eba\u9879\u76ee\u8d44\u6e90\u3002","title":"\u673a\u5668\u4eba\u8d44\u6e90"},{"location":"resources/#_2","text":"","title":"\u673a\u5668\u4eba\u5de5\u5177/\u8f6f\u4ef6"},{"location":"resources/#_3","text":"ROS (Robot Operating System) Gazebo Simulator","title":"\u64cd\u4f5c\u7cfb\u7edf"},{"location":"resources/#_4","text":"TensorFlow PyTorch","title":"\u673a\u5668\u5b66\u4e60"},{"location":"resources/#_5","text":"Arduino Raspberry Pi Nvidia Jetson","title":"\u786c\u4ef6\u5e73\u53f0"},{"location":"resources/#_6","text":"\uff08\u5f85\u5b8c\u5584\uff09","title":"\u673a\u5668\u4eba\u5b9e\u9a8c\u5ba4"},{"location":"resources/#_7","text":"DJI RoboMaster Eurobot FIRST LEGO League Robocup Pi Wars \u672c\u6761\u76ee\u8d21\u732e\u8005 \uff1a automaticdai xinyu-xu-dev","title":"\u673a\u5668\u4eba\u7ade\u8d5b"},{"location":"resources/conferences/","text":"\u673a\u5668\u4eba\u4f1a\u8bae\u4e0e\u671f\u520a\u5217\u8868 \u673a\u5668\u4eba / \u4eba\u5de5\u667a\u80fd / \u673a\u5668\u5b66\u4e60\uff08\u4f1a\u8bae\uff09 Name Rank Conference Full Name h5-index AAAI ** Conference on Artificial Intelligence 126 AIM * IEEE/ASME International Conference on Advanced Intelligent Mechatronics 17 ARM IEEE International Conference on Advanced Robotics and Mechatronics ARSO IEEE Workshop on Advanced Robotics and its Social Impacts BioRob IEEE/RAS-EMBS International Conference on Biomedical Robotics and Biomechatronics CASE International Conference on Automation Science and Engineering CIRA IEEE International Conference on Computational Intelligence in Robotics and Automation CoRL * Annual Conference on Robot Learning Humanoid IEEE RAS/RSJ International Conference on Humanoid Robots ICRA * IEEE International Conference on Robotics and Automation 94 IJCAI * International Joint Conference on Artificial Intelligence 95 ICMA IEEE International Conference on Mechatronics and Automation ICML ** International Conference on Machine Learning 171 ICORR International Conference on Rehabilitaion Robotics IROS * IEEE/RSJ International Conference on Intelligent Robots and Systems 63 NIPS ** Conference on Neural Information Processing Systems 198 ROBIO IEEE International Conference on Robotics and Biomimetics RO-MAN International Symposium on Robot and Human Interactive Communication RSS Robotics: Science and Systems Conference SSRR IEEE International Workshop on Safety, Security and Rescue Robots TAROS Towards Autonomous Robotic Systems Conference WCICA World Congress on Intelligent Control and Automation \u673a\u5668\u89c6\u89c9\uff08\u4f1a\u8bae\uff09 Name Rank Conference Full Name h5-index CVPR * Conference on Computer Vision and Pattern Recognition 299 ICCV * International Conference on Computer Vision 176 \u673a\u5668\u4eba / \u4eba\u5de5\u667a\u80fd\uff08\u671f\u520a\uff09 Name Rank Conference Full Name h5-index JFR * Journal of Field Robotics 45 JINT Journal of Intelligent and Robotic Systems 46 JMLR * Journal of Machine Learning Research 82 IJCV * International Journal of Computer Vision 70 IJRR ** International Journal of Robotics Research 61 TPAMI * IEEE Transactions on Pattern Analysis and Machine Intelligence 131 TRO ** IEEE Transactions on Robotics 61 RA-L IEEE Robotics and Automation Letters 53 RAM IEEE Robotics and Automation Magazine 34 RAS * Robotics and Autonomous Systems 56 \u53c2\u8003\u8d44\u6599 [1] \u673a\u5668\u4eba\u9886\u57df\u4e3b\u8981\u56fd\u9645\u4f1a\u8bae\u4e0e\u671f\u520a\u5217\u8868 - \u4e91\u98de\u673a\u5668\u4eba\u5b9e\u9a8c\u5ba4 \u672c\u9875\u9762\u8d21\u732e\u8005 \uff1a automaticdai","title":"\u673a\u5668\u4eba\u4f1a\u8bae\u4e0e\u671f\u520a\u5217\u8868"},{"location":"resources/conferences/#_1","text":"","title":"\u673a\u5668\u4eba\u4f1a\u8bae\u4e0e\u671f\u520a\u5217\u8868"},{"location":"resources/conferences/#_2","text":"Name Rank Conference Full Name h5-index AAAI ** Conference on Artificial Intelligence 126 AIM * IEEE/ASME International Conference on Advanced Intelligent Mechatronics 17 ARM IEEE International Conference on Advanced Robotics and Mechatronics ARSO IEEE Workshop on Advanced Robotics and its Social Impacts BioRob IEEE/RAS-EMBS International Conference on Biomedical Robotics and Biomechatronics CASE International Conference on Automation Science and Engineering CIRA IEEE International Conference on Computational Intelligence in Robotics and Automation CoRL * Annual Conference on Robot Learning Humanoid IEEE RAS/RSJ International Conference on Humanoid Robots ICRA * IEEE International Conference on Robotics and Automation 94 IJCAI * International Joint Conference on Artificial Intelligence 95 ICMA IEEE International Conference on Mechatronics and Automation ICML ** International Conference on Machine Learning 171 ICORR International Conference on Rehabilitaion Robotics IROS * IEEE/RSJ International Conference on Intelligent Robots and Systems 63 NIPS ** Conference on Neural Information Processing Systems 198 ROBIO IEEE International Conference on Robotics and Biomimetics RO-MAN International Symposium on Robot and Human Interactive Communication RSS Robotics: Science and Systems Conference SSRR IEEE International Workshop on Safety, Security and Rescue Robots TAROS Towards Autonomous Robotic Systems Conference WCICA World Congress on Intelligent Control and Automation","title":"\u673a\u5668\u4eba / \u4eba\u5de5\u667a\u80fd / \u673a\u5668\u5b66\u4e60\uff08\u4f1a\u8bae\uff09"},{"location":"resources/conferences/#_3","text":"Name Rank Conference Full Name h5-index CVPR * Conference on Computer Vision and Pattern Recognition 299 ICCV * International Conference on Computer Vision 176","title":"\u673a\u5668\u89c6\u89c9\uff08\u4f1a\u8bae\uff09"},{"location":"resources/conferences/#_4","text":"Name Rank Conference Full Name h5-index JFR * Journal of Field Robotics 45 JINT Journal of Intelligent and Robotic Systems 46 JMLR * Journal of Machine Learning Research 82 IJCV * International Journal of Computer Vision 70 IJRR ** International Journal of Robotics Research 61 TPAMI * IEEE Transactions on Pattern Analysis and Machine Intelligence 131 TRO ** IEEE Transactions on Robotics 61 RA-L IEEE Robotics and Automation Letters 53 RAM IEEE Robotics and Automation Magazine 34 RAS * Robotics and Autonomous Systems 56 \u53c2\u8003\u8d44\u6599 [1] \u673a\u5668\u4eba\u9886\u57df\u4e3b\u8981\u56fd\u9645\u4f1a\u8bae\u4e0e\u671f\u520a\u5217\u8868 - \u4e91\u98de\u673a\u5668\u4eba\u5b9e\u9a8c\u5ba4 \u672c\u9875\u9762\u8d21\u732e\u8005 \uff1a automaticdai","title":"\u673a\u5668\u4eba / \u4eba\u5de5\u667a\u80fd\uff08\u671f\u520a\uff09"},{"location":"resources/simulators/","text":"\u673a\u5668\u4eba\u5e38\u7528\u53ef\u89c6\u5316\u4eff\u771f\u5de5\u5177 \u673a\u5668\u4eba\u7cfb\u7edf\u8bbe\u8ba1\u79bb\u4e0d\u5f00\u4eff\u771f\u5de5\u5177\u7684\u652f\u6301\u3002\u673a\u5668\u4eba\u4eff\u771f\u8ba9\u6211\u4eec\u5728\u6ca1\u6709\u7269\u7406\u786c\u4ef6\u7684\u60c5\u51b5\u4e0b\u4e5f\u53ef\u4ee5\u5feb\u901f\u5bf9\u7b97\u6cd5\u8fdb\u884c\u9a8c\u8bc1\uff1b\u6216\u8005\u63d0\u9ad8\u5b89\u5168\u6027\uff0c\u907f\u514d\u5b9e\u9a8c\u635f\u4f24\u6211\u4eec\u7684\u8bbe\u5907\uff08\u6bd4\u5982\u5728\u589e\u5f3a\u5b66\u4e60\u4e2d\uff0c\u5c31\u9700\u8981\u5927\u91cfrandom\u7684exploration\uff09\u3002\u8fd9\u7bc7\u6587\u7ae0\u6211\u60f3\u4ecb\u7ecd\u4e00\u4e0b\u5f53\u524d\u4e3b\u6d41\u7684\u53ef\u89c6\u5316\u4eff\u771f\u5de5\u5177\u3002\u4e00\u822c\u6765\u8bf4\u8fd9\u4e9b\u4eff\u771f\u5de5\u5177\u5728\u7269\u7406\u5f15\u64ce\u4e4b\u4e0a\u8fdb\u884c\u5305\u88c5\uff0c\u5982\u57fa\u4e8eODE\u3001 Bullet\u7b49\u3002\u6709\u4e9b\u60c5\u51b5\u4e0b\u6211\u4eec\u53ea\u9700\u8981\u4f7f\u7528\u7269\u7406\u5f15\u64ce\u5c31\u53ef\u4ee5\u6ee1\u8db3\u9700\u8981\uff0c\u4f46\u4e00\u822c\u60c5\u51b5\u4e0b\u6211\u4eec\u4e5f\u60f3\u901a\u8fc7\u53ef\u89c6\u5316\u5e73\u53f0\u89c2\u5bdf\u673a\u5668\u4eba\u8fd0\u884c\u7684\u6b63\u786e\u6027\u3002\u4eff\u771f\u4e00\u822c\u53ea\u5728\u7cfb\u7edf\u524d\u671f\u4f7f\u7528\uff0c\u56e0\u4e3a\u771f\u5b9e\u7269\u7406\u5e73\u53f0\u4e0e\u4eff\u771f\u73af\u5883\u5b58\u5728\u5dee\u5f02\uff0c\u540e\u671f\u8fd8\u662f\u8981\u8f6c\u6362\u5230\u5b9e\u9645\u786c\u4ef6\u5e73\u53f0\u4e0a\u8fdb\u884c\u8c03\u8bd5\u3002\u5f53\u7136\u76ee\u524d\u4e5f\u6709sim-to-real\u7684\u7814\u7a76\u53ef\u4ee5\u52a0\u901f\u79fb\u690d\u7684\u8fc7\u7a0b\uff0c\u751a\u81f3\u53ef\u4ee5\u76f4\u63a5\u5c06\u4eff\u771f\u7ed3\u679c\u7528\u4e8e\u5b9e\u9645\u673a\u5668\u4eba\u5e73\u53f0\u3002 Gazebo \u5b98\u65b9\u7f51\u7ad9\uff1ahttp://gazebosim.org/ \u652f\u6301\u7684\u7269\u7406\u5f15\u64ce\uff1aODE/Bullet/Simbody/DART \u5f00\u6e90\u4eff\u771f\u73af\u5883 \u5c5e\u4e8eROS\u751f\u6001 Gazebo\u662f\u76ee\u524d\u6700\u5e7f\u6cdb\u4f7f\u7528\u7684\u4eff\u771f\u73af\u5883\uff0c\u6700\u65e9\u57282004\u5e74\u7531USC Robotics Research Lab (\u5357\u52a0\u5dde\u5927\u5b66\u673a\u5668\u4eba\u5b9e\u9a8c\u5ba4) \u5f00\u53d1\u3002\u4f9d\u6258\u4e8eROS\u7684\u53d1\u5c55\uff0cGazebo\u5177\u6709\u5f88\u5f3a\u7684\u4eff\u771f\u80fd\u529b\uff0c\u540c\u65f6\u4e5f\u5728\u673a\u5668\u4eba\u7814\u7a76\u548c\u5f00\u53d1\u4e2d\u5f97\u5230\u4e86\u5e7f\u6cdb\u5e94\u7528\u3002Gazebo\u7684\u529f\u80fd\u5305\u62ec\uff1a\u52a8\u529b\u5b66\u4eff\u771f\u3001\u4f20\u611f\u5668\u4eff\u771f\u3001\u4e09\u7ef4\u73af\u5883\u4eff\u771f\uff0c\u540c\u65f6\u652f\u6301\u591a\u79cd\u673a\u5668\u4eba\u6a21\u578b\uff1a\u5305\u62ecPR2\u3001Turtlebot\u3001AR.Drone\u7b49\u3002 CoppeliaSim (V-REP) \u5b98\u65b9\u7f51\u7ad9\uff1ahttp://www.coppeliarobotics.com/ 2019\u5e7411\u6708\u7531V-REP\u66f4\u540d\u4e3aCoppeliaSim \u652f\u6301\u7684\u7269\u7406\u5f15\u64ce\uff1aODE/Bullet/Vortex/Newton \u6559\u80b2\u7248\u514d\u8d39 / \u5546\u4e1a\u7248\u6536\u8d39 CoppeliaSim\u6709\u975e\u5e38\u5b8c\u5584\u7684\u7269\u7406\u4eff\u771f\u5f15\u64ce\uff0c\u652f\u6301\u79fb\u52a8\u673a\u5668\u4eba\u3001\u98de\u884c\u673a\u5668\u4eba\u3001\u4eba\u578b\u673a\u5668\u4eba\u3001\u591a\u8db3\u673a\u5668\u4eba\u4ee5\u53ca\u591a\u8f74\u673a\u68b0\u624b\u7684\u8fd0\u52a8\u5b66\u4eff\u771f\u3002CoppeliaSim\u7684\u4eff\u771f\u7a0b\u5ea6\u975e\u5e38\u9ad8\uff0c\u4e0d\u4ec5\u53ef\u4ee5\u4eff\u771f\u673a\u5668\u4eba\u7684\u672c\u4f53\u4e0e\u591a\u79cd\u4f20\u611f\u5668\uff0c\u8fd8\u652f\u6301\u969c\u788d\u7269\u4ee5\u53ca\u5730\u578b(\u7a7a\u4e2d\uff0c\u5730\u9762\uff0c\u6c34\u5e95)\u7684\u4eff\u771f\u3002CoppeliaSim\u652f\u6301\u4f7f\u7528C/C++\uff0cPython\uff0cJAVA\uff0cLua\uff0cMatlab\u7f16\u5199\u811a\u672c\uff0c\u5341\u5206\u9002\u5408\u4e8e\u591a\u673a\u5668\u4eba\u7684\u4eff\u771f\u3002\u4f5c\u4e3a\u5df2\u7ecf\u5546\u4e1a\u5316\u7684\u8f6f\u4ef6\uff0c\u76f8\u6bd4Gazebo\u6709\u66f4\u597d\u7684\u7a33\u5b9a\u6027\u4e0e\u4ea4\u4e92\u4f53\u9a8c\u3002 PyBullet \u5b98\u65b9\u7f51\u7ad9\uff1ahttps://pybullet.org/ \u7269\u7406\u5f15\u64ce\uff1aBullet \u5f00\u6e90\u4eff\u771f\u73af\u5883 PyBullet\u57fa\u4e8eBullet\u7269\u7406\u5f15\u64ce\uff0c\u662fGazebo\u5f3a\u6709\u529b\u7684\u7ade\u4e89\u5bf9\u624b\u3002PyBullet\u548cPython\u7d27\u5bc6\u7ed3\u5408\uff0c\u76ee\u524d\u5728\u589e\u5f3a\u5b66\u4e60 (RL) \u4e2d\u5e7f\u6cdb\u5e94\u7528\u3002\u8be5\u73af\u5883\u53ef\u4ee5\u7ed3\u5408TensorFlow\u5b9e\u73b0RL\u8bad\u7ec3\uff0c\u6bd4\u5982DQN\u3001PPO\u3001TRPO\u3001DDPG\u7b49\u7b97\u6cd5\u3002\u76ee\u524d\u770b\u5230\u6bd4\u8f83\u591a\u7684\u90fd\u662f\u4eff\u771f\u591a\u5173\u8282\u673a\u5668\u4eba\u3002 MuJoCo \u5b98\u65b9\u7f51\u7ad9\uff1ahttp://www.mujoco.org OpenAI Gym\u76842D/3D\u673a\u5668\u4eba\u4eff\u771f\u4f7f\u7528\u4e86MuJoCo\u73af\u5883\u3002\u4e4b\u524d\u4e0d\u592a\u4e86\u89e3\uff0c\u4f7f\u7528Gym\u540e\u624d\u6162\u6162\u63a5\u89e6\u5230\u3002\u4fa7\u91cd\u63a7\u5236\u4e0e\u63a5\u89e6\u76f8\u5173\u7684\u4eff\u771f\u4e0e\u4f18\u5316\u3002\u7531University of Washington\u534e\u76db\u987f\u5927\u5b66\u5f00\u53d1\u7ef4\u62a4\uff08\u8be5\u6821\u548cOpenAI\u5173\u7cfb\u5f88\u8fd1\uff09\u3002\u53ef\u8bd5\u752830\u5929\uff0c\u4e4b\u540e\u9700\u8981\u6309\u5e74\u8d2d\u4e70license\u3002\u53ef\u4ee5\u591a\u5907\u51e0\u4e2a\u6559\u80b2\u90ae\u7bb1\u4f7f\u7528\u3002 Stage \u5b98\u65b9\u7f51\u7ad9\uff1ahttp://wiki.ros.org/stage \u5c5e\u4e8eROS\u751f\u6001 \u7528\u4e8e\u4e8c\u7ef4\u73af\u5883\uff08\u65e0z\u8f74\u9ad8\u5ea6\u4fe1\u606f\uff09\u7684\u4eff\u771f\u5668\u3002\u6700\u65e91999\u5e74\u7531USC Robotics Research Lab\u5f00\u53d1\uff0c\u5e38\u7528\u4e8e\u8def\u5f84\u89c4\u5212\u6216\u591a\u673a\u5668\u4eba (multi-agents) \u4eff\u771f\u3002 Webots \u5b98\u65b9\u7f51\u7ad9\uff1ahttps://cyberbotics.com/ \u7269\u7406\u5f15\u64ce\uff1a\u57fa\u4e8eODE\u6539\u8fdb \u514d\u8d39 / \u54a8\u8be2\u670d\u52a1\u6536\u8d39 \u4e4b\u524d\u4e00\u76f4\u4e0d\u6e29\u4e0d\u706b\uff0c\u8fd1\u51e0\u5e74\u4ece\u5546\u4e1a\u8bb8\u53ef\u8f6c\u6362\u4e3a\u4e86\u5f00\u6e90\u6a21\u5f0f\u3002\u521d\u6b65\u6d4b\u8bd5\u4e86\u4e00\u4e0b\uff0c\u548cV-REP\u7684\u4f7f\u7528\u65b9\u5f0f\u975e\u5e38\u76f8\u4f3c\u3002\u6ca1\u6709\u6df1\u5165\u4f7f\u7528\u8fc7\uff0c\u65e0\u6cd5\u7ed9\u51fa\u66f4\u591a\u8bc4\u4ef7\u3002 MATLAB Robotics Toolbox \u5b98\u65b9\u7f51\u7ad9\uff1ahttps://uk.mathworks.com/products/robotics.html MATLAB\u673a\u5668\u4eba\u5de5\u5177\u7bb1\u4eceMATLAB 2013\u7248\u672c\u5f00\u59cb\u5f15\u5165\uff0c\u6211\u4e86\u89e3\u7684\u60c5\u51b5\u662f\u4e00\u822c\u4ee5\u7814\u7a76\u673a\u68b0\u624b\u548c\u8def\u5f84\u89c4\u5212\u5c45\u591a\u3002Robotics Toolbox\u63d0\u4f9b\u4e86ROS\u7684\u63a5\u53e3\uff0c\u4f7f\u5f97MATLAB\u4ee3\u7801\u548cSimulink\u53ef\u4ee5\u548cROS\u5f88\u597d\u7684\u7ed3\u5408\uff0c\u6211\u89c9\u5f97\u8fd9\u662f\u6700\u5927\u7684\u4f18\u70b9\u4e86\u3002\u7f3a\u70b9\u662f\u9700\u8981\u8d2d\u4e70license. \u6211\u81ea\u5df1\u4ece\u672a\u6709\u673a\u4f1a\u5728\u9879\u76ee\u4e2d\u7528\u5230\uff0c\u6240\u4ee5\u6ca1\u6cd5\u591a\u52a0\u8bc4\u8bba\u3002 \u53c2\u8003\u8d44\u6599\uff1a \u80e1\u6625\u65ed, ROS\u63a2\u7d22\u603b\u7ed3\uff08\u4e94\u5341\u516b\uff09\u2014\u2014 Gazebo\u7269\u7406\u4eff\u771f\u5e73\u53f0 , \u53e4\u6708\u5c45 \u80e1\u6625\u65ed, ROS\u53f2\u8bdd36\u7bc7 | 25. ROS\u4e4b\u7686\u5927\u6b22\u559c\uff08Player\u4e0eStage\uff09 , \u77e5\u4e4e \u4efb\u8d5c\u5b87, \u4e3a\u4ec0\u4e48\u8981\u673a\u5668\u4eba\u4eff\u771f , \u77e5\u4e4e OpenAI, OpenAI Gym Documentation \u5e7b\u751f\u5982\u68a6, PyBullet\u5feb\u901f\u4e0a\u624b\u6559\u7a0b , CSDN \u6234\u6653\u5929\uff0c \u673a\u5668\u4eba\u5e38\u7528\u53ef\u89c6\u5316\u4eff\u771f\u5de5\u5177 - \u4e91\u98de\u673a\u5668\u4eba\u5b9e\u9a8c\u5ba4","title":"\u673a\u5668\u4eba\u5e38\u7528\u53ef\u89c6\u5316\u4eff\u771f\u5de5\u5177"},{"location":"resources/simulators/#_1","text":"\u673a\u5668\u4eba\u7cfb\u7edf\u8bbe\u8ba1\u79bb\u4e0d\u5f00\u4eff\u771f\u5de5\u5177\u7684\u652f\u6301\u3002\u673a\u5668\u4eba\u4eff\u771f\u8ba9\u6211\u4eec\u5728\u6ca1\u6709\u7269\u7406\u786c\u4ef6\u7684\u60c5\u51b5\u4e0b\u4e5f\u53ef\u4ee5\u5feb\u901f\u5bf9\u7b97\u6cd5\u8fdb\u884c\u9a8c\u8bc1\uff1b\u6216\u8005\u63d0\u9ad8\u5b89\u5168\u6027\uff0c\u907f\u514d\u5b9e\u9a8c\u635f\u4f24\u6211\u4eec\u7684\u8bbe\u5907\uff08\u6bd4\u5982\u5728\u589e\u5f3a\u5b66\u4e60\u4e2d\uff0c\u5c31\u9700\u8981\u5927\u91cfrandom\u7684exploration\uff09\u3002\u8fd9\u7bc7\u6587\u7ae0\u6211\u60f3\u4ecb\u7ecd\u4e00\u4e0b\u5f53\u524d\u4e3b\u6d41\u7684\u53ef\u89c6\u5316\u4eff\u771f\u5de5\u5177\u3002\u4e00\u822c\u6765\u8bf4\u8fd9\u4e9b\u4eff\u771f\u5de5\u5177\u5728\u7269\u7406\u5f15\u64ce\u4e4b\u4e0a\u8fdb\u884c\u5305\u88c5\uff0c\u5982\u57fa\u4e8eODE\u3001 Bullet\u7b49\u3002\u6709\u4e9b\u60c5\u51b5\u4e0b\u6211\u4eec\u53ea\u9700\u8981\u4f7f\u7528\u7269\u7406\u5f15\u64ce\u5c31\u53ef\u4ee5\u6ee1\u8db3\u9700\u8981\uff0c\u4f46\u4e00\u822c\u60c5\u51b5\u4e0b\u6211\u4eec\u4e5f\u60f3\u901a\u8fc7\u53ef\u89c6\u5316\u5e73\u53f0\u89c2\u5bdf\u673a\u5668\u4eba\u8fd0\u884c\u7684\u6b63\u786e\u6027\u3002\u4eff\u771f\u4e00\u822c\u53ea\u5728\u7cfb\u7edf\u524d\u671f\u4f7f\u7528\uff0c\u56e0\u4e3a\u771f\u5b9e\u7269\u7406\u5e73\u53f0\u4e0e\u4eff\u771f\u73af\u5883\u5b58\u5728\u5dee\u5f02\uff0c\u540e\u671f\u8fd8\u662f\u8981\u8f6c\u6362\u5230\u5b9e\u9645\u786c\u4ef6\u5e73\u53f0\u4e0a\u8fdb\u884c\u8c03\u8bd5\u3002\u5f53\u7136\u76ee\u524d\u4e5f\u6709sim-to-real\u7684\u7814\u7a76\u53ef\u4ee5\u52a0\u901f\u79fb\u690d\u7684\u8fc7\u7a0b\uff0c\u751a\u81f3\u53ef\u4ee5\u76f4\u63a5\u5c06\u4eff\u771f\u7ed3\u679c\u7528\u4e8e\u5b9e\u9645\u673a\u5668\u4eba\u5e73\u53f0\u3002","title":"\u673a\u5668\u4eba\u5e38\u7528\u53ef\u89c6\u5316\u4eff\u771f\u5de5\u5177"},{"location":"resources/simulators/#gazebo","text":"\u5b98\u65b9\u7f51\u7ad9\uff1ahttp://gazebosim.org/ \u652f\u6301\u7684\u7269\u7406\u5f15\u64ce\uff1aODE/Bullet/Simbody/DART \u5f00\u6e90\u4eff\u771f\u73af\u5883 \u5c5e\u4e8eROS\u751f\u6001 Gazebo\u662f\u76ee\u524d\u6700\u5e7f\u6cdb\u4f7f\u7528\u7684\u4eff\u771f\u73af\u5883\uff0c\u6700\u65e9\u57282004\u5e74\u7531USC Robotics Research Lab (\u5357\u52a0\u5dde\u5927\u5b66\u673a\u5668\u4eba\u5b9e\u9a8c\u5ba4) \u5f00\u53d1\u3002\u4f9d\u6258\u4e8eROS\u7684\u53d1\u5c55\uff0cGazebo\u5177\u6709\u5f88\u5f3a\u7684\u4eff\u771f\u80fd\u529b\uff0c\u540c\u65f6\u4e5f\u5728\u673a\u5668\u4eba\u7814\u7a76\u548c\u5f00\u53d1\u4e2d\u5f97\u5230\u4e86\u5e7f\u6cdb\u5e94\u7528\u3002Gazebo\u7684\u529f\u80fd\u5305\u62ec\uff1a\u52a8\u529b\u5b66\u4eff\u771f\u3001\u4f20\u611f\u5668\u4eff\u771f\u3001\u4e09\u7ef4\u73af\u5883\u4eff\u771f\uff0c\u540c\u65f6\u652f\u6301\u591a\u79cd\u673a\u5668\u4eba\u6a21\u578b\uff1a\u5305\u62ecPR2\u3001Turtlebot\u3001AR.Drone\u7b49\u3002","title":"Gazebo"},{"location":"resources/simulators/#coppeliasim-v-rep","text":"\u5b98\u65b9\u7f51\u7ad9\uff1ahttp://www.coppeliarobotics.com/ 2019\u5e7411\u6708\u7531V-REP\u66f4\u540d\u4e3aCoppeliaSim \u652f\u6301\u7684\u7269\u7406\u5f15\u64ce\uff1aODE/Bullet/Vortex/Newton \u6559\u80b2\u7248\u514d\u8d39 / \u5546\u4e1a\u7248\u6536\u8d39 CoppeliaSim\u6709\u975e\u5e38\u5b8c\u5584\u7684\u7269\u7406\u4eff\u771f\u5f15\u64ce\uff0c\u652f\u6301\u79fb\u52a8\u673a\u5668\u4eba\u3001\u98de\u884c\u673a\u5668\u4eba\u3001\u4eba\u578b\u673a\u5668\u4eba\u3001\u591a\u8db3\u673a\u5668\u4eba\u4ee5\u53ca\u591a\u8f74\u673a\u68b0\u624b\u7684\u8fd0\u52a8\u5b66\u4eff\u771f\u3002CoppeliaSim\u7684\u4eff\u771f\u7a0b\u5ea6\u975e\u5e38\u9ad8\uff0c\u4e0d\u4ec5\u53ef\u4ee5\u4eff\u771f\u673a\u5668\u4eba\u7684\u672c\u4f53\u4e0e\u591a\u79cd\u4f20\u611f\u5668\uff0c\u8fd8\u652f\u6301\u969c\u788d\u7269\u4ee5\u53ca\u5730\u578b(\u7a7a\u4e2d\uff0c\u5730\u9762\uff0c\u6c34\u5e95)\u7684\u4eff\u771f\u3002CoppeliaSim\u652f\u6301\u4f7f\u7528C/C++\uff0cPython\uff0cJAVA\uff0cLua\uff0cMatlab\u7f16\u5199\u811a\u672c\uff0c\u5341\u5206\u9002\u5408\u4e8e\u591a\u673a\u5668\u4eba\u7684\u4eff\u771f\u3002\u4f5c\u4e3a\u5df2\u7ecf\u5546\u4e1a\u5316\u7684\u8f6f\u4ef6\uff0c\u76f8\u6bd4Gazebo\u6709\u66f4\u597d\u7684\u7a33\u5b9a\u6027\u4e0e\u4ea4\u4e92\u4f53\u9a8c\u3002","title":"CoppeliaSim (V-REP)"},{"location":"resources/simulators/#pybullet","text":"\u5b98\u65b9\u7f51\u7ad9\uff1ahttps://pybullet.org/ \u7269\u7406\u5f15\u64ce\uff1aBullet \u5f00\u6e90\u4eff\u771f\u73af\u5883 PyBullet\u57fa\u4e8eBullet\u7269\u7406\u5f15\u64ce\uff0c\u662fGazebo\u5f3a\u6709\u529b\u7684\u7ade\u4e89\u5bf9\u624b\u3002PyBullet\u548cPython\u7d27\u5bc6\u7ed3\u5408\uff0c\u76ee\u524d\u5728\u589e\u5f3a\u5b66\u4e60 (RL) \u4e2d\u5e7f\u6cdb\u5e94\u7528\u3002\u8be5\u73af\u5883\u53ef\u4ee5\u7ed3\u5408TensorFlow\u5b9e\u73b0RL\u8bad\u7ec3\uff0c\u6bd4\u5982DQN\u3001PPO\u3001TRPO\u3001DDPG\u7b49\u7b97\u6cd5\u3002\u76ee\u524d\u770b\u5230\u6bd4\u8f83\u591a\u7684\u90fd\u662f\u4eff\u771f\u591a\u5173\u8282\u673a\u5668\u4eba\u3002","title":"PyBullet"},{"location":"resources/simulators/#mujoco","text":"\u5b98\u65b9\u7f51\u7ad9\uff1ahttp://www.mujoco.org OpenAI Gym\u76842D/3D\u673a\u5668\u4eba\u4eff\u771f\u4f7f\u7528\u4e86MuJoCo\u73af\u5883\u3002\u4e4b\u524d\u4e0d\u592a\u4e86\u89e3\uff0c\u4f7f\u7528Gym\u540e\u624d\u6162\u6162\u63a5\u89e6\u5230\u3002\u4fa7\u91cd\u63a7\u5236\u4e0e\u63a5\u89e6\u76f8\u5173\u7684\u4eff\u771f\u4e0e\u4f18\u5316\u3002\u7531University of Washington\u534e\u76db\u987f\u5927\u5b66\u5f00\u53d1\u7ef4\u62a4\uff08\u8be5\u6821\u548cOpenAI\u5173\u7cfb\u5f88\u8fd1\uff09\u3002\u53ef\u8bd5\u752830\u5929\uff0c\u4e4b\u540e\u9700\u8981\u6309\u5e74\u8d2d\u4e70license\u3002\u53ef\u4ee5\u591a\u5907\u51e0\u4e2a\u6559\u80b2\u90ae\u7bb1\u4f7f\u7528\u3002","title":"MuJoCo"},{"location":"resources/simulators/#stage","text":"\u5b98\u65b9\u7f51\u7ad9\uff1ahttp://wiki.ros.org/stage \u5c5e\u4e8eROS\u751f\u6001 \u7528\u4e8e\u4e8c\u7ef4\u73af\u5883\uff08\u65e0z\u8f74\u9ad8\u5ea6\u4fe1\u606f\uff09\u7684\u4eff\u771f\u5668\u3002\u6700\u65e91999\u5e74\u7531USC Robotics Research Lab\u5f00\u53d1\uff0c\u5e38\u7528\u4e8e\u8def\u5f84\u89c4\u5212\u6216\u591a\u673a\u5668\u4eba (multi-agents) \u4eff\u771f\u3002","title":"Stage"},{"location":"resources/simulators/#webots","text":"\u5b98\u65b9\u7f51\u7ad9\uff1ahttps://cyberbotics.com/ \u7269\u7406\u5f15\u64ce\uff1a\u57fa\u4e8eODE\u6539\u8fdb \u514d\u8d39 / \u54a8\u8be2\u670d\u52a1\u6536\u8d39 \u4e4b\u524d\u4e00\u76f4\u4e0d\u6e29\u4e0d\u706b\uff0c\u8fd1\u51e0\u5e74\u4ece\u5546\u4e1a\u8bb8\u53ef\u8f6c\u6362\u4e3a\u4e86\u5f00\u6e90\u6a21\u5f0f\u3002\u521d\u6b65\u6d4b\u8bd5\u4e86\u4e00\u4e0b\uff0c\u548cV-REP\u7684\u4f7f\u7528\u65b9\u5f0f\u975e\u5e38\u76f8\u4f3c\u3002\u6ca1\u6709\u6df1\u5165\u4f7f\u7528\u8fc7\uff0c\u65e0\u6cd5\u7ed9\u51fa\u66f4\u591a\u8bc4\u4ef7\u3002","title":"Webots"},{"location":"resources/simulators/#matlab-robotics-toolbox","text":"\u5b98\u65b9\u7f51\u7ad9\uff1ahttps://uk.mathworks.com/products/robotics.html MATLAB\u673a\u5668\u4eba\u5de5\u5177\u7bb1\u4eceMATLAB 2013\u7248\u672c\u5f00\u59cb\u5f15\u5165\uff0c\u6211\u4e86\u89e3\u7684\u60c5\u51b5\u662f\u4e00\u822c\u4ee5\u7814\u7a76\u673a\u68b0\u624b\u548c\u8def\u5f84\u89c4\u5212\u5c45\u591a\u3002Robotics Toolbox\u63d0\u4f9b\u4e86ROS\u7684\u63a5\u53e3\uff0c\u4f7f\u5f97MATLAB\u4ee3\u7801\u548cSimulink\u53ef\u4ee5\u548cROS\u5f88\u597d\u7684\u7ed3\u5408\uff0c\u6211\u89c9\u5f97\u8fd9\u662f\u6700\u5927\u7684\u4f18\u70b9\u4e86\u3002\u7f3a\u70b9\u662f\u9700\u8981\u8d2d\u4e70license. \u6211\u81ea\u5df1\u4ece\u672a\u6709\u673a\u4f1a\u5728\u9879\u76ee\u4e2d\u7528\u5230\uff0c\u6240\u4ee5\u6ca1\u6cd5\u591a\u52a0\u8bc4\u8bba\u3002 \u53c2\u8003\u8d44\u6599\uff1a \u80e1\u6625\u65ed, ROS\u63a2\u7d22\u603b\u7ed3\uff08\u4e94\u5341\u516b\uff09\u2014\u2014 Gazebo\u7269\u7406\u4eff\u771f\u5e73\u53f0 , \u53e4\u6708\u5c45 \u80e1\u6625\u65ed, ROS\u53f2\u8bdd36\u7bc7 | 25. ROS\u4e4b\u7686\u5927\u6b22\u559c\uff08Player\u4e0eStage\uff09 , \u77e5\u4e4e \u4efb\u8d5c\u5b87, \u4e3a\u4ec0\u4e48\u8981\u673a\u5668\u4eba\u4eff\u771f , \u77e5\u4e4e OpenAI, OpenAI Gym Documentation \u5e7b\u751f\u5982\u68a6, PyBullet\u5feb\u901f\u4e0a\u624b\u6559\u7a0b , CSDN \u6234\u6653\u5929\uff0c \u673a\u5668\u4eba\u5e38\u7528\u53ef\u89c6\u5316\u4eff\u771f\u5de5\u5177 - \u4e91\u98de\u673a\u5668\u4eba\u5b9e\u9a8c\u5ba4","title":"MATLAB Robotics Toolbox"},{"location":"resources/standard/","text":"\u673a\u5668\u4eba\u9886\u57df\u884c\u4e1a\u6807\u51c6 \u4e1a\u754c\u5728\u4ea7\u54c1\u7814\u53d1\u4e0e\u5408\u89c4\u5de5\u4f5c\u65f6\u4e0d\u53ef\u907f\u514d\u7684\u9700\u8981\u53c2\u8003\u9075\u5faa\u4e00\u4e9b\u884c\u4e1a\u901a\u884c\u6807\u51c6\u3002\u8fd9\u4e9b\u6807\u51c6\u6587\u4ef6\u4e3a\u884c\u4e1a\u5236\u5b9a\u4e86\u4e00\u5957\u901a\u884c\u9ad8\u6548\u7684\u4ea4\u6d41\u8bed\u8a00\u548c\u7cbe\u76ca\u89c4\u8303\u5316\u7684\u5de5\u4f5c\u6d41\u7a0b\uff0c\u5e76\u5bf9\u5b66\u672f\u7814\u7a76\u7684\u63a8\u5e7f\u4ea4\u6d41\u4ee5\u53ca\u540e\u671f\u4ea7\u54c1\u5316\u7ed9\u4e88\u4e86\u6781\u5927\u7684\u5e2e\u52a9\u3002\u5728\u673a\u5668\u4eba\u9886\u57df\u540c\u6837\u4e5f\u6709\u4e00\u4e9b\u5e38\u7528\u5230\u7684\u884c\u4e1a\u6807\u51c6\uff0c\u8fd9\u5176\u4e2d\u5373\u6709ISO\u8fd9\u7c7b\u56fd\u9645\u901a\u884c\u6807\u51c6\uff0c\u4e5f\u6709ASTM\u3001VDI\u8fd9\u7c7b\u5730\u533a\u6027\u6807\u51c6\uff0c\u53e6\u5916\u4e5f\u5305\u542bROS REP\u8fd9\u7c7b\u673a\u5668\u4eba\u5f00\u6e90\u5e73\u53f0\u7684\u901a\u884c\u6807\u51c6\u3002\u672c\u5217\u8868\u6574\u7406\u4e86\u56fd\u9645\u4e0a\u5e38\u7528\u7684\u673a\u5668\u4eba\u6807\u51c6\u3002\u5217\u8868\u5206\u7c7b\u4f9d\u636e\u4e3b\u8981\u6309\u7167\u5bf9\u4e8e\u6807\u51c6\u7684\u9700\u6c42\u5212\u5206\uff0c\u800c\u975e\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u79cd\u7c7b\u6216\u6807\u51c6\u7684\u5236\u5b9a\u673a\u6784\u3002 Category I. \u672f\u8bed\u516c\u7ea6 (*) \u6b64\u7c7b\u6807\u51c6\u65e8\u5728\u5236\u5b9a\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u901a\u884c\u672f\u8bed\u4e0e\u7cfb\u7edf\u7ed3\u6784\uff0c\u5bf9\u673a\u5668\u4eba\u7cfb\u7edf\u5df2\u7ea6\u5b9a\u4fd7\u6210\u7684\u57fa\u672c\u6982\u5ff5\u8fdb\u884c\u7edf\u4e00\u5b9a\u4e49\u3002 ISO 8373-2012 Robots and robotic devices \u2013 Vocabulary ISO 9787-2013 Robots and robotic devices \u2013 Coordinate systems and motion nomenciatures ISO 19649-2017 Mobile robots \u2013 Vocabulary ASTM F3200-2018 Standard Terminology for Driverless Automatic Guided Industrial Vehicles VDI 2510-2005 Automated Guided Vehicle Systems (AGVS) VDI 2510-3-2017 Automated guided vehicle systems (AGVS) Interfaces to infrastructure and peripherals VDI 2710-3-2014 Applications of simulation for automated guided vehicle systems (AGVS) VDI 4451-2-2000 Compatibility of Automated Guide Vehicle Systems (AGVS) Power supply and charging technology VDI 4451-3-1998 Compatibility of automated guided vehicle systems (AGVS) Driving and steering motors VDI 4451-4-1998 CompatIbility of automated guided vehicle systems (AGVS) Open control system for automated guided vehicles (AGV) VDI 4451-5-2005 Compatibility of Automated Guided Vehicle Systems (AGVS) Interface between command initiator and AGVS control system VDI 4451-6-2003 Compatibility of automated guided vehicle systems (AGVS) Sensor systems for navigation and control VDI 4451-7-2005 Compatibility of Automated Guided Vehicle Systems (AGVS) AGVS guidance control system REP 103 Standard Units of Measure and Coordinate Conventions REP 105 Coordinate Frames for Mobile Platforms REP 120 Coordinate Frames for Humanoid Robots Category II. \u6027\u80fd\u8bc4\u4f30 (*) \u6b64\u7c7b\u6807\u51c6\u65e8\u5728\u4e3a\u5404\u7c7b\u673a\u5668\u4eba\u7cfb\u7edf\u63d0\u4f9b\u6027\u80fd\u8bc4\u4f30\u65b9\u6cd5\u4e0a\u7684\u5b9e\u7528\u6027\u5efa\u8bae\uff0c\u4e3a\u7814\u53d1\u8005\u63d0\u4f9b\u6700\u57fa\u7840\u7684\u53ef\u884c\u6027\u5b9e\u9a8c\u65b9\u6cd5\u3002 ISO 9283-1998 Manipulating industrial robots \u2013 Performance criteria and related test methods ISO 18646-1-2016 Robotics \u2014 Performance criteria and related test methods for service robots \u2014 Part 1 Locomotion for wheeled robots ISO 18646-2-2019 Robotics \u2014 Performance criteria and related test methods for service robots \u2014 Part 2 Navigation ASTM F3218-2017 Standard Practice for Recording Environmental Effects for Utilization with A-UGV Test Methods ASTM F3244-2017 Standard Test Method for Navigation Defined Area ASTM F3327-2018 Standard Practice for Recording the A-UGV Test Configuration ASTM International Autonomous Industrial Vehicles From the Laboratory to the Factory Floor NISTIR 8168 Guideline for Automatic Guided Vehicle Calibration VDI 2710-1-2007 Interdisciplinary design of automated guided vehicle systems (AGVS) \u2014 Decision criteria for the choice of a conveyor system VDI 2710-2-2008 AGVS check list Planning support for operators and manufacturers of automated guided vehicle-systems (AGVS) VDI 2710-4-2011 Evaluation of economic efficiency of Automated Guided Vehicles Systems (AGVS) VDI 2710-5-2013 Acceptance specification for automated guided vehicle systems (AGVS) Category III. \u7cfb\u7edf\u5b89\u5168 (*) \u6b64\u7c7b\u6807\u51c6\u65e8\u5728\u4e3a\u5404\u7c7b\u673a\u5668\u4eba\u7cfb\u7edf\u9700\u8981\u6ee1\u8db3\u7684\u6700\u57fa\u672c\u5b89\u5168\u6027\u529f\u80fd\u63d0\u4f9b\u5f3a\u5236\u6027\u89c4\u8303\uff0c\u5176\u4e2d\u4e5f\u5305\u542b\u5bf9\u4e8e\u5b89\u5168\u6027\u529f\u80fd\u6027\u80fd\u6d4b\u9a8c\u7684\u5b9e\u7528\u6027\u65b9\u6cd5\u3002 ISO 10218-1-2011 Robots and robotic devices \u2013 Safety requirements for industrial robots \u2014 Part 1 Robots ISO 10218-2-2011 Robots and robotic devices \u2013 Safety requirements for industrial robots \u2014 Part 2 Robot systems and integration ISO 13482-2014 Robots and robotic devices \u2013 Safety requirements for personal care robots ISO/TR 20218-1-2018 Robotics \u2014 Safety design for industrial robot systems \u2014 Part 1 End-effectors ISO/TR 20218-2-2018 Robotics \u2014 Safety design for industrial robot systems \u2014 Part 2 Manual load unload stations ISO/TR 23482-1-2019 Robotics \u2014 Application of ISO 13482 \u2014 Part 1 Safety-related test methods ISO/TR 23482-2-2019 Robotics \u2014 Application of ISO 13482 \u2014 Part 2 Application guidelines ISO/TS 15066-2016 Robots and robotic devices \u2014 Collaborative robots BS-EN 1525-1998 Safety of industrial trucks Driverless trucks and their systems ISO 3691-4-2019 Industrial trucks \u2013 Safety requirements and verification \u2014 Part 4 Driverless industrial trucks and their systems ANSI B56.5-2012 Safety Standard For Driverless Automatic Guided Industrial Vehicles And Automated Functions Of Manned Industrial Vehicles VDI 2510-2-2013 Automated guided vehicle systems (AGVS) \u2014 Safety of AGVS Reference [1] \u673a\u5668\u4eba\u9886\u57df\u884c\u4e1a\u6807\u51c6\u6c47\u603b - \u4e91\u98de\u673a\u5668\u4eba\u5b9e\u9a8c\u5ba4 \u672c\u9875\u9762\u8d21\u732e\u8005 \uff1a xinyu-xu-dev","title":"\u673a\u5668\u4eba\u9886\u57df\u884c\u4e1a\u6807\u51c6"},{"location":"resources/standard/#_1","text":"\u4e1a\u754c\u5728\u4ea7\u54c1\u7814\u53d1\u4e0e\u5408\u89c4\u5de5\u4f5c\u65f6\u4e0d\u53ef\u907f\u514d\u7684\u9700\u8981\u53c2\u8003\u9075\u5faa\u4e00\u4e9b\u884c\u4e1a\u901a\u884c\u6807\u51c6\u3002\u8fd9\u4e9b\u6807\u51c6\u6587\u4ef6\u4e3a\u884c\u4e1a\u5236\u5b9a\u4e86\u4e00\u5957\u901a\u884c\u9ad8\u6548\u7684\u4ea4\u6d41\u8bed\u8a00\u548c\u7cbe\u76ca\u89c4\u8303\u5316\u7684\u5de5\u4f5c\u6d41\u7a0b\uff0c\u5e76\u5bf9\u5b66\u672f\u7814\u7a76\u7684\u63a8\u5e7f\u4ea4\u6d41\u4ee5\u53ca\u540e\u671f\u4ea7\u54c1\u5316\u7ed9\u4e88\u4e86\u6781\u5927\u7684\u5e2e\u52a9\u3002\u5728\u673a\u5668\u4eba\u9886\u57df\u540c\u6837\u4e5f\u6709\u4e00\u4e9b\u5e38\u7528\u5230\u7684\u884c\u4e1a\u6807\u51c6\uff0c\u8fd9\u5176\u4e2d\u5373\u6709ISO\u8fd9\u7c7b\u56fd\u9645\u901a\u884c\u6807\u51c6\uff0c\u4e5f\u6709ASTM\u3001VDI\u8fd9\u7c7b\u5730\u533a\u6027\u6807\u51c6\uff0c\u53e6\u5916\u4e5f\u5305\u542bROS REP\u8fd9\u7c7b\u673a\u5668\u4eba\u5f00\u6e90\u5e73\u53f0\u7684\u901a\u884c\u6807\u51c6\u3002\u672c\u5217\u8868\u6574\u7406\u4e86\u56fd\u9645\u4e0a\u5e38\u7528\u7684\u673a\u5668\u4eba\u6807\u51c6\u3002\u5217\u8868\u5206\u7c7b\u4f9d\u636e\u4e3b\u8981\u6309\u7167\u5bf9\u4e8e\u6807\u51c6\u7684\u9700\u6c42\u5212\u5206\uff0c\u800c\u975e\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u79cd\u7c7b\u6216\u6807\u51c6\u7684\u5236\u5b9a\u673a\u6784\u3002","title":"\u673a\u5668\u4eba\u9886\u57df\u884c\u4e1a\u6807\u51c6"},{"location":"resources/standard/#category-i","text":"(*) \u6b64\u7c7b\u6807\u51c6\u65e8\u5728\u5236\u5b9a\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u901a\u884c\u672f\u8bed\u4e0e\u7cfb\u7edf\u7ed3\u6784\uff0c\u5bf9\u673a\u5668\u4eba\u7cfb\u7edf\u5df2\u7ea6\u5b9a\u4fd7\u6210\u7684\u57fa\u672c\u6982\u5ff5\u8fdb\u884c\u7edf\u4e00\u5b9a\u4e49\u3002 ISO 8373-2012 Robots and robotic devices \u2013 Vocabulary ISO 9787-2013 Robots and robotic devices \u2013 Coordinate systems and motion nomenciatures ISO 19649-2017 Mobile robots \u2013 Vocabulary ASTM F3200-2018 Standard Terminology for Driverless Automatic Guided Industrial Vehicles VDI 2510-2005 Automated Guided Vehicle Systems (AGVS) VDI 2510-3-2017 Automated guided vehicle systems (AGVS) Interfaces to infrastructure and peripherals VDI 2710-3-2014 Applications of simulation for automated guided vehicle systems (AGVS) VDI 4451-2-2000 Compatibility of Automated Guide Vehicle Systems (AGVS) Power supply and charging technology VDI 4451-3-1998 Compatibility of automated guided vehicle systems (AGVS) Driving and steering motors VDI 4451-4-1998 CompatIbility of automated guided vehicle systems (AGVS) Open control system for automated guided vehicles (AGV) VDI 4451-5-2005 Compatibility of Automated Guided Vehicle Systems (AGVS) Interface between command initiator and AGVS control system VDI 4451-6-2003 Compatibility of automated guided vehicle systems (AGVS) Sensor systems for navigation and control VDI 4451-7-2005 Compatibility of Automated Guided Vehicle Systems (AGVS) AGVS guidance control system REP 103 Standard Units of Measure and Coordinate Conventions REP 105 Coordinate Frames for Mobile Platforms REP 120 Coordinate Frames for Humanoid Robots","title":"Category I. \u672f\u8bed\u516c\u7ea6"},{"location":"resources/standard/#category-ii","text":"(*) \u6b64\u7c7b\u6807\u51c6\u65e8\u5728\u4e3a\u5404\u7c7b\u673a\u5668\u4eba\u7cfb\u7edf\u63d0\u4f9b\u6027\u80fd\u8bc4\u4f30\u65b9\u6cd5\u4e0a\u7684\u5b9e\u7528\u6027\u5efa\u8bae\uff0c\u4e3a\u7814\u53d1\u8005\u63d0\u4f9b\u6700\u57fa\u7840\u7684\u53ef\u884c\u6027\u5b9e\u9a8c\u65b9\u6cd5\u3002 ISO 9283-1998 Manipulating industrial robots \u2013 Performance criteria and related test methods ISO 18646-1-2016 Robotics \u2014 Performance criteria and related test methods for service robots \u2014 Part 1 Locomotion for wheeled robots ISO 18646-2-2019 Robotics \u2014 Performance criteria and related test methods for service robots \u2014 Part 2 Navigation ASTM F3218-2017 Standard Practice for Recording Environmental Effects for Utilization with A-UGV Test Methods ASTM F3244-2017 Standard Test Method for Navigation Defined Area ASTM F3327-2018 Standard Practice for Recording the A-UGV Test Configuration ASTM International Autonomous Industrial Vehicles From the Laboratory to the Factory Floor NISTIR 8168 Guideline for Automatic Guided Vehicle Calibration VDI 2710-1-2007 Interdisciplinary design of automated guided vehicle systems (AGVS) \u2014 Decision criteria for the choice of a conveyor system VDI 2710-2-2008 AGVS check list Planning support for operators and manufacturers of automated guided vehicle-systems (AGVS) VDI 2710-4-2011 Evaluation of economic efficiency of Automated Guided Vehicles Systems (AGVS) VDI 2710-5-2013 Acceptance specification for automated guided vehicle systems (AGVS)","title":"Category II. \u6027\u80fd\u8bc4\u4f30"},{"location":"resources/standard/#category-iii","text":"(*) \u6b64\u7c7b\u6807\u51c6\u65e8\u5728\u4e3a\u5404\u7c7b\u673a\u5668\u4eba\u7cfb\u7edf\u9700\u8981\u6ee1\u8db3\u7684\u6700\u57fa\u672c\u5b89\u5168\u6027\u529f\u80fd\u63d0\u4f9b\u5f3a\u5236\u6027\u89c4\u8303\uff0c\u5176\u4e2d\u4e5f\u5305\u542b\u5bf9\u4e8e\u5b89\u5168\u6027\u529f\u80fd\u6027\u80fd\u6d4b\u9a8c\u7684\u5b9e\u7528\u6027\u65b9\u6cd5\u3002 ISO 10218-1-2011 Robots and robotic devices \u2013 Safety requirements for industrial robots \u2014 Part 1 Robots ISO 10218-2-2011 Robots and robotic devices \u2013 Safety requirements for industrial robots \u2014 Part 2 Robot systems and integration ISO 13482-2014 Robots and robotic devices \u2013 Safety requirements for personal care robots ISO/TR 20218-1-2018 Robotics \u2014 Safety design for industrial robot systems \u2014 Part 1 End-effectors ISO/TR 20218-2-2018 Robotics \u2014 Safety design for industrial robot systems \u2014 Part 2 Manual load unload stations ISO/TR 23482-1-2019 Robotics \u2014 Application of ISO 13482 \u2014 Part 1 Safety-related test methods ISO/TR 23482-2-2019 Robotics \u2014 Application of ISO 13482 \u2014 Part 2 Application guidelines ISO/TS 15066-2016 Robots and robotic devices \u2014 Collaborative robots BS-EN 1525-1998 Safety of industrial trucks Driverless trucks and their systems ISO 3691-4-2019 Industrial trucks \u2013 Safety requirements and verification \u2014 Part 4 Driverless industrial trucks and their systems ANSI B56.5-2012 Safety Standard For Driverless Automatic Guided Industrial Vehicles And Automated Functions Of Manned Industrial Vehicles VDI 2510-2-2013 Automated guided vehicle systems (AGVS) \u2014 Safety of AGVS","title":"Category III. \u7cfb\u7edf\u5b89\u5168"},{"location":"resources/standard/#reference","text":"[1] \u673a\u5668\u4eba\u9886\u57df\u884c\u4e1a\u6807\u51c6\u6c47\u603b - \u4e91\u98de\u673a\u5668\u4eba\u5b9e\u9a8c\u5ba4 \u672c\u9875\u9762\u8d21\u732e\u8005 \uff1a xinyu-xu-dev","title":"Reference"},{"location":"ros/","text":"Robot Operating System (ROS) ROS (Robot Operating System) \u662f\u76ee\u524d\u6700\u4e3a\u9886\u5148\u7684\u673a\u5668\u4eba\u64cd\u4f5c\u7cfb\u7edf\uff0c\u88ab\u5e7f\u6cdb\u7528\u4e8e\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u63a7\u5236\u4e0e\u4eff\u771f\u4e2d\u3002 (\u672c\u6761\u76ee\u9700\u8981\u5b8c\u5584\uff0c \u7acb\u523b\u53c2\u4e0e\u77e5\u8bc6\u516c\u5171\u7f16\u8f91 ) \u672c\u6761\u76ee\u8d21\u732e\u8005 \uff1a automaticdai","title":"Robot Operating System (ROS)"},{"location":"ros/#robot-operating-system-ros","text":"ROS (Robot Operating System) \u662f\u76ee\u524d\u6700\u4e3a\u9886\u5148\u7684\u673a\u5668\u4eba\u64cd\u4f5c\u7cfb\u7edf\uff0c\u88ab\u5e7f\u6cdb\u7528\u4e8e\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u63a7\u5236\u4e0e\u4eff\u771f\u4e2d\u3002 (\u672c\u6761\u76ee\u9700\u8981\u5b8c\u5584\uff0c \u7acb\u523b\u53c2\u4e0e\u77e5\u8bc6\u516c\u5171\u7f16\u8f91 ) \u672c\u6761\u76ee\u8d21\u732e\u8005 \uff1a automaticdai","title":"Robot Operating System (ROS)"},{"location":"self-driving/","text":"\u81ea\u52a8\u9a7e\u9a76\u6280\u672f\u6307\u5357 --- A Guide to Autonomous Driving \u672c\u624b\u518c\u63d0\u4f9b\u6700\u5168\u7684\u81ea\u52a8\u9a7e\u9a76\u6280\u672f\u5386\u53f2\u3001\u73b0\u72b6\u4e0e\u53d1\u5c55\u8d8b\u52bf\u3002 \u6700\u521d\u53d1\u5e03\u4e8e\uff1a \u4e91\u98de\u673a\u5668\u4eba\u5b9e\u9a8c\u5ba4 -- \u8ba9\u673a\u5668\u5145\u6ee1\u667a\u6167\uff01 (\u672c\u6761\u76ee\u9700\u8981\u5b8c\u5584\uff0c \u7acb\u523b\u53c2\u4e0e\u77e5\u8bc6\u516c\u5171\u7f16\u8f91 ) \u672c\u6761\u76ee\u8d21\u732e\u8005: automaticdai","title":"\u81ea\u52a8\u9a7e\u9a76\u6280\u672f\u6307\u5357"},{"location":"self-driving/#_1","text":"--- A Guide to Autonomous Driving \u672c\u624b\u518c\u63d0\u4f9b\u6700\u5168\u7684\u81ea\u52a8\u9a7e\u9a76\u6280\u672f\u5386\u53f2\u3001\u73b0\u72b6\u4e0e\u53d1\u5c55\u8d8b\u52bf\u3002 \u6700\u521d\u53d1\u5e03\u4e8e\uff1a \u4e91\u98de\u673a\u5668\u4eba\u5b9e\u9a8c\u5ba4 -- \u8ba9\u673a\u5668\u5145\u6ee1\u667a\u6167\uff01 (\u672c\u6761\u76ee\u9700\u8981\u5b8c\u5584\uff0c \u7acb\u523b\u53c2\u4e0e\u77e5\u8bc6\u516c\u5171\u7f16\u8f91 ) \u672c\u6761\u76ee\u8d21\u732e\u8005: automaticdai","title":"\u81ea\u52a8\u9a7e\u9a76\u6280\u672f\u6307\u5357"},{"location":"self-driving/algorithm/decision_making/","text":"\u51b3\u7b56 (Decision Making Process) \u51b3\u5b9a\u4e86\u4e00\u4e2a\u7cfb\u7edf\u7684\u6027\u8d28\u662f\u81ea\u52a8\u7cfb\u7edf (Automated Systems) \u8fd8\u662f\u81ea\u4e3b\u7cfb\u7edf (Autonoumous Systems)\u3002","title":"\u51b3\u7b56 (Decision Making Process)"},{"location":"self-driving/algorithm/decision_making/#decision-making-process","text":"\u51b3\u5b9a\u4e86\u4e00\u4e2a\u7cfb\u7edf\u7684\u6027\u8d28\u662f\u81ea\u52a8\u7cfb\u7edf (Automated Systems) \u8fd8\u662f\u81ea\u4e3b\u7cfb\u7edf (Autonoumous Systems)\u3002","title":"\u51b3\u7b56 (Decision Making Process)"},{"location":"self-driving/algorithm/image_processing/","text":"\u56fe\u50cf\u8bc6\u522b\u4e0e\u5206\u5272","title":"\u56fe\u50cf\u8bc6\u522b\u4e0e\u5206\u5272"},{"location":"self-driving/algorithm/image_processing/#_1","text":"","title":"\u56fe\u50cf\u8bc6\u522b\u4e0e\u5206\u5272"},{"location":"self-driving/algorithm/laser_processing/","text":"\u6fc0\u5149\u70b9\u4e91\u6570\u636e\u5904\u7406","title":"\u6fc0\u5149\u70b9\u4e91\u6570\u636e\u5904\u7406"},{"location":"self-driving/algorithm/laser_processing/#_1","text":"","title":"\u6fc0\u5149\u70b9\u4e91\u6570\u636e\u5904\u7406"},{"location":"self-driving/algorithm/localisation/","text":"\u5730\u56fe\u4e0e\u5b9a\u4f4d Map Representation metric : The metric framework is the most common for humans and considers a two-dimensional space in which it places the objects. The objects are placed with precise coordinates. This representation is very useful, but is sensitive to noise and it is difficult to calculate the distances precisely . topological : The topological framework only considers places and relations between them. Often, the distances between places are stored. The map is then a graph, in which the nodes corresponds to places and arcs correspond to the paths . Voronoi diagram Grid Advantages of topological maps: Only sparse data storage Representation matches problem description: e.g. instruct robot to move between discrete locations Recognition only requires consistency, not accuracy Advantages of metric maps Can extrapolate between known locations Can derive novel shortcuts Common representation to fuse sensor/motor data","title":"\u5730\u56fe\u4e0e\u5b9a\u4f4d"},{"location":"self-driving/algorithm/localisation/#_1","text":"","title":"\u5730\u56fe\u4e0e\u5b9a\u4f4d"},{"location":"self-driving/algorithm/localisation/#map-representation","text":"metric : The metric framework is the most common for humans and considers a two-dimensional space in which it places the objects. The objects are placed with precise coordinates. This representation is very useful, but is sensitive to noise and it is difficult to calculate the distances precisely . topological : The topological framework only considers places and relations between them. Often, the distances between places are stored. The map is then a graph, in which the nodes corresponds to places and arcs correspond to the paths . Voronoi diagram Grid","title":"Map Representation"},{"location":"self-driving/algorithm/localisation/#advantages-of-topological-maps","text":"Only sparse data storage Representation matches problem description: e.g. instruct robot to move between discrete locations Recognition only requires consistency, not accuracy","title":"Advantages of topological maps:"},{"location":"self-driving/algorithm/localisation/#advantages-of-metric-maps","text":"Can extrapolate between known locations Can derive novel shortcuts Common representation to fuse sensor/motor data","title":"Advantages of metric maps"},{"location":"self-driving/algorithm/main/","text":"\u81ea\u52a8\u9a7e\u9a76\u6838\u5fc3\u7b97\u6cd5 \u672c\u7ae0\u4ecb\u7ecd\u81ea\u52a8\u9a7e\u9a76\u7684\u7075\u9b42 - \u7b97\u6cd5\u3002","title":"\u81ea\u52a8\u9a7e\u9a76\u6838\u5fc3\u7b97\u6cd5"},{"location":"self-driving/algorithm/main/#_1","text":"\u672c\u7ae0\u4ecb\u7ecd\u81ea\u52a8\u9a7e\u9a76\u7684\u7075\u9b42 - \u7b97\u6cd5\u3002","title":"\u81ea\u52a8\u9a7e\u9a76\u6838\u5fc3\u7b97\u6cd5"},{"location":"self-driving/algorithm/nlp/","text":"\u81ea\u7136\u8bed\u8a00\u8bc6\u522b\u4e0e\u4ea4\u4e92","title":"\u81ea\u7136\u8bed\u8a00\u8bc6\u522b\u4e0e\u4ea4\u4e92"},{"location":"self-driving/algorithm/nlp/#_1","text":"","title":"\u81ea\u7136\u8bed\u8a00\u8bc6\u522b\u4e0e\u4ea4\u4e92"},{"location":"self-driving/algorithm/path_planning/","text":"\u8def\u5f84\u89c4\u5212 Q: \u8def\u5f84\u89c4\u5212\u89e3\u51b3\u4e86\u4ec0\u4e48\u95ee\u9898\uff1f A: \u4e0a\u5c42\uff1arouting\u8def\u5f84\u89c4\u5212\u95ee\u9898\uff08\u540c\u5730\u56fe\u5bfc\u822a\uff09\uff0cmap + location + destination\uff1b\u4e0b\u5c42\uff1amotion planning\u5728\u5df2\u77e5\u5468\u56f4\u73af\u5883\u6570\u636e\u7684\u524d\u63d0\u4e0b\uff0c\u63d0\u4f9b\u673a\u5668\u4eba\u884c\u52a8\u8def\u5f84Trajectory + timestamp \u7684\u6700\u4f18\u89e3\u3002\u53ef\u8f6c\u6362\u6210constrained optimization problem. \u8def\u5f84\u89c4\u5212\u7684\u6a21\u578b \u8def\u5f84\u89c4\u5212\u5206\u4e3a\u4e09\u4e2a\u9886\u57df\uff0c (1) \u70b9\uff0c\u7ebf\u7ec4\u6210\u7684\u56fe\u8bba\u6a21\u5f0f: graph (2) \u8fde\u7eed\u4e8c\u7ef4\u7a7a\u95f4\u7684\u56db\u53c9\u6811\u6a21\u5f0f: grid (3) \u8fde\u7eed\u4e09\u7ef4\u7a7a\u95f4\u7684\u516b\u53c9\u6811\u6a21\u5f0f: cube Ideas \u969c\u788d\u7269\u4e0d\u7ba1\u662f\u52a8\u6001\u8fd8\u662f\u9759\u6001\uff0c\u907f\u969c\u90fd\u662f\u4e00\u6837\u7684\u3002\u4e0d\u540c\u5728\u4e8e\u52a8\u6001\u73af\u5883\u4e0b\u5730\u56fe\u662f\u8fde\u7eed\u53d8\u5316\u7684\uff0c\u8def\u5f84\u89c4\u5212\u4e0d\u80fd\u5355\u7eaf\u7684\u9760\u5168\u5c40\u89c4\u5212\u7b97\u6cd5\uff0c\u800c\u5f80\u5f80\u662f\u5168\u5c40\u4e0e\u5c40\u90e8\u89c4\u5212\u76f8\u7ed3\u5408\u3002 \u89e3\u51b3\u6b7b\u9501\u548c\u4ea4\u901a\u5835\u585e\uff1a\u591a\u5bfc\u822a\u5668\u534f\u8c03\u89c4\u5212 \u5c40\u90e8\u8def\u5f84\u89c4\u5212\u5fc5\u987b\u7ed3\u5408\u8f66\u8f86\u52a8\u529b\u5b66 \u8def\u9762condition\u7684\u8865\u507f\u6a21\u578b \u7ed3\u5408\u4ea4\u901a\u6cd5\u5f8b\u6cd5\u89c4\u7684\u7ea6\u675f \u7ed3\u5408\u51b3\u7b56\u6a21\u578b \u76f4\u884c \u907f\u8ba9 \u505c\u6b62 \u5239\u8f66 \u7d27\u6025\u5236\u52a8 \u8def\u5f84\u89c4\u5212\u65b9\u6cd5\u6bd4\u8f83","title":"\u8def\u5f84\u89c4\u5212"},{"location":"self-driving/algorithm/path_planning/#_1","text":"Q: \u8def\u5f84\u89c4\u5212\u89e3\u51b3\u4e86\u4ec0\u4e48\u95ee\u9898\uff1f A: \u4e0a\u5c42\uff1arouting\u8def\u5f84\u89c4\u5212\u95ee\u9898\uff08\u540c\u5730\u56fe\u5bfc\u822a\uff09\uff0cmap + location + destination\uff1b\u4e0b\u5c42\uff1amotion planning\u5728\u5df2\u77e5\u5468\u56f4\u73af\u5883\u6570\u636e\u7684\u524d\u63d0\u4e0b\uff0c\u63d0\u4f9b\u673a\u5668\u4eba\u884c\u52a8\u8def\u5f84Trajectory + timestamp \u7684\u6700\u4f18\u89e3\u3002\u53ef\u8f6c\u6362\u6210constrained optimization problem.","title":"\u8def\u5f84\u89c4\u5212"},{"location":"self-driving/algorithm/path_planning/#_2","text":"\u8def\u5f84\u89c4\u5212\u5206\u4e3a\u4e09\u4e2a\u9886\u57df\uff0c (1) \u70b9\uff0c\u7ebf\u7ec4\u6210\u7684\u56fe\u8bba\u6a21\u5f0f: graph (2) \u8fde\u7eed\u4e8c\u7ef4\u7a7a\u95f4\u7684\u56db\u53c9\u6811\u6a21\u5f0f: grid (3) \u8fde\u7eed\u4e09\u7ef4\u7a7a\u95f4\u7684\u516b\u53c9\u6811\u6a21\u5f0f: cube","title":"\u8def\u5f84\u89c4\u5212\u7684\u6a21\u578b"},{"location":"self-driving/algorithm/path_planning/#ideas","text":"\u969c\u788d\u7269\u4e0d\u7ba1\u662f\u52a8\u6001\u8fd8\u662f\u9759\u6001\uff0c\u907f\u969c\u90fd\u662f\u4e00\u6837\u7684\u3002\u4e0d\u540c\u5728\u4e8e\u52a8\u6001\u73af\u5883\u4e0b\u5730\u56fe\u662f\u8fde\u7eed\u53d8\u5316\u7684\uff0c\u8def\u5f84\u89c4\u5212\u4e0d\u80fd\u5355\u7eaf\u7684\u9760\u5168\u5c40\u89c4\u5212\u7b97\u6cd5\uff0c\u800c\u5f80\u5f80\u662f\u5168\u5c40\u4e0e\u5c40\u90e8\u89c4\u5212\u76f8\u7ed3\u5408\u3002 \u89e3\u51b3\u6b7b\u9501\u548c\u4ea4\u901a\u5835\u585e\uff1a\u591a\u5bfc\u822a\u5668\u534f\u8c03\u89c4\u5212 \u5c40\u90e8\u8def\u5f84\u89c4\u5212\u5fc5\u987b\u7ed3\u5408\u8f66\u8f86\u52a8\u529b\u5b66 \u8def\u9762condition\u7684\u8865\u507f\u6a21\u578b \u7ed3\u5408\u4ea4\u901a\u6cd5\u5f8b\u6cd5\u89c4\u7684\u7ea6\u675f \u7ed3\u5408\u51b3\u7b56\u6a21\u578b \u76f4\u884c \u907f\u8ba9 \u505c\u6b62 \u5239\u8f66 \u7d27\u6025\u5236\u52a8","title":"Ideas"},{"location":"self-driving/algorithm/path_planning/#_3","text":"","title":"\u8def\u5f84\u89c4\u5212\u65b9\u6cd5\u6bd4\u8f83"},{"location":"self-driving/algorithm/sw_overview/","text":"\u7cfb\u7edf\u8f6f\u4ef6\u6846\u67b6\u603b\u89c8 Classic Modules ACC(Adaptive Cruise Control\u81ea\u9002\u5e94\u5de1\u822a\u63a7\u5236) AEB(Autonomous Emergency Braking \u81ea\u52a8\u7d27\u6025\u5236\u52a8) LKA(Lane Keeping Assist \u8f85\u52a9\u8f66\u9053\u4fdd\u6301) PPS(Pedestrian Protection System \u884c\u4eba\u4fdd\u62a4\u7cfb\u7edf) TSR(Traffic Sign Recognition\u4ea4\u901a\u6807\u5fd7\u8bc6\u522b)","title":"\u7cfb\u7edf\u8f6f\u4ef6\u6846\u67b6\u603b\u89c8"},{"location":"self-driving/algorithm/sw_overview/#_1","text":"","title":"\u7cfb\u7edf\u8f6f\u4ef6\u6846\u67b6\u603b\u89c8"},{"location":"self-driving/algorithm/sw_overview/#classic-modules","text":"ACC(Adaptive Cruise Control\u81ea\u9002\u5e94\u5de1\u822a\u63a7\u5236) AEB(Autonomous Emergency Braking \u81ea\u52a8\u7d27\u6025\u5236\u52a8) LKA(Lane Keeping Assist \u8f85\u52a9\u8f66\u9053\u4fdd\u6301) PPS(Pedestrian Protection System \u884c\u4eba\u4fdd\u62a4\u7cfb\u7edf) TSR(Traffic Sign Recognition\u4ea4\u901a\u6807\u5fd7\u8bc6\u522b)","title":"Classic Modules"},{"location":"self-driving/casestudy/apollo/","text":"\u767e\u5ea6\u65e0\u4eba\u9a7e\u9a76 http://apollo.auto/ \u4ee5\u4e0b\u8bc4\u8bba\u57fa\u4e8e\u77e5\u4e4e\u7528\u6237\u5bf9\u4e8eApollo 1.0\u7684\u8bc4\u4ef7: \u5b9a\u4f4d Localization\uff1aRTK GPS + IMU\uff0c\u6ca1\u770b\u5230 Kalman Filter\uff1b \u611f\u77e5 Perception\uff1a\u8fd9\u5757\u5e94\u8be5\u662f\u7528\u6765\u8bc6\u522b\u969c\u788d\u7269\uff0c\u8f66\u9053\u7ebf\uff0c\u4ea4\u901a\u706f\u7b49\u5404\u79cd\u4fe1\u606f\u7684\u6a21\u5757\uff0c\u7b97\u662f\u65e0\u4eba\u9a7e\u9a76\u7cfb\u7edf\u4e2d\u975e\u5e38\u5173\u952e\u7684\u4e00\u5757\u3002\u8fd9\u6b21\u767e\u5ea6\u5e76\u6ca1\u6709\u516c\u5f00\u8fd9\u4e2a\uff1b \u9884\u6d4b Prediction\uff1a\u8fd9\u4e2a\u4e3b\u8981\u662f\u57fa\u4e8e\u611f\u77e5\u4fe1\u606f\u8fdb\u884c\u9884\u6d4b\uff0c\u6240\u4ee5\u4e5f\u6ca1\u6709\u516c\u5f00\uff1b \u51b3\u7b56 Decision\uff1a\u8fd9\u4e2a\u5c5e\u4e8e\u65e0\u4eba\u8f66\u7cfb\u7edf\u6700\u9ad8\u5c42\u7684\u51b3\u7b56\u7cfb\u7edf\uff0c\u5b83\u7684\u4f5c\u7528\u662f\u57fa\u4e8e\u73b0\u6709\u7684\u4fe1\u606f\u6765\u5224\u65ad\u4e0b\u4e00\u6b65\u52a8\u4f5c\uff0c\u6ca1\u6709\u611f\u77e5\uff0c\u6240\u4ee5\u8fd9\u90e8\u5206\u4e5f\u6ca1\u516c\u5f00\uff1b \u89c4\u5212 Planning\uff1a\u8fd9\u4e2a\u5e94\u8be5\u662f\u4e00\u822c\u610f\u4e49\u4e0a\u7684\u5168\u5c40\u89c4\u5212\u5668\uff0c\u7528\u9014\u662f\u627e\u5230\u53ef\u884c\u8def\u5f84\uff0c\u4e00\u822c\u4f1a\u91c7\u7528\u5404\u79cd\u5404\u6837\u7684\u82b1\u5f0f\u89c4\u5212\u7b97\u6cd5\uff0c\u7136\u540e\u8fd9\u6b21 Apollo \u4e2d\u4e5f\u6ca1\u6709\u63d0\u4f9b\u8fd9\u90e8\u5206\u5185\u5bb9\uff1b \u63a7\u5236 Control\uff1a\u8fd9\u4e2a\u5176\u5b9e\u5c31\u662f\u5c40\u90e8\u89c4\u5212\u5668\uff0c\u7528\u9014\u662f\u8ba9\u65e0\u4eba\u8f66\u6cbf\u7740\u89c4\u5212\u7684\u8f68\u8ff9\u8fd0\u884c\uff0c\u8fd9\u4e2a\u9879\u76ee\u4e2d\u63d0\u4f9b\u4e86\u57fa\u4e8e LQR \u7684\u7b97\u6cd5\uff0c\u8fd9\u90e8\u5206\u8fd8\u7b97\u53ef\u4ee5\u3002","title":"\u767e\u5ea6\u65e0\u4eba\u9a7e\u9a76"},{"location":"self-driving/casestudy/apollo/#_1","text":"http://apollo.auto/ \u4ee5\u4e0b\u8bc4\u8bba\u57fa\u4e8e\u77e5\u4e4e\u7528\u6237\u5bf9\u4e8eApollo 1.0\u7684\u8bc4\u4ef7: \u5b9a\u4f4d Localization\uff1aRTK GPS + IMU\uff0c\u6ca1\u770b\u5230 Kalman Filter\uff1b \u611f\u77e5 Perception\uff1a\u8fd9\u5757\u5e94\u8be5\u662f\u7528\u6765\u8bc6\u522b\u969c\u788d\u7269\uff0c\u8f66\u9053\u7ebf\uff0c\u4ea4\u901a\u706f\u7b49\u5404\u79cd\u4fe1\u606f\u7684\u6a21\u5757\uff0c\u7b97\u662f\u65e0\u4eba\u9a7e\u9a76\u7cfb\u7edf\u4e2d\u975e\u5e38\u5173\u952e\u7684\u4e00\u5757\u3002\u8fd9\u6b21\u767e\u5ea6\u5e76\u6ca1\u6709\u516c\u5f00\u8fd9\u4e2a\uff1b \u9884\u6d4b Prediction\uff1a\u8fd9\u4e2a\u4e3b\u8981\u662f\u57fa\u4e8e\u611f\u77e5\u4fe1\u606f\u8fdb\u884c\u9884\u6d4b\uff0c\u6240\u4ee5\u4e5f\u6ca1\u6709\u516c\u5f00\uff1b \u51b3\u7b56 Decision\uff1a\u8fd9\u4e2a\u5c5e\u4e8e\u65e0\u4eba\u8f66\u7cfb\u7edf\u6700\u9ad8\u5c42\u7684\u51b3\u7b56\u7cfb\u7edf\uff0c\u5b83\u7684\u4f5c\u7528\u662f\u57fa\u4e8e\u73b0\u6709\u7684\u4fe1\u606f\u6765\u5224\u65ad\u4e0b\u4e00\u6b65\u52a8\u4f5c\uff0c\u6ca1\u6709\u611f\u77e5\uff0c\u6240\u4ee5\u8fd9\u90e8\u5206\u4e5f\u6ca1\u516c\u5f00\uff1b \u89c4\u5212 Planning\uff1a\u8fd9\u4e2a\u5e94\u8be5\u662f\u4e00\u822c\u610f\u4e49\u4e0a\u7684\u5168\u5c40\u89c4\u5212\u5668\uff0c\u7528\u9014\u662f\u627e\u5230\u53ef\u884c\u8def\u5f84\uff0c\u4e00\u822c\u4f1a\u91c7\u7528\u5404\u79cd\u5404\u6837\u7684\u82b1\u5f0f\u89c4\u5212\u7b97\u6cd5\uff0c\u7136\u540e\u8fd9\u6b21 Apollo \u4e2d\u4e5f\u6ca1\u6709\u63d0\u4f9b\u8fd9\u90e8\u5206\u5185\u5bb9\uff1b \u63a7\u5236 Control\uff1a\u8fd9\u4e2a\u5176\u5b9e\u5c31\u662f\u5c40\u90e8\u89c4\u5212\u5668\uff0c\u7528\u9014\u662f\u8ba9\u65e0\u4eba\u8f66\u6cbf\u7740\u89c4\u5212\u7684\u8f68\u8ff9\u8fd0\u884c\uff0c\u8fd9\u4e2a\u9879\u76ee\u4e2d\u63d0\u4f9b\u4e86\u57fa\u4e8e LQR \u7684\u7b97\u6cd5\uff0c\u8fd9\u90e8\u5206\u8fd8\u7b97\u53ef\u4ee5\u3002","title":"\u767e\u5ea6\u65e0\u4eba\u9a7e\u9a76"},{"location":"self-driving/casestudy/main/","text":"\u81ea\u52a8\u9a7e\u9a76\u6848\u4f8b \u672c\u7ae0\u63d0\u4f9b\u4e00\u4e9b\u81ea\u52a8\u9a7e\u9a76\u7684\u5e94\u7528\u6848\u4f8b\u3002","title":"\u81ea\u52a8\u9a7e\u9a76\u6848\u4f8b"},{"location":"self-driving/casestudy/main/#_1","text":"\u672c\u7ae0\u63d0\u4f9b\u4e00\u4e9b\u81ea\u52a8\u9a7e\u9a76\u7684\u5e94\u7528\u6848\u4f8b\u3002","title":"\u81ea\u52a8\u9a7e\u9a76\u6848\u4f8b"},{"location":"self-driving/casestudy/tesla/","text":"Tesla","title":"Tesla"},{"location":"self-driving/casestudy/tesla/#tesla","text":"","title":"Tesla"},{"location":"self-driving/casestudy/tusimple/","text":"\u56fe\u68ee\u672a\u6765","title":"\u56fe\u68ee\u672a\u6765"},{"location":"self-driving/casestudy/tusimple/#_1","text":"","title":"\u56fe\u68ee\u672a\u6765"},{"location":"self-driving/casestudy/uber/","text":"Uber","title":"Uber"},{"location":"self-driving/casestudy/uber/#uber","text":"","title":"Uber"},{"location":"self-driving/casestudy/uisee/","text":"\u9a6d\u52bf\u79d1\u6280","title":"\u9a6d\u52bf\u79d1\u6280"},{"location":"self-driving/casestudy/uisee/#_1","text":"","title":"\u9a6d\u52bf\u79d1\u6280"},{"location":"self-driving/casestudy/waymo/","text":"Waymo","title":"Waymo"},{"location":"self-driving/casestudy/waymo/#waymo","text":"","title":"Waymo"},{"location":"self-driving/hardware/camera/","text":"\u89c6\u89c9\u4f20\u611f\u5668","title":"\u89c6\u89c9\u4f20\u611f\u5668"},{"location":"self-driving/hardware/camera/#_1","text":"","title":"\u89c6\u89c9\u4f20\u611f\u5668"},{"location":"self-driving/hardware/ccu/","text":"\u4e2d\u63a7\u5355\u5143 (AI\u82af\u7247, GPGPU)","title":"\u4e2d\u63a7\u5355\u5143 (AI\u82af\u7247, GPGPU)"},{"location":"self-driving/hardware/ccu/#ai-gpgpu","text":"","title":"\u4e2d\u63a7\u5355\u5143 (AI\u82af\u7247, GPGPU)"},{"location":"self-driving/hardware/communication/","text":"\u8f66\u5185\u603b\u7ebf","title":"\u8f66\u5185\u603b\u7ebf"},{"location":"self-driving/hardware/communication/#_1","text":"","title":"\u8f66\u5185\u603b\u7ebf"},{"location":"self-driving/hardware/drive_by_wire/","text":"Drive-by-wire","title":"Drive-by-wire"},{"location":"self-driving/hardware/drive_by_wire/#drive-by-wire","text":"","title":"Drive-by-wire"},{"location":"self-driving/hardware/hw_overview/","text":"\u786c\u4ef6\u603b\u89c8 \u81ea\u52a8\u9a7e\u9a76\u7684\u786c\u4ef6\u5305\u542b\u4ee5\u4e0b\u51e0\u4e2a\u90e8\u5206\uff1a \u4f20\u611f\u5355\u5143 \u6267\u884c\u673a\u6784 \u8f66\u63a7\u4e3b\u673a \u5e95\u76d8\u7cfb\u7edf","title":"\u786c\u4ef6\u603b\u89c8"},{"location":"self-driving/hardware/hw_overview/#_1","text":"\u81ea\u52a8\u9a7e\u9a76\u7684\u786c\u4ef6\u5305\u542b\u4ee5\u4e0b\u51e0\u4e2a\u90e8\u5206\uff1a \u4f20\u611f\u5355\u5143 \u6267\u884c\u673a\u6784 \u8f66\u63a7\u4e3b\u673a \u5e95\u76d8\u7cfb\u7edf","title":"\u786c\u4ef6\u603b\u89c8"},{"location":"self-driving/hardware/main/","text":"\u81ea\u52a8\u9a7e\u9a76\u786c\u4ef6 \u672c\u7ae0\u4ecb\u7ecd\u81ea\u52a8\u9a7e\u9a76\u7684\u786c\u4ef6\u6784\u6210\u3002","title":"\u81ea\u52a8\u9a7e\u9a76\u786c\u4ef6"},{"location":"self-driving/hardware/main/#_1","text":"\u672c\u7ae0\u4ecb\u7ecd\u81ea\u52a8\u9a7e\u9a76\u7684\u786c\u4ef6\u6784\u6210\u3002","title":"\u81ea\u52a8\u9a7e\u9a76\u786c\u4ef6"},{"location":"self-driving/hardware/sensors/","text":"\u611f\u77e5\u4f20\u611f\u5668","title":"\u611f\u77e5\u4f20\u611f\u5668"},{"location":"self-driving/hardware/sensors/#_1","text":"","title":"\u611f\u77e5\u4f20\u611f\u5668"},{"location":"self-driving/intro/category/","text":"\u81ea\u4e3b\u6027\u7b49\u7ea7\u5206\u7c7b \u81ea\u52a8\u9a7e\u9a76\u6309\u7167\u81ea\u4e3b\u6027\u7a0b\u5ea6\u53ef\u4ee5\u5206\u62106\u4e2a\u7b49\u7ea7\uff08SAE\uff09\uff1a","title":"\u81ea\u4e3b\u6027\u7b49\u7ea7\u5206\u7c7b"},{"location":"self-driving/intro/category/#_1","text":"\u81ea\u52a8\u9a7e\u9a76\u6309\u7167\u81ea\u4e3b\u6027\u7a0b\u5ea6\u53ef\u4ee5\u5206\u62106\u4e2a\u7b49\u7ea7\uff08SAE\uff09\uff1a","title":"\u81ea\u4e3b\u6027\u7b49\u7ea7\u5206\u7c7b"},{"location":"self-driving/intro/define/","text":"\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u5b9a\u4e49 \u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf \u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u662f\u7531\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u3001\u4ea4\u901a\u57fa\u7840\u8bbe\u65bd\u3001\u901a\u4fe1\u8bbe\u65bd\u3001\u540e\u53f0\u7cfb\u7edf\u5171\u540c\u7ec4\u6210\u7684\u5927\u578b\u7cfb\u7edf\u3002 \u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86 \u5e7f\u4e49\u4e0a \u7684\u81ea\u52a8\u9a7e\u9a76\u662f\u6307\uff1a\u542b\u6709\u51b3\u7b56\u529f\u80fd\u5e76\u53ef\u4ee5\u5f71\u54cd\u3001\u5e72\u9884\u5f53\u524d\u884c\u9a76\u72b6\u6001\u7684\u8f66\u8f86\uff1b \u72ed\u4e49\u4e0a \u7684\u81ea\u52a8\u9a7e\u9a76\u662f\u6307\uff1a\u65e0\u4eba\u7c7b\u9a7e\u9a76\u5458\uff0c\u7531\u8ba1\u7b97\u673a\u611f\u77e5\u3001\u51b3\u7b56\u548c\u64cd\u4f5c\u7684\u5168\u81ea\u4e3b\u8f66\u8f86\u3002","title":"\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u5b9a\u4e49"},{"location":"self-driving/intro/define/#_1","text":"","title":"\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u5b9a\u4e49"},{"location":"self-driving/intro/define/#_2","text":"\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u662f\u7531\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u3001\u4ea4\u901a\u57fa\u7840\u8bbe\u65bd\u3001\u901a\u4fe1\u8bbe\u65bd\u3001\u540e\u53f0\u7cfb\u7edf\u5171\u540c\u7ec4\u6210\u7684\u5927\u578b\u7cfb\u7edf\u3002","title":"\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf"},{"location":"self-driving/intro/define/#_3","text":"\u5e7f\u4e49\u4e0a \u7684\u81ea\u52a8\u9a7e\u9a76\u662f\u6307\uff1a\u542b\u6709\u51b3\u7b56\u529f\u80fd\u5e76\u53ef\u4ee5\u5f71\u54cd\u3001\u5e72\u9884\u5f53\u524d\u884c\u9a76\u72b6\u6001\u7684\u8f66\u8f86\uff1b \u72ed\u4e49\u4e0a \u7684\u81ea\u52a8\u9a7e\u9a76\u662f\u6307\uff1a\u65e0\u4eba\u7c7b\u9a7e\u9a76\u5458\uff0c\u7531\u8ba1\u7b97\u673a\u611f\u77e5\u3001\u51b3\u7b56\u548c\u64cd\u4f5c\u7684\u5168\u81ea\u4e3b\u8f66\u8f86\u3002","title":"\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86"},{"location":"self-driving/intro/future/","text":"\u53d1\u5c55\u4e0e\u5c55\u671b\uff1a\u65e0\u4eba\u5316\u667a\u80fd\u4ea4\u901a","title":"\u53d1\u5c55\u4e0e\u5c55\u671b\uff1a\u65e0\u4eba\u5316\u667a\u80fd\u4ea4\u901a"},{"location":"self-driving/intro/future/#_1","text":"","title":"\u53d1\u5c55\u4e0e\u5c55\u671b\uff1a\u65e0\u4eba\u5316\u667a\u80fd\u4ea4\u901a"},{"location":"self-driving/intro/history/","text":"\u5386\u53f2\u8d77\u6e90\uff1ato C -> to B","title":"\u5386\u53f2\u8d77\u6e90\uff1ato C -> to B"},{"location":"self-driving/intro/history/#to-c-to-b","text":"","title":"\u5386\u53f2\u8d77\u6e90\uff1ato C -&gt; to B"},{"location":"self-driving/intro/main/","text":"\u81ea\u52a8\u9a7e\u9a76\u4ecb\u7ecd \u672c\u7ae0\u4ecb\u7ecd\u81ea\u52a8\u9a7e\u9a76\u7684\u57fa\u672c\u77e5\u8bc6\uff0c\u5305\u62ec\u81ea\u52a8\u9a7e\u9a76\u7684\u5386\u53f2\u3001\u5b9a\u4e49\u3001\u5206\u7c7b\u4ee5\u53ca\u5bf9\u672a\u6765\u667a\u80fd\u4ea4\u901a\u7684\u5c55\u671b\u3002","title":"\u81ea\u52a8\u9a7e\u9a76\u4ecb\u7ecd"},{"location":"self-driving/intro/main/#_1","text":"\u672c\u7ae0\u4ecb\u7ecd\u81ea\u52a8\u9a7e\u9a76\u7684\u57fa\u672c\u77e5\u8bc6\uff0c\u5305\u62ec\u81ea\u52a8\u9a7e\u9a76\u7684\u5386\u53f2\u3001\u5b9a\u4e49\u3001\u5206\u7c7b\u4ee5\u53ca\u5bf9\u672a\u6765\u667a\u80fd\u4ea4\u901a\u7684\u5c55\u671b\u3002","title":"\u81ea\u52a8\u9a7e\u9a76\u4ecb\u7ecd"},{"location":"self-driving/system/main/","text":"\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf \u672c\u7ae0\u4ece\u7cfb\u7edf\u5c42\u9762\u4ecb\u7ecd\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\uff0c\u5305\u62ec\u667a\u6167\u4ea4\u901a\u3001\u4eff\u771f\u4e0e\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u4ee5\u53ca\u5b89\u5168\u4fdd\u969c\u3002","title":"\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf"},{"location":"self-driving/system/main/#_1","text":"\u672c\u7ae0\u4ece\u7cfb\u7edf\u5c42\u9762\u4ecb\u7ecd\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\uff0c\u5305\u62ec\u667a\u6167\u4ea4\u901a\u3001\u4eff\u771f\u4e0e\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u4ee5\u53ca\u5b89\u5168\u4fdd\u969c\u3002","title":"\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf"},{"location":"self-driving/system/platform/","text":"\u8bbe\u8ba1\u4e0e\u4eff\u771f\u5e73\u53f0 Platform Description Autoware Apollo \u767e\u5ea6\u65e0\u4eba\u9a7e\u9a76\u5e73\u53f0 AirSim CARLA MATLAB - Autonomous Vehicle Toolbox \u5de5\u5177\u7bb1\u9700\u4ed8\u8d39\u8d2d\u4e70 LGSVL Simulator Fully integrated with Apollo and Autoware","title":"\u8bbe\u8ba1\u4e0e\u4eff\u771f\u5e73\u53f0"},{"location":"self-driving/system/platform/#_1","text":"Platform Description Autoware Apollo \u767e\u5ea6\u65e0\u4eba\u9a7e\u9a76\u5e73\u53f0 AirSim CARLA MATLAB - Autonomous Vehicle Toolbox \u5de5\u5177\u7bb1\u9700\u4ed8\u8d39\u8d2d\u4e70 LGSVL Simulator Fully integrated with Apollo and Autoware","title":"\u8bbe\u8ba1\u4e0e\u4eff\u771f\u5e73\u53f0"},{"location":"self-driving/system/regulation/","text":"\u653f\u7b56\u4e0e\u6cd5\u5f8b\u6cd5\u89c4","title":"\u653f\u7b56\u4e0e\u6cd5\u5f8b\u6cd5\u89c4"},{"location":"self-driving/system/regulation/#_1","text":"","title":"\u653f\u7b56\u4e0e\u6cd5\u5f8b\u6cd5\u89c4"},{"location":"self-driving/system/safety/","text":"\u7cfb\u7edf\u5b89\u5168\u4fdd\u969c \u81ea\u52a8\u9a7e\u9a76\u548c\u4eba\u5de5\u667a\u80fd\u662f\u76ee\u524d\u6700\u706b\u70ed\u7684\u8bdd\u9898\u4e86\u3002\u5728\u529f\u80fd\u6027\u4e0d\u65ad\u5b8c\u5584\u7684\u540c\u65f6\uff0c\u7cfb\u7edf\u7684\u5b89\u5168\u5f80\u5f80\u88ab\u4eba\u5ffd\u7565\u3002\u672c\u6587\u4ecb\u7ecd\u76ee\u524d\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u4e2d\u5b58\u5728\u7684\u5b89\u5168\u9a8c\u8bc1\u56f0\u5883\uff0c\u5df2\u7ecf\u53ef\u80fd\u7684\u89e3\u51b3\u65b9\u6cd5\u3002 \u5982\u4f55\u9a8c\u8bc1\u81ea\u52a8\u9a7e\u9a76 ISO 26262 & IEC 61508\u7684\u4e0d\u8db3 \u7cfb\u7edf\u65e0\u6cd5\u5148\u9a8c \u4f7f\u7528\u4eba\u5de5\u667a\u80fd\u5bfc\u81f4\u7684\u56f0\u96be Fail safe & fail operational RAS Safety Standard Quality management system(ISO9001, IATF16949..) cover product quality, zero defect, zero DPPM Functional Safety (ISO26262) cover systematic fault and random fault SOTIF cover limitation of intended function ASPICE cover software process and capability Mobileye RSS (Responsibility-Sensitive Safety) provide model for safety NVIDA Safety Force Field protect against real-world traffic E-NCAP and C-NCAP for new car assessment Cybersecurity to cover system security hole ASIL: Automotive Safety Integrity Level \u53c2\u8003\u8d44\u6599 A. Bhat, S. Aoki and R. Rajkumar. Tools and Methodologies for Autonomous Driving Systems. Proceedings of the IEEE. 2018","title":"\u7cfb\u7edf\u5b89\u5168\u4fdd\u969c"},{"location":"self-driving/system/safety/#_1","text":"\u81ea\u52a8\u9a7e\u9a76\u548c\u4eba\u5de5\u667a\u80fd\u662f\u76ee\u524d\u6700\u706b\u70ed\u7684\u8bdd\u9898\u4e86\u3002\u5728\u529f\u80fd\u6027\u4e0d\u65ad\u5b8c\u5584\u7684\u540c\u65f6\uff0c\u7cfb\u7edf\u7684\u5b89\u5168\u5f80\u5f80\u88ab\u4eba\u5ffd\u7565\u3002\u672c\u6587\u4ecb\u7ecd\u76ee\u524d\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u4e2d\u5b58\u5728\u7684\u5b89\u5168\u9a8c\u8bc1\u56f0\u5883\uff0c\u5df2\u7ecf\u53ef\u80fd\u7684\u89e3\u51b3\u65b9\u6cd5\u3002 \u5982\u4f55\u9a8c\u8bc1\u81ea\u52a8\u9a7e\u9a76 ISO 26262 & IEC 61508\u7684\u4e0d\u8db3 \u7cfb\u7edf\u65e0\u6cd5\u5148\u9a8c \u4f7f\u7528\u4eba\u5de5\u667a\u80fd\u5bfc\u81f4\u7684\u56f0\u96be Fail safe & fail operational","title":"\u7cfb\u7edf\u5b89\u5168\u4fdd\u969c"},{"location":"self-driving/system/safety/#ras-safety-standard","text":"Quality management system(ISO9001, IATF16949..) cover product quality, zero defect, zero DPPM Functional Safety (ISO26262) cover systematic fault and random fault SOTIF cover limitation of intended function ASPICE cover software process and capability Mobileye RSS (Responsibility-Sensitive Safety) provide model for safety NVIDA Safety Force Field protect against real-world traffic E-NCAP and C-NCAP for new car assessment Cybersecurity to cover system security hole","title":"RAS Safety Standard"},{"location":"self-driving/system/safety/#asil-automotive-safety-integrity-level","text":"","title":"ASIL: Automotive Safety Integrity Level"},{"location":"self-driving/system/safety/#_2","text":"A. Bhat, S. Aoki and R. Rajkumar. Tools and Methodologies for Autonomous Driving Systems. Proceedings of the IEEE. 2018","title":"\u53c2\u8003\u8d44\u6599"},{"location":"self-driving/system/v2x/","text":"\u667a\u80fd\u4ea4\u901a \u667a\u6167\u4ea4\u901a\u4e2d\u91cd\u8981\u7684\u6982\u5ff5\u662f\uff1aV2X, \u5305\u62ecV2V\u548cV2I\u3002\u5206\u522b\u5b9a\u4e49\u4e3a\uff1a V2V: vehicle to vehicle V2I: vehicle to infrastructure","title":"\u667a\u80fd\u4ea4\u901a"},{"location":"self-driving/system/v2x/#_1","text":"\u667a\u6167\u4ea4\u901a\u4e2d\u91cd\u8981\u7684\u6982\u5ff5\u662f\uff1aV2X, \u5305\u62ecV2V\u548cV2I\u3002\u5206\u522b\u5b9a\u4e49\u4e3a\uff1a V2V: vehicle to vehicle V2I: vehicle to infrastructure","title":"\u667a\u80fd\u4ea4\u901a"},{"location":"self-driving/system/vehicle/","text":"\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86 \u4e00\u4e2a\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u5305\u542b\u4ee5\u4e0b\u7ec4\u4ef6\uff1a \u4f20\u611f\u5668 (Sensors) V2X\u901a\u4fe1\u63a5\u53e3 (V2X communication interface) \u611f\u77e5 (Perception) \u9053\u8def-\u4e16\u754c\u6a21\u578b (Road-world model) \u8def\u5f84\u89c4\u5212 (Path planning) \u884c\u4e3a\u89c4\u5212 (Behaviour) \u77ed\u671f\u8def\u5f84\u89c4\u5212 (Short-term path planning) \u72b6\u6001\u76d1\u6d4b (Health monitoring) \u8f66\u8f86\u7ebf\u63a7\u7cfb\u7edf (Vehicle by-wire control) \u6570\u636e\u8bb0\u5f55\u5355\u5143 (Data logger) \u5d4c\u5165\u5f0f\u8ba1\u7b97\u5e73\u53f0 (Embedded computing platform) \u7528\u6237\u4ea4\u4e92\u754c\u9762 (User interface)","title":"\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86"},{"location":"self-driving/system/vehicle/#_1","text":"\u4e00\u4e2a\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u5305\u542b\u4ee5\u4e0b\u7ec4\u4ef6\uff1a \u4f20\u611f\u5668 (Sensors) V2X\u901a\u4fe1\u63a5\u53e3 (V2X communication interface) \u611f\u77e5 (Perception) \u9053\u8def-\u4e16\u754c\u6a21\u578b (Road-world model) \u8def\u5f84\u89c4\u5212 (Path planning) \u884c\u4e3a\u89c4\u5212 (Behaviour) \u77ed\u671f\u8def\u5f84\u89c4\u5212 (Short-term path planning) \u72b6\u6001\u76d1\u6d4b (Health monitoring) \u8f66\u8f86\u7ebf\u63a7\u7cfb\u7edf (Vehicle by-wire control) \u6570\u636e\u8bb0\u5f55\u5355\u5143 (Data logger) \u5d4c\u5165\u5f0f\u8ba1\u7b97\u5e73\u53f0 (Embedded computing platform) \u7528\u6237\u4ea4\u4e92\u754c\u9762 (User interface)","title":"\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86"}]}